{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QA sql query generator using Deepseek\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Authors**\n",
    "1. Alfan Dinda Rahmawan (alfan.d.rahmawan@gdplabs.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: google-api-python-client==2.100.0 in ./.venv/lib/python3.12/site-packages (2.100.0)\n",
      "Requirement already satisfied: gspread==5.10.0 in ./.venv/lib/python3.12/site-packages (5.10.0)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.15.0 in ./.venv/lib/python3.12/site-packages (from google-api-python-client==2.100.0) (0.22.0)\n",
      "Requirement already satisfied: google-auth<3.0.0.dev0,>=1.19.0 in ./.venv/lib/python3.12/site-packages (from google-api-python-client==2.100.0) (2.38.0)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in ./.venv/lib/python3.12/site-packages (from google-api-python-client==2.100.0) (0.2.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in ./.venv/lib/python3.12/site-packages (from google-api-python-client==2.100.0) (2.24.2)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in ./.venv/lib/python3.12/site-packages (from google-api-python-client==2.100.0) (4.1.1)\n",
      "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in ./.venv/lib/python3.12/site-packages (from gspread==5.10.0) (1.2.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in ./.venv/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client==2.100.0) (1.69.2)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in ./.venv/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client==2.100.0) (6.30.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in ./.venv/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client==2.100.0) (1.26.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in ./.venv/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client==2.100.0) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./.venv/lib/python3.12/site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client==2.100.0) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.12/site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client==2.100.0) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.venv/lib/python3.12/site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client==2.100.0) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./.venv/lib/python3.12/site-packages (from google-auth-oauthlib>=0.4.1->gspread==5.10.0) (2.0.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in ./.venv/lib/python3.12/site-packages (from httplib2<1.dev0,>=0.15.0->google-api-python-client==2.100.0) (3.2.3)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in ./.venv/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client==2.100.0) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client==2.100.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client==2.100.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client==2.100.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client==2.100.0) (2025.1.31)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./.venv/lib/python3.12/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread==5.10.0) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.12/site-packages (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting pymysql==1.0.2\n",
      "  Downloading PyMySQL-1.0.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Downloading PyMySQL-1.0.2-py3-none-any.whl (43 kB)\n",
      "Installing collected packages: pymysql\n",
      "  Attempting uninstall: pymysql\n",
      "    Found existing installation: PyMySQL 1.1.1\n",
      "    Uninstalling PyMySQL-1.1.1:\n",
      "      Successfully uninstalled PyMySQL-1.1.1\n",
      "Successfully installed pymysql-1.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q langchain==\"0.3.0\"\n",
    "%pip install -q langchain-aws==\"0.2.7\"\n",
    "%pip install -q langchain_openai==\"0.2.14\"\n",
    "%pip install -q boto3==\"1.35.71\"\n",
    "%pip install -q pandas==\"2.2.2\"\n",
    "%pip install -q tqdm==\"4.66.4\"\n",
    "%pip install google-api-python-client==2.100.0 gspread==5.10.0\n",
    "%pip install python-dotenv\n",
    "%pip install pymysql==1.0.2\n",
    "%pip install -q mysql-connector-python==9.2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MariaDB Server version 5.5.5-10.5.28-MariaDB-ubu2004\n",
      "Connected to MariaDB Server version 5.5.5-10.5.28-MariaDB-ubu2004\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "from typing import Dict, List, Any, Optional\n",
    "\n",
    "\n",
    "def connect_to_mariadb(database_name: str) -> Optional[mysql.connector.connection.MySQLConnection]:\n",
    "    \"\"\"\n",
    "    Connect to the MariaDB database.\n",
    "\n",
    "    Returns:\n",
    "        Optional[mysql.connector.connection.MySQLConnection]: A connection object if successful, None otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        connection = mysql.connector.connect(\n",
    "            host=\"localhost\",\n",
    "            port=33062,\n",
    "            user=\"app_user_demo\",\n",
    "            password=\"StrongPassw0rd!\",\n",
    "            database=database_name\n",
    "        )\n",
    "\n",
    "        if connection.is_connected():\n",
    "            db_info = connection.get_server_info()\n",
    "            print(f\"Connected to MariaDB Server version {db_info}\")\n",
    "            return connection\n",
    "\n",
    "    except Error as e:\n",
    "        print(f\"Error connecting to MariaDB: {e}\")\n",
    "        return None\n",
    "\n",
    "def execute_query(connection: mysql.connector.connection.MySQLConnection, query: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Execute a query on the MariaDB database.\n",
    "\n",
    "    Args:\n",
    "        connection: The database connection object.\n",
    "        query: The SQL query to execute.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict[str, Any]]: A list of dictionaries containing the query results.\n",
    "    \"\"\"\n",
    "    cursor = connection.cursor(dictionary=True)\n",
    "    cursor.execute(query)\n",
    "    result = cursor.fetchall()\n",
    "    cursor.close()\n",
    "    return result\n",
    "\n",
    "time_management_db = connect_to_mariadb(\"ru4f_time_management\")\n",
    "core_employee_db = connect_to_mariadb(\"ru4f_core_employee\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_SPREADSHEET_ID: str = \"1dDMqrol_DrEMjvLy88IRu2WdHN7T5BU0LrD8ORLuNPI\" # put your spreadsheet id here\n",
    "GOOGLE_SPREADSHEET_URL: str = f\"https://docs.google.com/spreadsheets/d/{GOOGLE_SPREADSHEET_ID}/edit?usp=sharing\" # put your spreadsheet link here\n",
    "DATA_TEST_SHEET_NAME: str = \"catapa_syntetics_time_management_augment3_prompt2\"\n",
    "\n",
    "GOOGLE_SHEETS_CLIENT_EMAIL: str = os.getenv('GOOGLE_SHEETS_CLIENT_EMAIL')\n",
    "GOOGLE_SHEETS_PRIVATE_KEY: str = os.getenv('GOOGLE_SHEETS_PRIVATE_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Authentication\n",
    "from modules.google_sheets_writer import GoogleUtil\n",
    "\n",
    "PRIVATE_KEY = GOOGLE_SHEETS_PRIVATE_KEY\n",
    "google: GoogleUtil = GoogleUtil(PRIVATE_KEY, GOOGLE_SHEETS_CLIENT_EMAIL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Query fixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
    "from tqdm import tqdm\n",
    "\n",
    "from modules.database_info.schema import employee_schema, time_management_schema\n",
    "from modules.database_info.master_data import employee_master_data, time_management_master_data\n",
    "from modules.database_info.relation import employee_relations, time_management_relations\n",
    "from modules.database_info.trustee_tables import data_trustee_employee, data_trustee_time_management\n",
    "from modules.database_info.anonymize_entities import anonymized_entities_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_MESSAGE = \"\"\"<instructions>\n",
    "You are a specialized SQL query fixer and generator for an HR database. Your task is to analyze SQL queries that have errors, fix them, and generate multiple candidate solutions that correctly answer business questions in Indonesian language based on the provided HR database schema.\n",
    "\n",
    "ADDITIONAL GUIDELINES\n",
    "- Generate optimized, correct SQL queries that follow best practices\n",
    "- Consider privacy concerns with data trustee fields and anonymized entities\n",
    "- Include comments in complex SQL queries to explain the logic\n",
    "- Format queries appropriately for readability\n",
    "- Use appropriate joins, filters, and aggregations based on the question\n",
    "- Make sure the output is in valid, properly formatted JSON\n",
    "- Think step-by-step before generating the final SQL query\n",
    "- When fixing errors, carefully analyze the error message and identify the root cause\n",
    "- Generate multiple candidate solutions with different approaches when possible\n",
    "</instructions>\"\"\"\n",
    "\n",
    "USER_MESSAGE = \"\"\"\n",
    "**General SQL Generation Guidelines**:\n",
    "The generated SQL must be directly executable in MariaDB 10.5.23.\n",
    "- Do NOT select identifiers (e.g., `id`, `employee_id`) except when used within aggregate functions like `MAX`, `SUM`, or `AVG`.\n",
    "- Always display human-readable names rather than IDs (e.g., use `religions.name` instead of `religions.id`).\n",
    "- Prefix column names with the table name in the SELECT clause to avoid ambiguity.\n",
    "- Use snake_case for column aliases in the SELECT clause. Do NOT use aliases in the FROM clause.\n",
    "- All date literals must be wrapped in `STR_TO_DATE()`, and when comparing dates, ensure the comparator is of DATE type using `CAST()`.\n",
    "- Use aggregate functions only in the SELECT or HAVING clauses, not within the WHERE clause.\n",
    "- JOIN conditions must reference the correct foreign keys, and if an expected display name is missing, add an extra JOIN to the appropriate master table.\n",
    "- Handle division carefully by ensuring denominators are non-zero.\n",
    "- Rename output column names based on the user's instruction language for clarity.\n",
    "\n",
    "**Dynamic Schema Handling**:\n",
    "- Use the provided placeholders dynamically:\n",
    "\n",
    "**Database Schema**:\n",
    "- The schema for the database is as follows:\n",
    "  {schema}\n",
    "\n",
    "**Table Relationships**:\n",
    "- The relationships between these tables are described below:\n",
    "  {relations}\n",
    "\n",
    "**Master Data**:\n",
    "- Master data in the database are listed here:\n",
    "  {master_data}\n",
    "\n",
    "**Data Trustee Enabled Tables**:\n",
    "- List of tables requiring a data trustee and specific columns for JOIN operations. Entries may indicate a prerequisite join with another table before joining to the `employment_statuses` table, denoted by `table_name.column_name`. A join must first occur with `table_name` then followed by a join to `employment_statuses` using `column_name` from `table_name`:\n",
    "  {data_trustee_tables}\n",
    "\n",
    "**Anonymized Entities**:\n",
    "- List of anonymized entities along with their descriptions that may be used in the `WHERE` clause:\n",
    "  {anonymized_entities_description}\n",
    "\n",
    "- If new tables or columns are introduced in the schema, apply the same rules without hardcoding table-specific logic.\n",
    "- If a referenced table or column is missing a display name, join to the corresponding master table to retrieve it.\n",
    "\n",
    "**Data Trustee Requirements**:\n",
    "- If any table in the query appears in the `Data Trustee Enabled Tables` list, then:\n",
    "  - Add a JOIN with the `employment_statuses` table using the `employee_id` column.\n",
    "  - Add filters:\n",
    "    `employment_statuses.organization_id IN ('[ORGANIZATION_IDS]')`\n",
    "    `AND employment_statuses.job_level_id IN ('[JOB_LEVEL_IDS]')`\n",
    "    `AND employment_statuses.location_id IN ('[LOCATION_IDS]')`.\n",
    "  - If the table requires a prerequisite join (as indicated in the list), perform that JOIN before joining with `employment_statuses`.\n",
    "- If no table from the list is used, do not include any data trustee-specific JOINs or filters.\n",
    "\n",
    "**Date Handling**:\n",
    "- Use the provided `{current_date}` as the reference for any date-related calculations.\n",
    "- Always wrap date strings in `STR_TO_DATE()` and use `CAST()` where necessary to ensure proper date comparisons.\n",
    "\n",
    "**Query Examples** (for reference):\n",
    "- *Turnover Rate*:\n",
    "  Use a WITH clause to generate a series of years, and then calculate the turnover rate using appropriate JOINs and conditions.\n",
    "- *Quarterly New Employee Count*:\n",
    "  Count employees hired per quarter, ensuring that only active employees are counted by including `WHERE employees.active = TRUE`.\n",
    "- *Employee Managerial Status*:\n",
    "  Use a CASE statement to determine if an employee is a manager by checking if their `id` appears as a `manager_id` in the employees table.\n",
    "\n",
    "**User Instruction**:\n",
    "- The business question is provided in the placeholder `{business_question}`.\n",
    "- The current SQL query with errors is provided in the placeholder `{current_sql_query}`.\n",
    "- The error output from executing the current SQL query is provided in the placeholder `{error_output}`.\n",
    "\n",
    "**Task**:\n",
    "1. **Analyze Error**:\n",
    "   - Carefully analyze the error message to identify the root cause of the issue.\n",
    "\n",
    "2. **Fix SQL Query**:\n",
    "   - Generate three candidate SQL queries that fix the identified issues while correctly answering the business question.\n",
    "   - Each candidate should use a slightly different approach when possible.\n",
    "\n",
    "3. **Ensure Data Trustee Compliance**:\n",
    "   - If any table from the `Data Trustee Enabled Tables` is used, add the necessary JOINs and filters as specified.\n",
    "\n",
    "**Output Format**:\n",
    "- Your response must be a valid JSON object with the following structure:\n",
    "```json\n",
    "{{\n",
    "  \"sql_queries\": {{\n",
    "    \"business_question\": \"<user_business_question>\",\n",
    "    \"sql_query_candidate_1\": \"<sql_query_candidate_1>\",\n",
    "    \"sql_query_candidate_2\": \"<sql_query_candidate_2>\",\n",
    "    \"sql_query_candidate_3\": \"<sql_query_candidate_3>\",\n",
    "  }}\n",
    "}}\n",
    "```\n",
    "- Do NOT output any additional text besides this JSON object.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QnAPair(BaseModel):\n",
    "    paraphrased_input: str = Field(description=\"paraphrased_input\")\n",
    "    test_to_sql_query: str = Field(description=\"test_to_sql_query\")\n",
    "\n",
    "class QnAPairs(BaseModel):\n",
    "    qna_pairs: List[QnAPair] = Field(description=\"list of qna pairs\")\n",
    "\n",
    "## OpenAI / DeepSeek\n",
    "DEEPSEEK_MODEL_NAME = os.getenv(\"DEEPSEEK_MODEL\")\n",
    "DEEPSEEK_ENDPOINT = os.getenv(\"DEEPSEEK_ENDPOINT\")\n",
    "DEEPSEEK_API_KEY = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name=DEEPSEEK_MODEL_NAME,\n",
    "    temperature=0.7,  # Higher temperature (0.7-0.9) for more creative variations\n",
    "    openai_api_base=DEEPSEEK_ENDPOINT,\n",
    "    openai_api_key=DEEPSEEK_API_KEY,\n",
    "    top_p=0.95,  # Keep high top_p for diverse outputs while filtering unlikely tokens\n",
    "    seed=42  # Optional: set seed for reproducibility\n",
    ")\n",
    "\n",
    "# Create prompt template\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(SYSTEM_MESSAGE)\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(USER_MESSAGE)\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    system_message_prompt,\n",
    "    human_message_prompt\n",
    "])\n",
    "parser = JsonOutputParser(pydantic_object=QnAPairs)\n",
    "chain = prompt | llm | parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 09:14:28,655 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sql_queries': {'business_question': \"Berapa persentase karyawan yang mengajukan pengunduran diri dengan alasan 'Pensiun' selama tahun 2023?\",\n",
       "  'sql_query_candidate_1': \"SELECT \\n  (COUNT(DISTINCT termination_entries.employee_id) * 100.0 / \\n  (SELECT COUNT(DISTINCT employees.id) \\n  FROM employees \\n  JOIN employment_statuses ON employees.id = employment_statuses.employee_id \\n  WHERE employees.active = TRUE \\n  AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]') \\n  AND employment_statuses.job_level_id IN ('[JOB_LEVEL_IDS]') \\n  AND employment_statuses.location_id IN ('[LOCATION_IDS]')\\n  ) AS persentase_pengunduran_diri \\nFROM termination_entries \\nJOIN termination_reasons ON termination_entries.termination_reason_id = termination_reasons.id \\nJOIN employees ON termination_entries.employee_id = employees.id \\nJOIN employment_statuses ON employees.id = employment_statuses.employee_id \\nWHERE termination_reasons.name = 'Pensiun' \\nAND termination_entries.approval_status = 'APPROVED' \\nAND CAST(termination_entries.effective_date AS DATE) BETWEEN STR_TO_DATE('2023-01-01', '%Y-%m-%d') AND STR_TO_DATE('2023-12-31', '%Y-%m-%d') \\nAND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]') \\nAND employment_statuses.job_level_id IN ('[JOB_LEVEL_IDS]') \\nAND employment_statuses.location_id IN ('[LOCATION_IDS]');\",\n",
       "  'sql_query_candidate_2': \"WITH total_active_employees AS (\\n  SELECT COUNT(DISTINCT employees.id) AS total_count\\n  FROM employees\\n  JOIN employment_statuses ON employees.id = employment_statuses.employee_id\\n  WHERE employees.active = TRUE\\n  AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]')\\n  AND employment_statuses.job_level_id IN ('[JOB_LEVEL_IDS]')\\n  AND employment_statuses.location_id IN ('[LOCATION_IDS]')\\n),\\nretired_employees AS (\\n  SELECT COUNT(DISTINCT termination_entries.employee_id) AS retired_count\\n  FROM termination_entries\\n  JOIN termination_reasons ON termination_entries.termination_reason_id = termination_reasons.id\\n  JOIN employees ON termination_entries.employee_id = employees.id\\n  JOIN employment_statuses ON employees.id = employment_statuses.employee_id\\n  WHERE termination_reasons.name = 'Pensiun'\\n  AND termination_entries.approval_status = 'APPROVED'\\n  AND CAST(termination_entries.effective_date AS DATE) BETWEEN STR_TO_DATE('2023-01-01', '%Y-%m-%d') AND STR_TO_DATE('2023-12-31', '%Y-%m-%d')\\n  AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]')\\n  AND employment_statuses.job_level_id IN ('[JOB_LEVEL_IDS]')\\n  AND employment_statuses.location_id IN ('[LOCATION_IDS]')\\n)\\nSELECT \\n  (retired_employees.retired_count * 100.0 / total_active_employees.total_count) AS persentase_pengunduran_diri\\nFROM retired_employees, total_active_employees;\",\n",
       "  'sql_query_candidate_3': \"SELECT \\n  (COUNT(DISTINCT termination_entries.employee_id) * 100.0 / \\n  NULLIF(\\n    (SELECT COUNT(DISTINCT employees.id) \\n    FROM employees \\n    JOIN employment_statuses ON employees.id = employment_statuses.employee_id \\n    WHERE employees.active = TRUE \\n    AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]') \\n    AND employment_statuses.job_level_id IN ('[JOB_LEVEL_IDS]') \\n    AND employment_statuses.location_id IN ('[LOCATION_IDS]')\\n    ), 0\\n  ) AS persentase_pengunduran_diri \\nFROM termination_entries \\nJOIN termination_reasons ON termination_entries.termination_reason_id = termination_reasons.id \\nJOIN employees ON termination_entries.employee_id = employees.id \\nJOIN employment_statuses ON employees.id = employment_statuses.employee_id \\nWHERE termination_reasons.name = 'Pensiun' \\nAND termination_entries.approval_status = 'APPROVED' \\nAND CAST(termination_entries.effective_date AS DATE) BETWEEN STR_TO_DATE('2023-01-01', '%Y-%m-%d') AND STR_TO_DATE('2023-12-31', '%Y-%m-%d') \\nAND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]') \\nAND employment_statuses.job_level_id IN ('[JOB_LEVEL_IDS]') \\nAND employment_statuses.location_id IN ('[LOCATION_IDS]');\"}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "current_date = datetime.now().strftime(\"%d %B %Y\")\n",
    "database_type = \"employee\"\n",
    "business_question = \"Berapa persentase karyawan yang mengajukan pengunduran diri dengan alasan 'Pensiun' selama tahun 2023?\"\n",
    "\n",
    "current_sql_query = \"SELECT (COUNT(DISTINCT termination_entries.employee_id) * 100.0 / (SELECT COUNT(DISTINCT employees.id) FROM employees JOIN employment_statuses ON employees.id = employment_statuses.employee_id WHERE employees.active = TRUE AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]') AND employment_statuses.job_level_id IN ('[JOB_LEVEL_IDS]') AND employment_statuses.location_id IN ('[LOCATION_IDS]')) AS 'persentase_pengunduran_diri' FROM termination_entries JOIN termination_reasons ON termination_entries.termination_reason_id = termination_reasons.id JOIN employees ON termination_entries.employee_id = employees.id JOIN employment_statuses ON employees.id = employment_statuses.employee_id WHERE termination_reasons.name = 'Pensiun' AND termination_entries.approval_status = 'APPROVED' AND CAST(termination_entries.effective_date AS DATE) BETWEEN STR_TO_DATE('2023-01-01', '%Y-%m-%d') AND STR_TO_DATE('2023-12-31', '%Y-%m-%d') AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]') AND employment_statuses.job_level_id IN ('[JOB_LEVEL_IDS]') AND employment_statuses.location_id IN ('[LOCATION_IDS]');\"\n",
    "\n",
    "error_output = \"\"\"\n",
    "Error executing query: (pymysql.err.ProgrammingError) (1064, \"You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near ', 0) AS persentase_pengunduran_diri FROM termination_entries JOIN termination_re' at line 1\")\n",
    "\"\"\"\n",
    "\n",
    "if database_type == \"employee\":\n",
    "    schema = employee_schema\n",
    "    relations = employee_relations\n",
    "    master_data = employee_master_data\n",
    "    data_trustee_tables = data_trustee_employee\n",
    "    master_data = employee_master_data\n",
    "else:\n",
    "    schema = time_management_schema\n",
    "    relations = time_management_relations\n",
    "    master_data = time_management_master_data\n",
    "    data_trustee_tables = data_trustee_time_management\n",
    "    master_data = time_management_master_data\n",
    "\n",
    "response = chain.invoke({\n",
    "    \"schema\": schema,\n",
    "    \"relations\": relations,\n",
    "    \"master_data\": master_data,\n",
    "    \"data_trustee_tables\": data_trustee_tables,\n",
    "    \"anonymized_entities_description\": anonymized_entities_description,\n",
    "    \"current_date\": current_date,\n",
    "    \"business_question\": business_question,\n",
    "    \"current_sql_query\": current_sql_query,\n",
    "    \"error_output\": error_output\n",
    "})\n",
    "display(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'department': 'Information Technology', 'absence_count': 3}, {'department': 'Human Resources', 'absence_count': 1}, {'department': 'Board of Directors', 'absence_count': 1}]\n"
     ]
    }
   ],
   "source": [
    "connection = time_management_db\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "  organizations.name AS department,\n",
    "  COUNT(attendances.id) AS absence_count\n",
    "FROM\n",
    "  employees\n",
    "  LEFT JOIN employment_statuses ON employees.id = employment_statuses.employee_id\n",
    "  LEFT JOIN organizations ON employment_statuses.organization_id = organizations.id\n",
    "  LEFT JOIN attendances ON employees.id = attendances.employee_id\n",
    "  LEFT JOIN attendance_statuses ON attendances.attendance_status_in_id = attendance_statuses.id\n",
    "WHERE\n",
    "  employees.active = TRUE\n",
    "  AND attendance_statuses.attendance_type = 'ABSENT'\n",
    "  AND attendances.date BETWEEN STR_TO_DATE('2025-02-01', '%Y-%m-%d') AND STR_TO_DATE('2025-02-28', '%Y-%m-%d')\n",
    "  AND organization_id IN ('428b67d8-aa38-43b3-9fbd-714e424e78b4', '48bee117-5c8e-4dd9-ad3a-ea0691fa311b', '5bd621f0-fd6e-445c-9c65-f12e0ed97e76', '9d1e8e05-50c8-45ee-8aaf-840da1e2b2ba', '9f293790-0f46-4800-bda0-f700d51af3de', 'bdb90554-027a-43c2-abc5-5c26993b15a7')\n",
    "  AND job_level_id IN ('4471d89c-7d48-460d-8d92-7b5b4e5fbea0', 'a9e8af86-fbd8-4cd3-a477-b3cff496bf40', 'aa1c7990-ac32-4522-842b-09ac7c6d04a6', 'b2ec711e-0848-4e32-8888-2bf279e3febd', 'cc1e8b6b-bdb9-4500-8d33-3afbe2f9f462')\n",
    "  AND location_id IN ('12a76682-d541-4847-ba9f-e850eb519a76', '60090d71-af4f-47a3-a6fc-962218b1f4d1', '8bdd9889-4247-46f8-86a7-56fd75aa9c40')\n",
    "GROUP BY\n",
    "  organizations.name\n",
    "ORDER BY\n",
    "  absence_count DESC;\n",
    "\"\"\"\n",
    "cursor = connection.cursor(dictionary=True)\n",
    "cursor.execute(query)\n",
    "result = cursor.fetchall()\n",
    "print(result)\n",
    "# print(type(result))\n",
    "# [str(row['organization_id']) for row in result]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run sql query fixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:02:16,660 - INFO - {'Status': 'Skipped 51_1'}\n",
      "2025-04-11 10:02:16,661 - INFO - {'Status': 'Skipped 51_2'}\n",
      "2025-04-11 10:02:16,662 - INFO - {'Status': 'Skipped 51_3'}\n",
      "2025-04-11 10:02:16,663 - INFO - {'Status': 'Skipped 52_1'}\n",
      "2025-04-11 10:02:16,664 - INFO - {'Status': 'Skipped 52_2'}\n",
      "2025-04-11 10:02:16,667 - INFO - {'Status': 'Skipped 52_3'}\n",
      "2025-04-11 10:02:16,668 - INFO - {'Status': 'Skipped 53_1'}\n",
      "2025-04-11 10:02:16,669 - INFO - {'Status': 'Skipped 53_2'}\n",
      "2025-04-11 10:02:16,671 - INFO - {'Status': 'Skipped 53_3'}\n",
      "2025-04-11 10:02:16,675 - INFO - {'Status': 'Skipped 54_1'}\n",
      "2025-04-11 10:02:16,676 - INFO - {'Status': 'Skipped 54_2'}\n",
      "2025-04-11 10:02:16,679 - INFO - {'Status': 'Skipped 54_3'}\n",
      "2025-04-11 10:02:16,682 - INFO - {'Status': 'Skipped 55_1'}\n",
      "2025-04-11 10:02:16,684 - INFO - {'Status': 'Skipped 55_2'}\n",
      "2025-04-11 10:02:16,687 - INFO - {'Status': 'Skipped 55_3'}\n",
      "2025-04-11 10:02:16,689 - INFO - {'Status': 'Skipped 56_1'}\n",
      "2025-04-11 10:02:16,694 - INFO - {'Status': 'Skipped 56_2'}\n",
      "2025-04-11 10:02:16,699 - INFO - {'Status': 'Skipped 56_3'}\n",
      "2025-04-11 10:02:16,703 - INFO - {'Status': 'Skipped 57_1'}\n",
      "2025-04-11 10:02:16,705 - INFO - {'Status': 'Skipped 57_2'}\n",
      "2025-04-11 10:02:16,706 - INFO - {'Status': 'Skipped 57_3'}\n",
      "2025-04-11 10:02:16,707 - INFO - {'Status': 'Skipped 58_1'}\n",
      "2025-04-11 10:02:16,710 - INFO - {'Status': 'Skipped 58_2'}\n",
      "2025-04-11 10:02:16,711 - INFO - {'Status': 'Skipped 58_3'}\n",
      "2025-04-11 10:02:16,713 - INFO - {'Status': 'Skipped 59_1'}\n",
      "2025-04-11 10:02:16,715 - INFO - {'Status': 'Skipped 59_2'}\n",
      "2025-04-11 10:02:16,717 - INFO - {'Status': 'Skipped 59_3'}\n",
      "2025-04-11 10:02:16,718 - INFO - {'Status': 'Skipped 60_1'}\n",
      "2025-04-11 10:02:16,719 - INFO - {'Status': 'Skipped 60_2'}\n",
      "2025-04-11 10:02:16,721 - INFO - {'Status': 'Skipped 60_3'}\n",
      "2025-04-11 10:02:16,722 - INFO - {'Status': 'Skipped 61_1'}\n",
      "2025-04-11 10:02:16,724 - INFO - {'Status': 'Skipped 61_2'}\n",
      "2025-04-11 10:02:16,725 - INFO - {'Status': 'Skipped 61_3'}\n",
      "2025-04-11 10:02:16,726 - INFO - {'Status': 'Skipped 62_1'}\n",
      "2025-04-11 10:02:16,727 - INFO - {'Status': 'Skipped 62_2'}\n",
      "2025-04-11 10:02:16,729 - INFO - {'Status': 'Skipped 62_3'}\n",
      "2025-04-11 10:02:16,730 - INFO - {'Status': 'Skipped 63_1'}\n",
      "2025-04-11 10:02:16,733 - INFO - {'Status': 'Skipped 63_2'}\n",
      "2025-04-11 10:02:16,734 - INFO - {'Status': 'Skipped 63_3'}\n",
      "2025-04-11 10:02:16,736 - INFO - {'Status': 'Skipped 64_1'}\n",
      "2025-04-11 10:02:16,739 - INFO - {'Status': 'Skipped 64_2'}\n",
      "2025-04-11 10:02:16,741 - INFO - {'Status': 'Skipped 64_3'}\n",
      "2025-04-11 10:02:16,743 - INFO - {'Status': 'Skipped 65_1'}\n",
      "2025-04-11 10:02:16,754 - INFO - {'Status': 'Skipped 65_2'}\n",
      "2025-04-11 10:02:16,756 - INFO - {'Status': 'Skipped 65_3'}\n",
      "2025-04-11 10:02:16,759 - INFO - {'Status': 'Skipped 66_1'}\n",
      "2025-04-11 10:02:16,766 - INFO - {'Status': 'Skipped 66_2'}\n",
      "2025-04-11 10:02:16,767 - INFO - {'Status': 'Skipped 66_3'}\n",
      "2025-04-11 10:02:16,768 - INFO - {'Status': 'Skipped 67_1'}\n",
      "2025-04-11 10:02:16,769 - INFO - {'Status': 'Skipped 67_2'}\n",
      "2025-04-11 10:02:16,772 - INFO - {'Status': 'Skipped 67_3'}\n",
      "2025-04-11 10:02:16,773 - INFO - {'Status': 'Skipped 68_1'}\n",
      "2025-04-11 10:02:16,774 - INFO - {'Status': 'Skipped 68_2'}\n",
      "2025-04-11 10:02:16,777 - INFO - {'Status': 'Skipped 68_3'}\n",
      "2025-04-11 10:02:16,778 - INFO - {'Status': 'Skipped 69_1'}\n",
      "2025-04-11 10:02:16,780 - INFO - {'Status': 'Skipped 69_2'}\n",
      "2025-04-11 10:02:16,782 - INFO - {'Status': 'Skipped 69_3'}\n",
      "2025-04-11 10:02:16,783 - INFO - {'Status': 'Skipped 70_1'}\n",
      "2025-04-11 10:02:16,784 - INFO - {'Status': 'Skipped 70_2'}\n",
      "2025-04-11 10:02:16,785 - INFO - {'Status': 'Skipped 70_3'}\n",
      "2025-04-11 10:02:16,788 - INFO - {'Status': 'Skipped 71_1'}\n",
      "2025-04-11 10:02:16,791 - INFO - {'Status': 'Skipped 71_2'}\n",
      "2025-04-11 10:02:16,792 - INFO - {'Status': 'Skipped 71_3'}\n",
      "2025-04-11 10:02:16,793 - INFO - {'Status': 'Skipped 72_1'}\n",
      "2025-04-11 10:02:16,794 - INFO - {'Status': 'Skipped 72_2'}\n",
      "2025-04-11 10:02:16,796 - INFO - {'Status': 'Skipped 72_3'}\n",
      "2025-04-11 10:02:16,797 - INFO - {'Status': 'Skipped 73_1'}\n",
      "2025-04-11 10:02:16,798 - INFO - {'Status': 'Skipped 73_2'}\n",
      "2025-04-11 10:02:16,800 - INFO - {'Status': 'Skipped 73_3'}\n",
      "2025-04-11 10:02:16,803 - INFO - {'Status': 'Skipped 74_1'}\n",
      "2025-04-11 10:02:16,804 - INFO - {'Status': 'Skipped 74_2'}\n",
      "2025-04-11 10:02:16,805 - INFO - {'Status': 'Skipped 74_3'}\n",
      "2025-04-11 10:02:16,807 - INFO - {'Status': 'Skipped 75_1'}\n",
      "2025-04-11 10:02:16,808 - INFO - {'Status': 'Skipped 75_2'}\n",
      "2025-04-11 10:02:16,810 - INFO - {'Status': 'Skipped 75_3'}\n",
      "2025-04-11 10:02:16,811 - INFO - {'Status': 'Skipped 76_1'}\n",
      "2025-04-11 10:02:16,814 - INFO - {'Status': 'Skipped 76_2'}\n",
      "2025-04-11 10:02:16,818 - INFO - {'Status': 'Skipped 76_3'}\n",
      "2025-04-11 10:02:16,819 - INFO - {'Status': 'Skipped 77_1'}\n",
      "2025-04-11 10:02:16,821 - INFO - {'Status': 'Skipped 77_2'}\n",
      "2025-04-11 10:02:16,822 - INFO - {'Status': 'Skipped 77_3'}\n",
      "2025-04-11 10:02:16,823 - INFO - {'Status': 'Skipped 78_1'}\n",
      "2025-04-11 10:02:16,824 - INFO - {'Status': 'Skipped 78_2'}\n",
      "2025-04-11 10:02:16,826 - INFO - {'Status': 'Skipped 78_3'}\n",
      "2025-04-11 10:02:16,827 - INFO - {'Status': 'Skipped 79_1'}\n",
      "2025-04-11 10:02:16,828 - INFO - {'Status': 'Skipped 79_2'}\n",
      "2025-04-11 10:02:16,830 - INFO - {'Status': 'Skipped 79_3'}\n",
      "2025-04-11 10:02:16,831 - INFO - {'Status': 'Skipped 80_1'}\n",
      "2025-04-11 10:02:16,836 - INFO - {'Status': 'Skipped 80_2'}\n",
      "2025-04-11 10:02:16,838 - INFO - {'Status': 'Skipped 80_3'}\n",
      "2025-04-11 10:02:16,840 - INFO - {'Status': 'Skipped 81_1'}\n",
      "2025-04-11 10:02:16,841 - INFO - {'Status': 'Skipped 81_2'}\n",
      "2025-04-11 10:02:16,842 - INFO - {'Status': 'Skipped 81_3'}\n",
      "2025-04-11 10:02:16,843 - INFO - {'Status': 'Skipped 82_1'}\n",
      "2025-04-11 10:02:16,844 - INFO - {'Status': 'Skipped 82_2'}\n",
      "2025-04-11 10:02:16,846 - INFO - {'Status': 'Skipped 82_3'}\n",
      "2025-04-11 10:02:16,848 - INFO - {'Status': 'Skipped 83_1'}\n",
      "2025-04-11 10:02:16,851 - INFO - {'Status': 'Skipped 83_2'}\n",
      "2025-04-11 10:02:16,853 - INFO - {'Status': 'Skipped 83_3'}\n",
      "2025-04-11 10:02:16,855 - INFO - {'Status': 'Skipped 84_1'}\n",
      "2025-04-11 10:02:16,856 - INFO - {'Status': 'Skipped 84_2'}\n",
      "2025-04-11 10:02:16,857 - INFO - {'Status': 'Skipped 84_3'}\n",
      "2025-04-11 10:02:16,859 - INFO - {'Status': 'Skipped 85_1'}\n",
      "2025-04-11 10:02:16,860 - INFO - {'Status': 'Skipped 85_2'}\n",
      "2025-04-11 10:02:16,865 - INFO - {'Status': 'Skipped 85_3'}\n",
      "2025-04-11 10:02:16,869 - INFO - {'Status': 'Skipped 86_1'}\n",
      "2025-04-11 10:02:16,870 - INFO - {'Status': 'Skipped 86_2'}\n",
      "2025-04-11 10:02:16,871 - INFO - {'Status': 'Skipped 86_3'}\n",
      "2025-04-11 10:02:16,873 - INFO - {'Status': 'Skipped 87_1'}\n",
      "2025-04-11 10:02:16,874 - INFO - {'Status': 'Skipped 87_2'}\n",
      "2025-04-11 10:02:16,875 - INFO - {'Status': 'Skipped 87_3'}\n",
      "2025-04-11 10:02:16,876 - INFO - {'Status': 'Skipped 88_1'}\n",
      "2025-04-11 10:02:16,877 - INFO - {'Status': 'Skipped 88_2'}\n",
      "2025-04-11 10:02:16,879 - INFO - {'Status': 'Skipped 88_3'}\n",
      "2025-04-11 10:02:16,880 - INFO - {'Status': 'Skipped 89_1'}\n",
      "2025-04-11 10:02:16,881 - INFO - {'Status': 'Skipped 89_2'}\n",
      "2025-04-11 10:02:16,884 - INFO - {'Status': 'Skipped 89_3'}\n",
      "2025-04-11 10:02:16,890 - INFO - {'Status': 'Skipped 90_1'}\n",
      "2025-04-11 10:02:16,891 - INFO - {'Status': 'Skipped 90_2'}\n",
      "2025-04-11 10:02:16,892 - INFO - {'Status': 'Skipped 90_3'}\n",
      "2025-04-11 10:02:16,894 - INFO - {'Status': 'Skipped 91_1'}\n",
      "2025-04-11 10:02:16,899 - INFO - {'Status': 'Skipped 91_2'}\n",
      "2025-04-11 10:02:16,901 - INFO - {'Status': 'Skipped 91_3'}\n",
      "2025-04-11 10:02:16,902 - INFO - {'Status': 'Skipped 92_1'}\n",
      "2025-04-11 10:02:16,904 - INFO - {'Status': 'Skipped 92_2'}\n",
      "2025-04-11 10:02:16,906 - INFO - {'Status': 'Skipped 92_3'}\n",
      "2025-04-11 10:02:16,908 - INFO - {'Status': 'Skipped 93_1'}\n",
      "2025-04-11 10:02:16,911 - INFO - {'Status': 'Skipped 93_2'}\n",
      "2025-04-11 10:02:16,913 - INFO - {'Status': 'Skipped 93_3'}\n",
      "2025-04-11 10:02:16,915 - INFO - {'Status': 'Skipped 94_1'}\n",
      "2025-04-11 10:02:16,917 - INFO - {'Status': 'Skipped 94_2'}\n",
      "2025-04-11 10:02:16,921 - INFO - {'Status': 'Skipped 94_3'}\n",
      "2025-04-11 10:02:16,922 - INFO - {'Status': 'Skipped 95_1'}\n",
      "2025-04-11 10:02:16,925 - INFO - {'Status': 'Skipped 95_2'}\n",
      "2025-04-11 10:02:16,927 - INFO - {'Status': 'Skipped 95_3'}\n",
      "2025-04-11 10:02:16,930 - INFO - {'Status': 'Skipped 96_1'}\n",
      "2025-04-11 10:02:16,931 - INFO - {'Status': 'Skipped 96_2'}\n",
      "2025-04-11 10:02:16,932 - INFO - {'Status': 'Skipped 96_3'}\n",
      "2025-04-11 10:02:16,933 - INFO - {'Status': 'Skipped 97_1'}\n",
      "2025-04-11 10:02:16,935 - INFO - {'Status': 'Skipped 97_2'}\n",
      "2025-04-11 10:02:16,938 - INFO - {'Status': 'Skipped 97_3'}\n",
      "2025-04-11 10:02:16,939 - INFO - {'Status': 'Skipped 98_1'}\n",
      "2025-04-11 10:02:16,940 - INFO - {'Status': 'Skipped 98_2'}\n",
      "2025-04-11 10:02:16,941 - INFO - {'Status': 'Skipped 98_3'}\n",
      "2025-04-11 10:02:16,943 - INFO - {'Status': 'Skipped 99_1'}\n",
      "2025-04-11 10:02:16,944 - INFO - {'Status': 'Skipped 99_2'}\n",
      "2025-04-11 10:02:16,945 - INFO - {'Status': 'Skipped 99_3'}\n",
      "2025-04-11 10:02:16,947 - INFO - {'Status': 'Skipped 100_1'}\n",
      "2025-04-11 10:02:16,948 - INFO - {'Status': 'Skipped 100_2'}\n",
      "2025-04-11 10:02:16,949 - INFO - {'Status': 'Skipped 100_3'}\n",
      "2025-04-11 10:02:16,950 - INFO - {'Status': 'Skipped 101_1'}\n",
      "2025-04-11 10:02:16,951 - INFO - {'Status': 'Skipped 101_2'}\n",
      "2025-04-11 10:02:16,952 - INFO - {'Status': 'Skipped 101_3'}\n",
      "2025-04-11 10:02:16,954 - INFO - {'Status': 'Skipped 102_1'}\n",
      "2025-04-11 10:02:16,956 - INFO - {'Status': 'Skipped 102_2'}\n",
      "2025-04-11 10:02:16,957 - INFO - {'Status': 'Skipped 102_3'}\n",
      "2025-04-11 10:02:16,958 - INFO - {'Status': 'Skipped 103_1'}\n",
      "2025-04-11 10:02:16,962 - INFO - {'Status': 'Skipped 103_2'}\n",
      "2025-04-11 10:02:16,964 - INFO - {'Status': 'Skipped 103_3'}\n",
      "2025-04-11 10:02:16,971 - INFO - {'Status': 'Skipped 104_1'}\n",
      "2025-04-11 10:02:16,976 - INFO - {'Status': 'Skipped 104_2'}\n",
      "2025-04-11 10:02:16,977 - INFO - {'Status': 'Skipped 104_3'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105_1: ✅ Original query executed successfully!\n",
      "105_2: ✅ Original query executed successfully!\n",
      "105_3: ✅ Original query executed successfully!\n",
      "106_1: ✅ Original query executed successfully!\n",
      "Processing... question 106_2 Retry attempt: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:02:18,668 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 1):\n",
      "WITH managers AS (\n",
      "  SELECT DISTINCT manager_id \n",
      "  FROM employees \n",
      "  WHERE manager_id IS NOT NULL AND active = TRUE\n",
      "),\n",
      "department_stats AS (\n",
      "  SELECT \n",
      "    organizations.name AS department,\n",
      "    COUNT(DISTINCT CASE WHEN employees.id IN (SELECT manager_id FROM managers) THEN employees.id END) AS manager_count,\n",
      "    COUNT(DISTINCT employees.id) AS total_employees\n",
      "  FROM employees\n",
      "  JOIN employment_statuses ON employees.id = employment_statuses.employee_id\n",
      "  JOIN organizations ON employment_statuses.organization_id = organizations.id\n",
      "  WHERE employees.active = TRUE\n",
      "    AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "    AND employment_statuses.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "    AND employment_statuses.location_id IN ('[LOCATION_IDS]')\n",
      "  GROUP BY organizations.name\n",
      ")\n",
      "SELECT \n",
      "  department,\n",
      "  manager_count,\n",
      "  total_employees - manager_count AS non_manager_count,\n",
      "  ROUND(manager_count / NULLIF((total_employees - manager_count), 0), 2) AS manager_to_non_manager_ratio\n",
      "FROM department_stats\n",
      "ORDER BY manager_to_non_manager_ratio DESC;\n",
      "\n",
      "Trying candidate 1\n",
      "✅ Candidate 1 executed successfully!\n",
      "106_3: ⚠️ Skipped due to column not found error.\n",
      "107_1: ✅ Original query executed successfully!\n",
      "Processing... question 107_2 Retry attempt: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:03:10,507 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 1):\n",
      "WITH company_avg AS (\n",
      "    SELECT AVG(attendance_detail_recapitulations.paid_overtime/3600000) AS avg_overtime\n",
      "    FROM attendance_detail_recapitulations\n",
      "    JOIN employment_statuses ON attendance_detail_recapitulations.employee_id = employment_statuses.employee_id\n",
      "    WHERE attendance_detail_recapitulations.date BETWEEN DATE_SUB(STR_TO_DATE('11 April 2025', '%d %M %Y'), INTERVAL 3 MONTH) AND STR_TO_DATE('11 April 2025', '%d %M %Y')\n",
      "    AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "    AND employment_statuses.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "    AND employment_statuses.location_id IN ('[LOCATION_IDS]')\n",
      "),\n",
      "dept_stats AS (\n",
      "    SELECT \n",
      "        organizations.name AS department,\n",
      "        COUNT(DISTINCT attendance_detail_recapitulations.employee_id) AS total_employees,\n",
      "        SUM(CASE WHEN (attendance_detail_recapitulations.paid_overtime/3600000) > (SELECT avg_overtime FROM company_avg) THEN 1 ELSE 0 END) AS above_avg_employees\n",
      "    FROM \n",
      "        attendance_detail_recapitulations\n",
      "    JOIN \n",
      "        employment_statuses ON attendance_detail_recapitulations.employee_id = employment_statuses.employee_id\n",
      "    JOIN \n",
      "        organizations ON employment_statuses.organization_id = organizations.id\n",
      "    WHERE \n",
      "        attendance_detail_recapitulations.date BETWEEN DATE_SUB(STR_TO_DATE('11 April 2025', '%d %M %Y'), INTERVAL 3 MONTH) AND STR_TO_DATE('11 April 2025', '%d %M %Y')\n",
      "        AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND employment_statuses.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND employment_statuses.location_id IN ('[LOCATION_IDS]')\n",
      "    GROUP BY \n",
      "        organizations.name\n",
      ")\n",
      "SELECT \n",
      "    department,\n",
      "    total_employees,\n",
      "    above_avg_employees,\n",
      "    ROUND((above_avg_employees/total_employees)*100, 2) AS percentage_above_avg\n",
      "FROM \n",
      "    dept_stats\n",
      "ORDER BY \n",
      "    percentage_above_avg DESC;\n",
      "\n",
      "Trying candidate 1\n",
      "❌ Candidate 1 failed with error: Error executing query: 1111 (HY000): Invalid use of group function\n",
      "WITH employee_overtime AS (\n",
      "    SELECT \n",
      "        attendance_detail_recapitulations.employee_id,\n",
      "        employment_statuses.organization_id,\n",
      "        AVG(attendance_detail_recapitulations.paid_overtime/3600000) AS avg_employee_overtime\n",
      "    FROM \n",
      "        attendance_detail_recapitulations\n",
      "    JOIN \n",
      "        employment_statuses ON attendance_detail_recapitulations.employee_id = employment_statuses.employee_id\n",
      "    WHERE \n",
      "        attendance_detail_recapitulations.date BETWEEN DATE_SUB(STR_TO_DATE('11 April 2025', '%d %M %Y'), INTERVAL 3 MONTH) AND STR_TO_DATE('11 April 2025', '%d %M %Y')\n",
      "        AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND employment_statuses.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND employment_statuses.location_id IN ('[LOCATION_IDS]')\n",
      "    GROUP BY \n",
      "        attendance_detail_recapitulations.employee_id, employment_statuses.organization_id\n",
      "),\n",
      "company_avg AS (\n",
      "    SELECT AVG(avg_employee_overtime) AS avg_overtime\n",
      "    FROM employee_overtime\n",
      "),\n",
      "dept_stats AS (\n",
      "    SELECT \n",
      "        organizations.name AS department,\n",
      "        COUNT(DISTINCT employee_overtime.employee_id) AS total_employees,\n",
      "        SUM(CASE WHEN employee_overtime.avg_employee_overtime > (SELECT avg_overtime FROM company_avg) THEN 1 ELSE 0 END) AS above_avg_employees\n",
      "    FROM \n",
      "        employee_overtime\n",
      "    JOIN \n",
      "        organizations ON employee_overtime.organization_id = organizations.id\n",
      "    GROUP BY \n",
      "        organizations.name\n",
      ")\n",
      "SELECT \n",
      "    department,\n",
      "    total_employees,\n",
      "    above_avg_employees,\n",
      "    ROUND((above_avg_employees/total_employees)*100, 2) AS percentage_above_avg\n",
      "FROM \n",
      "    dept_stats\n",
      "ORDER BY \n",
      "    percentage_above_avg DESC;\n",
      "\n",
      "Trying candidate 2\n",
      "❌ Candidate 2 failed with error: Error executing query: 1111 (HY000): Invalid use of group function\n",
      "WITH employee_overtime AS (\n",
      "    SELECT \n",
      "        attendance_detail_recapitulations.employee_id,\n",
      "        employment_statuses.organization_id,\n",
      "        SUM(attendance_detail_recapitulations.paid_overtime)/3600000 AS total_overtime_hours\n",
      "    FROM \n",
      "        attendance_detail_recapitulations\n",
      "    JOIN \n",
      "        employment_statuses ON attendance_detail_recapitulations.employee_id = employment_statuses.employee_id\n",
      "    WHERE \n",
      "        attendance_detail_recapitulations.date BETWEEN DATE_SUB(STR_TO_DATE('11 April 2025', '%d %M %Y'), INTERVAL 3 MONTH) AND STR_TO_DATE('11 April 2025', '%d %M %Y')\n",
      "        AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND employment_statuses.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND employment_statuses.location_id IN ('[LOCATION_IDS]')\n",
      "    GROUP BY \n",
      "        attendance_detail_recapitulations.employee_id, employment_statuses.organization_id\n",
      "),\n",
      "company_avg AS (\n",
      "    SELECT AVG(total_overtime_hours) AS avg_overtime\n",
      "    FROM employee_overtime\n",
      "),\n",
      "dept_stats AS (\n",
      "    SELECT \n",
      "        organizations.name AS department,\n",
      "        COUNT(DISTINCT employee_overtime.employee_id) AS total_employees,\n",
      "        SUM(CASE WHEN employee_overtime.total_overtime_hours > (SELECT avg_overtime FROM company_avg) THEN 1 ELSE 0 END) AS above_avg_employees\n",
      "    FROM \n",
      "        employee_overtime\n",
      "    JOIN \n",
      "        organizations ON employee_overtime.organization_id = organizations.id\n",
      "    GROUP BY \n",
      "        organizations.name\n",
      ")\n",
      "SELECT \n",
      "    department,\n",
      "    total_employees,\n",
      "    above_avg_employees,\n",
      "    ROUND((above_avg_employees/total_employees)*100, 2) AS percentage_above_avg\n",
      "FROM \n",
      "    dept_stats\n",
      "ORDER BY \n",
      "    percentage_above_avg DESC;\n",
      "\n",
      "Trying candidate 3\n",
      "❌ Candidate 3 failed with error: Error executing query: 1111 (HY000): Invalid use of group function\n",
      "No working candidates found. Retrying... (1/3)\n",
      "Processing... question 107_2 Retry attempt: 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:04:21,819 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 2):\n",
      "WITH employee_overtime AS (\n",
      "    SELECT \n",
      "        attendance_detail_recapitulations.employee_id,\n",
      "        employment_statuses.organization_id,\n",
      "        SUM(attendance_detail_recapitulations.paid_overtime)/3600000 AS total_overtime_hours\n",
      "    FROM \n",
      "        attendance_detail_recapitulations\n",
      "    JOIN \n",
      "        employment_statuses ON attendance_detail_recapitulations.employee_id = employment_statuses.employee_id\n",
      "    WHERE \n",
      "        attendance_detail_recapitulations.date BETWEEN DATE_SUB(STR_TO_DATE('11 April 2025', '%d %M %Y'), INTERVAL 3 MONTH) AND STR_TO_DATE('11 April 2025', '%d %M %Y')\n",
      "        AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND employment_statuses.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND employment_statuses.location_id IN ('[LOCATION_IDS]')\n",
      "    GROUP BY \n",
      "        attendance_detail_recapitulations.employee_id, employment_statuses.organization_id\n",
      "),\n",
      "company_avg AS (\n",
      "    SELECT AVG(total_overtime_hours) AS avg_overtime\n",
      "    FROM employee_overtime\n",
      "),\n",
      "dept_stats AS (\n",
      "    SELECT \n",
      "        organizations.name AS department,\n",
      "        COUNT(DISTINCT employee_overtime.employee_id) AS total_employees,\n",
      "        SUM(CASE WHEN employee_overtime.total_overtime_hours > (SELECT avg_overtime FROM company_avg) THEN 1 ELSE 0 END) AS above_avg_employees\n",
      "    FROM \n",
      "        employee_overtime\n",
      "    JOIN \n",
      "        organizations ON employee_overtime.organization_id = organizations.id\n",
      "    GROUP BY \n",
      "        organizations.name\n",
      ")\n",
      "SELECT \n",
      "    department,\n",
      "    total_employees,\n",
      "    above_avg_employees,\n",
      "    ROUND((above_avg_employees/total_employees)*100, 2) AS percentage_above_avg\n",
      "FROM \n",
      "    dept_stats\n",
      "ORDER BY \n",
      "    percentage_above_avg DESC;\n",
      "\n",
      "Trying candidate 1\n",
      "❌ Candidate 1 failed with error: Error executing query: 1111 (HY000): Invalid use of group function\n",
      "WITH employee_overtime AS (\n",
      "    SELECT \n",
      "        attendance_detail_recapitulations.employee_id,\n",
      "        employment_statuses.organization_id,\n",
      "        SUM(attendance_detail_recapitulations.paid_overtime)/3600000 AS total_overtime_hours\n",
      "    FROM \n",
      "        attendance_detail_recapitulations\n",
      "    JOIN \n",
      "        employment_statuses ON attendance_detail_recapitulations.employee_id = employment_statuses.employee_id\n",
      "    WHERE \n",
      "        attendance_detail_recapitulations.date BETWEEN DATE_SUB(STR_TO_DATE('11 April 2025', '%d %M %Y'), INTERVAL 3 MONTH) AND STR_TO_DATE('11 April 2025', '%d %M %Y')\n",
      "        AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND employment_statuses.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND employment_statuses.location_id IN ('[LOCATION_IDS]')\n",
      "    GROUP BY \n",
      "        attendance_detail_recapitulations.employee_id, employment_statuses.organization_id\n",
      "),\n",
      "company_avg AS (\n",
      "    SELECT AVG(total_overtime_hours) AS avg_overtime\n",
      "    FROM employee_overtime\n",
      "),\n",
      "dept_stats AS (\n",
      "    SELECT \n",
      "        organizations.name AS department,\n",
      "        COUNT(DISTINCT employee_overtime.employee_id) AS total_employees,\n",
      "        SUM(CASE WHEN employee_overtime.total_overtime_hours > (SELECT avg_overtime FROM company_avg) THEN 1 ELSE 0 END) AS above_avg_employees\n",
      "    FROM \n",
      "        employee_overtime\n",
      "    JOIN \n",
      "        organizations ON employee_overtime.organization_id = organizations.id\n",
      "    GROUP BY \n",
      "        organizations.name\n",
      ")\n",
      "SELECT \n",
      "    department,\n",
      "    total_employees,\n",
      "    above_avg_employees,\n",
      "    ROUND((above_avg_employees/total_employees)*100, 2) AS percentage_above_avg\n",
      "FROM \n",
      "    dept_stats\n",
      "ORDER BY \n",
      "    percentage_above_avg DESC;\n",
      "\n",
      "Trying candidate 2\n",
      "❌ Candidate 2 failed with error: Error executing query: 1111 (HY000): Invalid use of group function\n",
      "WITH employee_overtime AS (\n",
      "    SELECT \n",
      "        attendance_detail_recapitulations.employee_id,\n",
      "        employment_statuses.organization_id,\n",
      "        SUM(attendance_detail_recapitulations.paid_overtime)/3600000 AS total_overtime_hours\n",
      "    FROM \n",
      "        attendance_detail_recapitulations\n",
      "    JOIN \n",
      "        employment_statuses ON attendance_detail_recapitulations.employee_id = employment_statuses.employee_id\n",
      "    WHERE \n",
      "        attendance_detail_recapitulations.date BETWEEN DATE_SUB(STR_TO_DATE('11 April 2025', '%d %M %Y'), INTERVAL 3 MONTH) AND STR_TO_DATE('11 April 2025', '%d %M %Y')\n",
      "        AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND employment_statuses.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND employment_statuses.location_id IN ('[LOCATION_IDS]')\n",
      "    GROUP BY \n",
      "        attendance_detail_recapitulations.employee_id, employment_statuses.organization_id\n",
      "),\n",
      "company_avg AS (\n",
      "    SELECT AVG(total_overtime_hours) AS avg_overtime\n",
      "    FROM employee_overtime\n",
      "),\n",
      "dept_stats AS (\n",
      "    SELECT \n",
      "        organizations.name AS department,\n",
      "        COUNT(DISTINCT employee_overtime.employee_id) AS total_employees,\n",
      "        SUM(CASE WHEN employee_overtime.total_overtime_hours > (SELECT avg_overtime FROM company_avg) THEN 1 ELSE 0 END) AS above_avg_employees\n",
      "    FROM \n",
      "        employee_overtime\n",
      "    JOIN \n",
      "        organizations ON employee_overtime.organization_id = organizations.id\n",
      "    GROUP BY \n",
      "        organizations.name\n",
      ")\n",
      "SELECT \n",
      "    department,\n",
      "    total_employees,\n",
      "    above_avg_employees,\n",
      "    ROUND((above_avg_employees/total_employees)*100, 2) AS percentage_above_avg\n",
      "FROM \n",
      "    dept_stats\n",
      "ORDER BY \n",
      "    percentage_above_avg DESC;\n",
      "\n",
      "Trying candidate 3\n",
      "❌ Candidate 3 failed with error: Error executing query: 1111 (HY000): Invalid use of group function\n",
      "No working candidates found. Retrying... (2/3)\n",
      "Processing... question 107_2 Retry attempt: 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:05:29,699 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 3):\n",
      "WITH employee_overtime AS (\n",
      "    SELECT \n",
      "        attendance_detail_recapitulations.employee_id,\n",
      "        employment_statuses.organization_id,\n",
      "        SUM(attendance_detail_recapitulations.paid_overtime)/3600000 AS total_overtime_hours\n",
      "    FROM \n",
      "        attendance_detail_recapitulations\n",
      "    JOIN \n",
      "        employment_statuses ON attendance_detail_recapitulations.employee_id = employment_statuses.employee_id\n",
      "    WHERE \n",
      "        attendance_detail_recapitulations.date BETWEEN DATE_SUB(STR_TO_DATE('11 April 2025', '%d %M %Y'), INTERVAL 3 MONTH) AND STR_TO_DATE('11 April 2025', '%d %M %Y')\n",
      "        AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND employment_statuses.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND employment_statuses.location_id IN ('[LOCATION_IDS]')\n",
      "    GROUP BY \n",
      "        attendance_detail_recapitulations.employee_id, employment_statuses.organization_id\n",
      "),\n",
      "company_avg AS (\n",
      "    SELECT AVG(total_overtime_hours) AS avg_overtime\n",
      "    FROM employee_overtime\n",
      "),\n",
      "dept_stats AS (\n",
      "    SELECT \n",
      "        organizations.name AS department,\n",
      "        COUNT(DISTINCT employee_overtime.employee_id) AS total_employees,\n",
      "        SUM(CASE WHEN employee_overtime.total_overtime_hours > (SELECT avg_overtime FROM company_avg) THEN 1 ELSE 0 END) AS above_avg_employees\n",
      "    FROM \n",
      "        employee_overtime\n",
      "    JOIN \n",
      "        organizations ON employee_overtime.organization_id = organizations.id\n",
      "    GROUP BY \n",
      "        organizations.name\n",
      ")\n",
      "SELECT \n",
      "    department,\n",
      "    total_employees,\n",
      "    above_avg_employees,\n",
      "    ROUND((above_avg_employees/total_employees)*100, 2) AS percentage_above_avg\n",
      "FROM \n",
      "    dept_stats\n",
      "ORDER BY \n",
      "    percentage_above_avg DESC;\n",
      "\n",
      "Trying candidate 1\n",
      "❌ Candidate 1 failed with error: Error executing query: 1111 (HY000): Invalid use of group function\n",
      "WITH employee_overtime AS (\n",
      "    SELECT \n",
      "        attendance_detail_recapitulations.employee_id,\n",
      "        employment_statuses.organization_id,\n",
      "        SUM(attendance_detail_recapitulations.paid_overtime)/3600000 AS total_overtime_hours\n",
      "    FROM \n",
      "        attendance_detail_recapitulations\n",
      "    JOIN \n",
      "        employment_statuses ON attendance_detail_recapitulations.employee_id = employment_statuses.employee_id\n",
      "    WHERE \n",
      "        attendance_detail_recapitulations.date BETWEEN DATE_SUB(STR_TO_DATE('11 April 2025', '%d %M %Y'), INTERVAL 3 MONTH) AND STR_TO_DATE('11 April 2025', '%d %M %Y')\n",
      "        AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND employment_statuses.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND employment_statuses.location_id IN ('[LOCATION_IDS]')\n",
      "    GROUP BY \n",
      "        attendance_detail_recapitulations.employee_id, employment_statuses.organization_id\n",
      "),\n",
      "company_avg AS (\n",
      "    SELECT AVG(total_overtime_hours) AS avg_overtime\n",
      "    FROM employee_overtime\n",
      "),\n",
      "dept_stats AS (\n",
      "    SELECT \n",
      "        organizations.name AS department,\n",
      "        COUNT(DISTINCT employee_overtime.employee_id) AS total_employees,\n",
      "        SUM(CASE WHEN employee_overtime.total_overtime_hours > (SELECT avg_overtime FROM company_avg) THEN 1 ELSE 0 END) AS above_avg_employees\n",
      "    FROM \n",
      "        employee_overtime\n",
      "    JOIN \n",
      "        organizations ON employee_overtime.organization_id = organizations.id\n",
      "    GROUP BY \n",
      "        organizations.name\n",
      ")\n",
      "SELECT \n",
      "    department,\n",
      "    total_employees,\n",
      "    above_avg_employees,\n",
      "    ROUND((above_avg_employees/total_employees)*100, 2) AS percentage_above_avg\n",
      "FROM \n",
      "    dept_stats\n",
      "ORDER BY \n",
      "    percentage_above_avg DESC;\n",
      "\n",
      "Trying candidate 2\n",
      "❌ Candidate 2 failed with error: Error executing query: 1111 (HY000): Invalid use of group function\n",
      "WITH employee_overtime AS (\n",
      "    SELECT \n",
      "        attendance_detail_recapitulations.employee_id,\n",
      "        employment_statuses.organization_id,\n",
      "        SUM(attendance_detail_recapitulations.paid_overtime)/3600000 AS total_overtime_hours\n",
      "    FROM \n",
      "        attendance_detail_recapitulations\n",
      "    JOIN \n",
      "        employment_statuses ON attendance_detail_recapitulations.employee_id = employment_statuses.employee_id\n",
      "    WHERE \n",
      "        attendance_detail_recapitulations.date BETWEEN DATE_SUB(STR_TO_DATE('11 April 2025', '%d %M %Y'), INTERVAL 3 MONTH) AND STR_TO_DATE('11 April 2025', '%d %M %Y')\n",
      "        AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND employment_statuses.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND employment_statuses.location_id IN ('[LOCATION_IDS]')\n",
      "    GROUP BY \n",
      "        attendance_detail_recapitulations.employee_id, employment_statuses.organization_id\n",
      "),\n",
      "company_avg AS (\n",
      "    SELECT AVG(total_overtime_hours) AS avg_overtime\n",
      "    FROM employee_overtime\n",
      "),\n",
      "dept_stats AS (\n",
      "    SELECT \n",
      "        organizations.name AS department,\n",
      "        COUNT(DISTINCT employee_overtime.employee_id) AS total_employees,\n",
      "        SUM(CASE WHEN employee_overtime.total_overtime_hours > (SELECT avg_overtime FROM company_avg) THEN 1 ELSE 0 END) AS above_avg_employees\n",
      "    FROM \n",
      "        employee_overtime\n",
      "    JOIN \n",
      "        organizations ON employee_overtime.organization_id = organizations.id\n",
      "    GROUP BY \n",
      "        organizations.name\n",
      ")\n",
      "SELECT \n",
      "    department,\n",
      "    total_employees,\n",
      "    above_avg_employees,\n",
      "    ROUND((above_avg_employees/total_employees)*100, 2) AS percentage_above_avg\n",
      "FROM \n",
      "    dept_stats\n",
      "ORDER BY \n",
      "    percentage_above_avg DESC;\n",
      "\n",
      "Trying candidate 3\n",
      "❌ Candidate 3 failed with error: Error executing query: 1111 (HY000): Invalid use of group function\n",
      "No working candidates found. Retrying... (3/3)\n",
      "⚠️ Failed to find working SQL query after 3 attempts.\n",
      "107_3: ✅ Original query executed successfully!\n",
      "Processing... question 108_1 Retry attempt: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:06:37,666 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 1):\n",
      "WITH status_changes AS (\n",
      "    SELECT \n",
      "        esh.employee_id,\n",
      "        esh.effective_date,\n",
      "        esh.job_level_id,\n",
      "        esh.organization_id,\n",
      "        o.name AS department,\n",
      "        ed.gender,\n",
      "        LAG(esh.job_level_id) OVER (PARTITION BY esh.employee_id ORDER BY esh.effective_date) AS prev_job_level,\n",
      "        LAG(esh.organization_id) OVER (PARTITION BY esh.employee_id ORDER BY esh.effective_date) AS prev_organization\n",
      "    FROM employment_status_histories esh\n",
      "    JOIN organizations o ON esh.organization_id = o.id\n",
      "    JOIN employee_details ed ON esh.employee_id = ed.employee_id\n",
      "    JOIN employment_statuses es ON esh.employee_id = es.employee_id\n",
      "    WHERE esh.effective_date >= DATE_SUB(CURRENT_DATE, INTERVAL 2 YEAR)\n",
      "    AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "    AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "    AND es.location_id IN ('[LOCATION_IDS]')\n",
      ")\n",
      "SELECT \n",
      "    department,\n",
      "    gender,\n",
      "    CASE \n",
      "        WHEN job_level_id > prev_job_level THEN 'Promosi'\n",
      "        WHEN job_level_id < prev_job_level THEN 'Demosi'\n",
      "        WHEN organization_id != prev_organization THEN 'Transfer'\n",
      "        ELSE 'Tidak ada perubahan'\n",
      "    END AS jenis_perubahan,\n",
      "    COUNT(*) AS jumlah\n",
      "FROM status_changes\n",
      "WHERE prev_job_level IS NOT NULL\n",
      "GROUP BY department, gender, jenis_perubahan\n",
      "ORDER BY department, gender, jenis_perubahan;\n",
      "\n",
      "Trying candidate 1\n",
      "❌ Candidate 1 failed with error: Error executing query: 1054 (42S22): Unknown column 'ed.gender' in 'field list'\n",
      "WITH status_changes AS (\n",
      "    SELECT \n",
      "        esh.employee_id,\n",
      "        esh.effective_date,\n",
      "        jl1.name AS current_job_level,\n",
      "        jl2.name AS previous_job_level,\n",
      "        o1.name AS current_department,\n",
      "        o2.name AS previous_department,\n",
      "        ed.gender,\n",
      "        LAG(esh.job_level_id) OVER (PARTITION BY esh.employee_id ORDER BY esh.effective_date) AS prev_job_level_id,\n",
      "        LAG(esh.organization_id) OVER (PARTITION BY esh.employee_id ORDER BY esh.effective_date) AS prev_organization_id\n",
      "    FROM employment_status_histories esh\n",
      "    JOIN organizations o1 ON esh.organization_id = o1.id\n",
      "    JOIN job_levels jl1 ON esh.job_level_id = jl1.id\n",
      "    JOIN employee_details ed ON esh.employee_id = ed.employee_id\n",
      "    JOIN employment_statuses es ON esh.employee_id = es.employee_id\n",
      "    LEFT JOIN organizations o2 ON esh.organization_id = o2.id\n",
      "    LEFT JOIN job_levels jl2 ON esh.job_level_id = jl2.id\n",
      "    WHERE esh.effective_date >= DATE_SUB(CURRENT_DATE, INTERVAL 2 YEAR)\n",
      "    AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "    AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "    AND es.location_id IN ('[LOCATION_IDS]')\n",
      ")\n",
      "SELECT \n",
      "    current_department AS departemen,\n",
      "    gender AS jenis_kelamin,\n",
      "    CASE \n",
      "        WHEN current_job_level > previous_job_level THEN 'Promosi'\n",
      "        WHEN current_job_level < previous_job_level THEN 'Demosi'\n",
      "        WHEN current_department != previous_department THEN 'Transfer'\n",
      "        ELSE 'Tidak ada perubahan'\n",
      "    END AS jenis_perubahan,\n",
      "    COUNT(*) AS jumlah\n",
      "FROM status_changes\n",
      "WHERE prev_job_level_id IS NOT NULL\n",
      "GROUP BY departemen, jenis_kelamin, jenis_perubahan\n",
      "ORDER BY departemen, jenis_kelamin, jenis_perubahan;\n",
      "\n",
      "Trying candidate 2\n",
      "❌ Candidate 2 failed with error: Error executing query: 1054 (42S22): Unknown column 'ed.gender' in 'field list'\n",
      "WITH employee_changes AS (\n",
      "    SELECT \n",
      "        esh.employee_id,\n",
      "        e.name AS employee_name,\n",
      "        esh.effective_date,\n",
      "        jl_current.name AS current_level,\n",
      "        jl_previous.name AS previous_level,\n",
      "        org_current.name AS current_dept,\n",
      "        org_previous.name AS previous_dept,\n",
      "        ed.gender,\n",
      "        ROW_NUMBER() OVER (PARTITION BY esh.employee_id ORDER BY esh.effective_date DESC) AS rn\n",
      "    FROM employment_status_histories esh\n",
      "    JOIN employment_status_histories esh_prev ON \n",
      "        esh.employee_id = esh_prev.employee_id AND \n",
      "        esh.effective_date > esh_prev.effective_date\n",
      "    JOIN organizations org_current ON esh.organization_id = org_current.id\n",
      "    JOIN organizations org_previous ON esh_prev.organization_id = org_previous.id\n",
      "    JOIN job_levels jl_current ON esh.job_level_id = jl_current.id\n",
      "    JOIN job_levels jl_previous ON esh_prev.job_level_id = jl_previous.id\n",
      "    JOIN employee_details ed ON esh.employee_id = ed.employee_id\n",
      "    JOIN employees e ON esh.employee_id = e.id\n",
      "    JOIN employment_statuses es ON esh.employee_id = es.employee_id\n",
      "    WHERE esh.effective_date >= DATE_SUB(CURRENT_DATE, INTERVAL 2 YEAR)\n",
      "    AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "    AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "    AND es.location_id IN ('[LOCATION_IDS]')\n",
      ")\n",
      "SELECT \n",
      "    current_dept AS departemen,\n",
      "    gender AS jenis_kelamin,\n",
      "    CASE \n",
      "        WHEN current_level > previous_level THEN 'Promosi'\n",
      "        WHEN current_level < previous_level THEN 'Demosi'\n",
      "        WHEN current_dept != previous_dept THEN 'Transfer'\n",
      "    END AS perubahan_status,\n",
      "    COUNT(*) AS jumlah_karyawan\n",
      "FROM employee_changes\n",
      "WHERE rn = 1\n",
      "GROUP BY departemen, jenis_kelamin, perubahan_status\n",
      "ORDER BY departemen, jenis_kelamin, perubahan_status;\n",
      "\n",
      "Trying candidate 3\n",
      "❌ Candidate 3 failed with error: Error executing query: 1054 (42S22): Unknown column 'ed.gender' in 'field list'\n",
      "No working candidates found. Retrying... (1/3)\n",
      "Processing... question 108_1 Retry attempt: 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:07:46,740 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 2):\n",
      "WITH employee_changes AS (\n",
      "    SELECT \n",
      "        esh.employee_id,\n",
      "        e.name AS employee_name,\n",
      "        esh.effective_date,\n",
      "        jl_current.name AS current_level,\n",
      "        jl_previous.name AS previous_level,\n",
      "        org_current.name AS current_dept,\n",
      "        org_previous.name AS previous_dept,\n",
      "        ed.gender AS jenis_kelamin,\n",
      "        ROW_NUMBER() OVER (PARTITION BY esh.employee_id ORDER BY esh.effective_date DESC) AS rn\n",
      "    FROM employment_status_histories esh\n",
      "    JOIN employment_status_histories esh_prev ON \n",
      "        esh.employee_id = esh_prev.employee_id AND \n",
      "        esh.effective_date > esh_prev.effective_date\n",
      "    JOIN organizations org_current ON esh.organization_id = org_current.id\n",
      "    JOIN organizations org_previous ON esh_prev.organization_id = org_previous.id\n",
      "    JOIN job_levels jl_current ON esh.job_level_id = jl_current.id\n",
      "    JOIN job_levels jl_previous ON esh_prev.job_level_id = jl_previous.id\n",
      "    JOIN employees e ON esh.employee_id = e.id\n",
      "    JOIN employee_details ed ON e.id = ed.employee_id\n",
      "    JOIN employment_statuses es ON esh.employee_id = es.employee_id\n",
      "    WHERE esh.effective_date >= DATE_SUB(CURRENT_DATE, INTERVAL 2 YEAR)\n",
      "    AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "    AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "    AND es.location_id IN ('[LOCATION_IDS]')\n",
      ")\n",
      "SELECT \n",
      "    current_dept AS departemen,\n",
      "    jenis_kelamin,\n",
      "    CASE \n",
      "        WHEN current_level > previous_level THEN 'Promosi'\n",
      "        WHEN current_level < previous_level THEN 'Demosi'\n",
      "        WHEN current_dept != previous_dept THEN 'Transfer'\n",
      "    END AS perubahan_status,\n",
      "    COUNT(*) AS jumlah_karyawan\n",
      "FROM employee_changes\n",
      "WHERE rn = 1\n",
      "GROUP BY departemen, jenis_kelamin, perubahan_status\n",
      "ORDER BY departemen, jenis_kelamin, perubahan_status;\n",
      "\n",
      "Trying candidate 1\n",
      "❌ Candidate 1 failed with error: Error executing query: 1054 (42S22): Unknown column 'ed.gender' in 'field list'\n",
      "WITH employee_changes AS (\n",
      "    SELECT \n",
      "        esh.employee_id,\n",
      "        e.name AS employee_name,\n",
      "        esh.effective_date,\n",
      "        jl_current.name AS current_level,\n",
      "        jl_previous.name AS previous_level,\n",
      "        org_current.name AS current_dept,\n",
      "        org_previous.name AS previous_dept,\n",
      "        CASE \n",
      "            WHEN ed.gender = 'MALE' THEN 'Laki-laki'\n",
      "            WHEN ed.gender = 'FEMALE' THEN 'Perempuan'\n",
      "            ELSE 'Tidak Diketahui'\n",
      "        END AS jenis_kelamin,\n",
      "        ROW_NUMBER() OVER (PARTITION BY esh.employee_id ORDER BY esh.effective_date DESC) AS rn\n",
      "    FROM employment_status_histories esh\n",
      "    JOIN employment_status_histories esh_prev ON \n",
      "        esh.employee_id = esh_prev.employee_id AND \n",
      "        esh.effective_date > esh_prev.effective_date\n",
      "    JOIN organizations org_current ON esh.organization_id = org_current.id\n",
      "    JOIN organizations org_previous ON esh_prev.organization_id = org_previous.id\n",
      "    JOIN job_levels jl_current ON esh.job_level_id = jl_current.id\n",
      "    JOIN job_levels jl_previous ON esh_prev.job_level_id = jl_previous.id\n",
      "    JOIN employees e ON esh.employee_id = e.id\n",
      "    JOIN employee_details ed ON e.id = ed.employee_id\n",
      "    JOIN employment_statuses es ON esh.employee_id = es.employee_id\n",
      "    WHERE esh.effective_date >= DATE_SUB(CURRENT_DATE, INTERVAL 2 YEAR)\n",
      "    AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "    AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "    AND es.location_id IN ('[LOCATION_IDS]')\n",
      ")\n",
      "SELECT \n",
      "    current_dept AS departemen,\n",
      "    jenis_kelamin,\n",
      "    CASE \n",
      "        WHEN current_level > previous_level THEN 'Promosi'\n",
      "        WHEN current_level < previous_level THEN 'Demosi'\n",
      "        WHEN current_dept != previous_dept THEN 'Transfer'\n",
      "    END AS perubahan_status,\n",
      "    COUNT(*) AS jumlah_karyawan\n",
      "FROM employee_changes\n",
      "WHERE rn = 1\n",
      "GROUP BY departemen, jenis_kelamin, perubahan_status\n",
      "ORDER BY departemen, jenis_kelamin, perubahan_status;\n",
      "\n",
      "Trying candidate 2\n",
      "❌ Candidate 2 failed with error: Error executing query: 1054 (42S22): Unknown column 'ed.gender' in 'field list'\n",
      "WITH employee_status_changes AS (\n",
      "    SELECT \n",
      "        esh.employee_id,\n",
      "        e.name AS employee_name,\n",
      "        esh.effective_date,\n",
      "        jl_current.name AS current_level,\n",
      "        jl_previous.name AS previous_level,\n",
      "        org_current.name AS current_dept,\n",
      "        org_previous.name AS previous_dept,\n",
      "        ed.gender AS jenis_kelamin,\n",
      "        ROW_NUMBER() OVER (PARTITION BY esh.employee_id ORDER BY esh.effective_date DESC) AS rn\n",
      "    FROM employment_status_histories esh\n",
      "    JOIN LATERAL (\n",
      "        SELECT * FROM employment_status_histories esh_prev\n",
      "        WHERE esh_prev.employee_id = esh.employee_id\n",
      "        AND esh_prev.effective_date < esh.effective_date\n",
      "        ORDER BY esh_prev.effective_date DESC\n",
      "        LIMIT 1\n",
      "    ) esh_prev ON 1=1\n",
      "    JOIN organizations org_current ON esh.organization_id = org_current.id\n",
      "    JOIN organizations org_previous ON esh_prev.organization_id = org_previous.id\n",
      "    JOIN job_levels jl_current ON esh.job_level_id = jl_current.id\n",
      "    JOIN job_levels jl_previous ON esh_prev.job_level_id = jl_previous.id\n",
      "    JOIN employees e ON esh.employee_id = e.id\n",
      "    JOIN employee_details ed ON e.id = ed.employee_id\n",
      "    JOIN employment_statuses es ON esh.employee_id = es.employee_id\n",
      "    WHERE esh.effective_date >= DATE_SUB(CURRENT_DATE, INTERVAL 2 YEAR)\n",
      "    AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "    AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "    AND es.location_id IN ('[LOCATION_IDS]')\n",
      ")\n",
      "SELECT \n",
      "    current_dept AS departemen,\n",
      "    jenis_kelamin,\n",
      "    CASE \n",
      "        WHEN current_level > previous_level THEN 'Promosi'\n",
      "        WHEN current_level < previous_level THEN 'Demosi'\n",
      "        WHEN current_dept != previous_dept THEN 'Transfer'\n",
      "    END AS perubahan_status,\n",
      "    COUNT(*) AS jumlah_karyawan\n",
      "FROM employee_status_changes\n",
      "WHERE rn = 1\n",
      "GROUP BY departemen, jenis_kelamin, perubahan_status\n",
      "ORDER BY departemen, jenis_kelamin, perubahan_status;\n",
      "\n",
      "Trying candidate 3\n",
      "❌ Candidate 3 failed with error: Error executing query: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near '(\n",
      "No working candidates found. Retrying... (2/3)\n",
      "Processing... question 108_1 Retry attempt: 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:09:04,881 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 3):\n",
      "WITH employee_status_changes AS (\n",
      "    SELECT \n",
      "        esh.employee_id,\n",
      "        employees.name AS employee_name,\n",
      "        esh.effective_date,\n",
      "        jl_current.name AS current_level,\n",
      "        jl_previous.name AS previous_level,\n",
      "        org_current.name AS current_dept,\n",
      "        org_previous.name AS previous_dept,\n",
      "        employee_details.gender AS jenis_kelamin,\n",
      "        ROW_NUMBER() OVER (PARTITION BY esh.employee_id ORDER BY esh.effective_date DESC) AS rn\n",
      "    FROM employment_status_histories esh\n",
      "    JOIN (\n",
      "        SELECT employee_id, MAX(effective_date) AS max_prev_date\n",
      "        FROM employment_status_histories\n",
      "        WHERE effective_date < (\n",
      "            SELECT MAX(effective_date) \n",
      "            FROM employment_status_histories esh2 \n",
      "            WHERE esh2.employee_id = employment_status_histories.employee_id\n",
      "        )\n",
      "        GROUP BY employee_id\n",
      "    ) prev_dates ON esh.employee_id = prev_dates.employee_id\n",
      "    JOIN employment_status_histories esh_prev ON esh_prev.employee_id = prev_dates.employee_id \n",
      "        AND esh_prev.effective_date = prev_dates.max_prev_date\n",
      "    JOIN organizations org_current ON esh.organization_id = org_current.id\n",
      "    JOIN organizations org_previous ON esh_prev.organization_id = org_previous.id\n",
      "    JOIN job_levels jl_current ON esh.job_level_id = jl_current.id\n",
      "    JOIN job_levels jl_previous ON esh_prev.job_level_id = jl_previous.id\n",
      "    JOIN employees ON esh.employee_id = employees.id\n",
      "    JOIN employee_details ON employees.id = employee_details.employee_id\n",
      "    JOIN employment_statuses ON esh.employee_id = employment_statuses.employee_id\n",
      "    WHERE esh.effective_date >= DATE_SUB(CURRENT_DATE, INTERVAL 2 YEAR)\n",
      "    AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "    AND employment_statuses.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "    AND employment_statuses.location_id IN ('[LOCATION_IDS]')\n",
      ")\n",
      "SELECT \n",
      "    current_dept AS departemen,\n",
      "    jenis_kelamin,\n",
      "    CASE \n",
      "        WHEN current_level > previous_level THEN 'Promosi'\n",
      "        WHEN current_level < previous_level THEN 'Demosi'\n",
      "        WHEN current_dept != previous_dept THEN 'Transfer'\n",
      "        ELSE 'Tidak Ada Perubahan'\n",
      "    END AS perubahan_status,\n",
      "    COUNT(*) AS jumlah_karyawan\n",
      "FROM employee_status_changes\n",
      "WHERE rn = 1\n",
      "GROUP BY departemen, jenis_kelamin, perubahan_status\n",
      "ORDER BY departemen, jenis_kelamin, perubahan_status;\n",
      "\n",
      "Trying candidate 1\n",
      "❌ Candidate 1 failed with error: Error executing query: 1054 (42S22): Unknown column 'employee_details.gender' in 'field list'\n",
      "WITH ranked_status_changes AS (\n",
      "    SELECT \n",
      "        esh.employee_id,\n",
      "        esh.effective_date,\n",
      "        esh.organization_id,\n",
      "        esh.job_level_id,\n",
      "        ROW_NUMBER() OVER (PARTITION BY esh.employee_id ORDER BY esh.effective_date DESC) AS rn\n",
      "    FROM employment_status_histories esh\n",
      "    JOIN employment_statuses es ON esh.employee_id = es.employee_id\n",
      "    WHERE esh.effective_date >= DATE_SUB(CURRENT_DATE, INTERVAL 2 YEAR)\n",
      "    AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "    AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "    AND es.location_id IN ('[LOCATION_IDS]')\n",
      "),\n",
      "current_status AS (\n",
      "    SELECT * FROM ranked_status_changes WHERE rn = 1\n",
      "),\n",
      "previous_status AS (\n",
      "    SELECT * FROM ranked_status_changes WHERE rn = 2\n",
      ")\n",
      "SELECT \n",
      "    org_current.name AS departemen,\n",
      "    employee_details.gender AS jenis_kelamin,\n",
      "    CASE\n",
      "        WHEN jl_current.level_value > jl_previous.level_value THEN 'Promosi'\n",
      "        WHEN jl_current.level_value < jl_previous.level_value THEN 'Demosi'\n",
      "        WHEN org_current.id != org_previous.id THEN 'Transfer'\n",
      "        ELSE 'Tidak Ada Perubahan'\n",
      "    END AS perubahan_status,\n",
      "    COUNT(DISTINCT cs.employee_id) AS jumlah_karyawan\n",
      "FROM current_status cs\n",
      "LEFT JOIN previous_status ps ON cs.employee_id = ps.employee_id\n",
      "JOIN organizations org_current ON cs.organization_id = org_current.id\n",
      "JOIN organizations org_previous ON ps.organization_id = org_previous.id\n",
      "JOIN job_levels jl_current ON cs.job_level_id = jl_current.id\n",
      "JOIN job_levels jl_previous ON ps.job_level_id = jl_previous.id\n",
      "JOIN employees ON cs.employee_id = employees.id\n",
      "JOIN employee_details ON employees.id = employee_details.employee_id\n",
      "GROUP BY departemen, jenis_kelamin, perubahan_status\n",
      "ORDER BY departemen, jenis_kelamin, perubahan_status;\n",
      "\n",
      "Trying candidate 2\n",
      "❌ Candidate 2 failed with error: Error executing query: 1054 (42S22): Unknown column 'employee_details.gender' in 'field list'\n",
      "WITH status_changes AS (\n",
      "    SELECT \n",
      "        esh.employee_id,\n",
      "        esh.effective_date,\n",
      "        esh.organization_id AS current_org_id,\n",
      "        esh.job_level_id AS current_level_id,\n",
      "        (\n",
      "            SELECT esh2.organization_id \n",
      "            FROM employment_status_histories esh2\n",
      "            WHERE esh2.employee_id = esh.employee_id\n",
      "            AND esh2.effective_date < esh.effective_date\n",
      "            ORDER BY esh2.effective_date DESC\n",
      "            LIMIT 1\n",
      "        ) AS previous_org_id,\n",
      "        (\n",
      "            SELECT esh2.job_level_id \n",
      "            FROM employment_status_histories esh2\n",
      "            WHERE esh2.employee_id = esh.employee_id\n",
      "            AND esh2.effective_date < esh.effective_date\n",
      "            ORDER BY esh2.effective_date DESC\n",
      "            LIMIT 1\n",
      "        ) AS previous_level_id\n",
      "    FROM employment_status_histories esh\n",
      "    JOIN employment_statuses es ON esh.employee_id = es.employee_id\n",
      "    WHERE esh.effective_date >= DATE_SUB(CURRENT_DATE, INTERVAL 2 YEAR)\n",
      "    AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "    AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "    AND es.location_id IN ('[LOCATION_IDS]')\n",
      ")\n",
      "SELECT \n",
      "    org_current.name AS departemen,\n",
      "    employee_details.gender AS jenis_kelamin,\n",
      "    CASE\n",
      "        WHEN jl_current.level_value > jl_previous.level_value THEN 'Promosi'\n",
      "        WHEN jl_current.level_value < jl_previous.level_value THEN 'Demosi'\n",
      "        WHEN org_current.id != org_previous.id THEN 'Transfer'\n",
      "        ELSE 'Tidak Ada Perubahan'\n",
      "    END AS perubahan_status,\n",
      "    COUNT(DISTINCT sc.employee_id) AS jumlah_karyawan\n",
      "FROM status_changes sc\n",
      "JOIN organizations org_current ON sc.current_org_id = org_current.id\n",
      "JOIN organizations org_previous ON sc.previous_org_id = org_previous.id\n",
      "JOIN job_levels jl_current ON sc.current_level_id = jl_current.id\n",
      "JOIN job_levels jl_previous ON sc.previous_level_id = jl_previous.id\n",
      "JOIN employees ON sc.employee_id = employees.id\n",
      "JOIN employee_details ON employees.id = employee_details.employee_id\n",
      "GROUP BY departemen, jenis_kelamin, perubahan_status\n",
      "ORDER BY departemen, jenis_kelamin, perubahan_status;\n",
      "\n",
      "Trying candidate 3\n",
      "❌ Candidate 3 failed with error: Error executing query: 1054 (42S22): Unknown column 'employee_details.gender' in 'field list'\n",
      "No working candidates found. Retrying... (3/3)\n",
      "⚠️ Failed to find working SQL query after 3 attempts.\n",
      "Processing... question 108_2 Retry attempt: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:10:28,329 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 1):\n",
      "WITH promotions AS (\n",
      "    SELECT \n",
      "        employee_id,\n",
      "        COUNT(*) AS promotion_count\n",
      "    FROM (\n",
      "        SELECT \n",
      "            employee_id,\n",
      "            job_level_id,\n",
      "            LAG(job_level_id) OVER (PARTITION BY employee_id ORDER BY effective_date) AS prev_job_level\n",
      "        FROM employment_status_histories\n",
      "        WHERE effective_date >= DATE_SUB(CURRENT_DATE, INTERVAL 3 YEAR)\n",
      "        AND job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "    ) t\n",
      "    WHERE job_level_id > prev_job_level\n",
      "    GROUP BY employee_id\n",
      "),\n",
      "education_levels AS (\n",
      "    SELECT \n",
      "        e.employee_id,\n",
      "        el.name AS education_level\n",
      "    FROM educations e\n",
      "    JOIN education_levels el ON e.education_level_id = el.id\n",
      "    JOIN employment_statuses es ON e.employee_id = es.employee_id\n",
      "    WHERE e.employee_id IN (SELECT employee_id FROM promotions)\n",
      "SELECT \n",
      "    el.education_level,\n",
      "    AVG(p.promotion_count) AS avg_promotions,\n",
      "    COUNT(DISTINCT p.employee_id) AS employee_count\n",
      "FROM promotions p\n",
      "JOIN education_levels el ON p.employee_id = el.employee_id\n",
      "GROUP BY el.education_level\n",
      "ORDER BY avg_promotions DESC;\n",
      "\n",
      "Trying candidate 1\n",
      "❌ Candidate 1 failed with error: Error executing query: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near 'SELECT \n",
      "WITH employee_promotions AS (\n",
      "    SELECT \n",
      "        esh.employee_id,\n",
      "        COUNT(CASE WHEN esh.job_level_id > LAG(esh.job_level_id) OVER (PARTITION BY esh.employee_id ORDER BY esh.effective_date) THEN 1 END) AS promotion_count\n",
      "    FROM employment_status_histories esh\n",
      "    JOIN employment_statuses es ON esh.employee_id = es.employee_id\n",
      "    WHERE esh.effective_date >= DATE_SUB(CURRENT_DATE, INTERVAL 3 YEAR)\n",
      "    GROUP BY esh.employee_id\n",
      "),\n",
      "employee_education AS (\n",
      "    SELECT \n",
      "        e.employee_id,\n",
      "        el.name AS education_level\n",
      "    FROM educations e\n",
      "    JOIN education_levels el ON e.education_level_id = el.id\n",
      "    JOIN employment_statuses es ON e.employee_id = es.employee_id\n",
      ")\n",
      "SELECT \n",
      "    ee.education_level,\n",
      "    AVG(ep.promotion_count) AS avg_promotions,\n",
      "    COUNT(DISTINCT ep.employee_id) AS employee_count\n",
      "FROM employee_promotions ep\n",
      "JOIN employee_education ee ON ep.employee_id = ee.employee_id\n",
      "GROUP BY ee.education_level\n",
      "ORDER BY avg_promotions DESC;\n",
      "\n",
      "Trying candidate 2\n",
      "❌ Candidate 2 failed with error: Error executing query: (pymysql.err.ProgrammingError) (1146, \"Table 'ru4f_time_management.families' doesn't exist\")\n",
      "WITH promotion_data AS (\n",
      "    SELECT \n",
      "        esh.employee_id,\n",
      "        esh.job_level_id,\n",
      "        LAG(esh.job_level_id) OVER (PARTITION BY esh.employee_id ORDER BY esh.effective_date) AS prev_job_level,\n",
      "        esh.effective_date\n",
      "    FROM employment_status_histories esh\n",
      "    JOIN employment_statuses es ON esh.employee_id = es.employee_id\n",
      "    WHERE esh.effective_date >= DATE_SUB(CURRENT_DATE, INTERVAL 3 YEAR)\n",
      "),\n",
      "promotions AS (\n",
      "    SELECT \n",
      "        employee_id,\n",
      "        COUNT(*) AS promotion_count\n",
      "    FROM promotion_data\n",
      "    WHERE job_level_id > prev_job_level\n",
      "    GROUP BY employee_id\n",
      "),\n",
      "education_levels AS (\n",
      "    SELECT \n",
      "        e.employee_id,\n",
      "        el.name AS education_level\n",
      "    FROM educations e\n",
      "    JOIN education_levels el ON e.education_level_id = el.id\n",
      "    JOIN employment_statuses es ON e.employee_id = es.employee_id\n",
      "    WHERE e.employee_id IN (SELECT employee_id FROM promotions)\n",
      ")\n",
      "SELECT \n",
      "    el.education_level,\n",
      "    AVG(p.promotion_count) AS avg_promotions,\n",
      "    COUNT(DISTINCT p.employee_id) AS employee_count\n",
      "FROM promotions p\n",
      "JOIN education_levels el ON p.employee_id = el.employee_id\n",
      "GROUP BY el.education_level\n",
      "ORDER BY avg_promotions DESC;\n",
      "\n",
      "Trying candidate 3\n",
      "❌ Candidate 3 failed with error: Error executing query: (pymysql.err.ProgrammingError) (1146, \"Table 'ru4f_time_management.families' doesn't exist\")\n",
      "No working candidates found. Retrying... (1/3)\n",
      "Processing... question 108_2 Retry attempt: 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:11:15,566 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 2):\n",
      "WITH promotion_data AS (\n",
      "    SELECT \n",
      "        esh.employee_id,\n",
      "        esh.job_level_id,\n",
      "        LAG(esh.job_level_id) OVER (PARTITION BY esh.employee_id ORDER BY esh.effective_date) AS prev_job_level,\n",
      "        esh.effective_date\n",
      "    FROM employment_status_histories esh\n",
      "    JOIN employment_statuses es ON esh.employee_id = es.employee_id\n",
      "    WHERE esh.effective_date >= DATE_SUB(STR_TO_DATE('11 April 2025', '%d %M %Y'), INTERVAL 3 YEAR)\n",
      "    AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "    AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "    AND es.location_id IN ('[LOCATION_IDS]')\n",
      "),\n",
      "promotions AS (\n",
      "    SELECT \n",
      "        employee_id,\n",
      "        COUNT(*) AS promotion_count\n",
      "    FROM promotion_data\n",
      "    WHERE job_level_id > prev_job_level\n",
      "    GROUP BY employee_id\n",
      "),\n",
      "education_levels AS (\n",
      "    SELECT \n",
      "        e.employee_id,\n",
      "        el.name AS education_level\n",
      "    FROM educations e\n",
      "    JOIN education_levels el ON e.education_level_id = el.id\n",
      "    JOIN employment_statuses es ON e.employee_id = es.employee_id\n",
      "    WHERE e.employee_id IN (SELECT employee_id FROM promotions)\n",
      "    AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "    AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "    AND es.location_id IN ('[LOCATION_IDS]')\n",
      ")\n",
      "SELECT \n",
      "    el.education_level,\n",
      "    AVG(p.promotion_count) AS avg_promotions,\n",
      "    COUNT(DISTINCT p.employee_id) AS employee_count\n",
      "FROM promotions p\n",
      "JOIN education_levels el ON p.employee_id = el.employee_id\n",
      "GROUP BY el.education_level\n",
      "ORDER BY avg_promotions DESC;\n",
      "\n",
      "Trying candidate 1\n",
      "❌ Candidate 1 failed with error: Error executing query: (pymysql.err.ProgrammingError) (1146, \"Table 'ru4f_time_management.families' doesn't exist\")\n",
      "WITH employee_promotions AS (\n",
      "    SELECT \n",
      "        esh.employee_id,\n",
      "        COUNT(CASE WHEN esh.job_level_id > LAG(esh.job_level_id) OVER (PARTITION BY esh.employee_id ORDER BY esh.effective_date) THEN 1 END) AS promotion_count\n",
      "    FROM employment_status_histories esh\n",
      "    JOIN employment_statuses es ON esh.employee_id = es.employee_id\n",
      "    WHERE esh.effective_date >= DATE_SUB(STR_TO_DATE('11 April 2025', '%d %M %Y'), INTERVAL 3 YEAR)\n",
      "    AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "    AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "    AND es.location_id IN ('[LOCATION_IDS]')\n",
      "    GROUP BY esh.employee_id\n",
      "    HAVING promotion_count > 0\n",
      "),\n",
      "employee_education AS (\n",
      "    SELECT \n",
      "        e.employee_id,\n",
      "        el.name AS education_level\n",
      "    FROM educations e\n",
      "    JOIN education_levels el ON e.education_level_id = el.id\n",
      "    JOIN employment_statuses es ON e.employee_id = es.employee_id\n",
      "    WHERE es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "    AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "    AND es.location_id IN ('[LOCATION_IDS]')\n",
      ")\n",
      "SELECT \n",
      "    ee.education_level,\n",
      "    AVG(ep.promotion_count) AS avg_promotions,\n",
      "    COUNT(DISTINCT ep.employee_id) AS employee_count\n",
      "FROM employee_promotions ep\n",
      "JOIN employee_education ee ON ep.employee_id = ee.employee_id\n",
      "GROUP BY ee.education_level\n",
      "ORDER BY avg_promotions DESC;\n",
      "\n",
      "Trying candidate 2\n",
      "❌ Candidate 2 failed with error: Error executing query: (pymysql.err.ProgrammingError) (1146, \"Table 'ru4f_time_management.families' doesn't exist\")\n",
      "WITH date_range AS (\n",
      "    SELECT \n",
      "        STR_TO_DATE('11 April 2025', '%d %M %Y') AS end_date,\n",
      "        DATE_SUB(STR_TO_DATE('11 April 2025', '%d %M %Y'), INTERVAL 3 YEAR) AS start_date\n",
      "),\n",
      "promotion_counts AS (\n",
      "    SELECT \n",
      "        esh.employee_id,\n",
      "        COUNT(*) AS promotion_count\n",
      "    FROM employment_status_histories esh\n",
      "    JOIN employment_statuses es ON esh.employee_id = es.employee_id\n",
      "    CROSS JOIN date_range dr\n",
      "    WHERE esh.effective_date BETWEEN dr.start_date AND dr.end_date\n",
      "    AND esh.job_level_id > LAG(esh.job_level_id) OVER (PARTITION BY esh.employee_id ORDER BY esh.effective_date)\n",
      "    AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "    AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "    AND es.location_id IN ('[LOCATION_IDS]')\n",
      "    GROUP BY esh.employee_id\n",
      "),\n",
      "education_data AS (\n",
      "    SELECT \n",
      "        e.employee_id,\n",
      "        el.name AS education_level\n",
      "    FROM educations e\n",
      "    JOIN education_levels el ON e.education_level_id = el.id\n",
      "    JOIN employment_statuses es ON e.employee_id = es.employee_id\n",
      "    WHERE es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "    AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "    AND es.location_id IN ('[LOCATION_IDS]')\n",
      ")\n",
      "SELECT \n",
      "    ed.education_level,\n",
      "    IFNULL(AVG(pc.promotion_count), 0) AS avg_promotions,\n",
      "    COUNT(DISTINCT pc.employee_id) AS employee_count\n",
      "FROM education_data ed\n",
      "LEFT JOIN promotion_counts pc ON ed.employee_id = pc.employee_id\n",
      "GROUP BY ed.education_level\n",
      "ORDER BY avg_promotions DESC;\n",
      "\n",
      "Trying candidate 3\n",
      "❌ Candidate 3 failed with error: Error executing query: (pymysql.err.ProgrammingError) (1146, \"Table 'ru4f_time_management.families' doesn't exist\")\n",
      "No working candidates found. Retrying... (2/3)\n",
      "Processing... question 108_2 Retry attempt: 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:12:22,517 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 3):\n",
      "WITH date_range AS (\n",
      "    SELECT \n",
      "        STR_TO_DATE('11 April 2025', '%d %M %Y') AS end_date,\n",
      "        DATE_SUB(STR_TO_DATE('11 April 2025', '%d %M %Y'), INTERVAL 3 YEAR) AS start_date\n",
      "),\n",
      "employee_promotions AS (\n",
      "    SELECT \n",
      "        esh.employee_id,\n",
      "        COUNT(CASE WHEN esh.job_level_id > LAG(esh.job_level_id) OVER (PARTITION BY esh.employee_id ORDER BY esh.effective_date) THEN 1 END) AS promotion_count\n",
      "    FROM employment_status_histories esh\n",
      "    JOIN employment_statuses es ON esh.employee_id = es.employee_id\n",
      "    CROSS JOIN date_range dr\n",
      "    WHERE esh.effective_date BETWEEN dr.start_date AND dr.end_date\n",
      "    AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "    AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "    AND es.location_id IN ('[LOCATION_IDS]')\n",
      "    GROUP BY esh.employee_id\n",
      "),\n",
      "education_levels AS (\n",
      "    SELECT \n",
      "        e.employee_id,\n",
      "        el.name AS education_level\n",
      "    FROM educations e\n",
      "    JOIN education_levels el ON e.education_level_id = el.id\n",
      "    JOIN employment_statuses es ON e.employee_id = es.employee_id\n",
      "    WHERE es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "    AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "    AND es.location_id IN ('[LOCATION_IDS]')\n",
      ")\n",
      "SELECT \n",
      "    el.education_level,\n",
      "    IFNULL(AVG(ep.promotion_count), 0) AS avg_promotions,\n",
      "    COUNT(DISTINCT ep.employee_id) AS employee_count\n",
      "FROM education_levels el\n",
      "LEFT JOIN employee_promotions ep ON el.employee_id = ep.employee_id\n",
      "GROUP BY el.education_level\n",
      "ORDER BY avg_promotions DESC;\n",
      "\n",
      "Trying candidate 1\n",
      "❌ Candidate 1 failed with error: Error executing query: (pymysql.err.ProgrammingError) (1146, \"Table 'ru4f_time_management.families' doesn't exist\")\n",
      "WITH date_range AS (\n",
      "    SELECT \n",
      "        STR_TO_DATE('11 April 2025', '%d %M %Y') AS end_date,\n",
      "        DATE_SUB(STR_TO_DATE('11 April 2025', '%d %M %Y'), INTERVAL 3 YEAR) AS start_date\n",
      "),\n",
      "promotion_data AS (\n",
      "    SELECT \n",
      "        esh.employee_id,\n",
      "        SUM(CASE WHEN esh.job_level_id > LAG(esh.job_level_id) OVER (PARTITION BY esh.employee_id ORDER BY esh.effective_date) THEN 1 ELSE 0 END) AS promotion_count\n",
      "    FROM employment_status_histories esh\n",
      "    JOIN employment_statuses es ON esh.employee_id = es.employee_id\n",
      "    CROSS JOIN date_range dr\n",
      "    WHERE esh.effective_date BETWEEN dr.start_date AND dr.end_date\n",
      "    AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "    AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "    AND es.location_id IN ('[LOCATION_IDS]')\n",
      "    GROUP BY esh.employee_id\n",
      "),\n",
      "education_info AS (\n",
      "    SELECT \n",
      "        e.employee_id,\n",
      "        el.name AS education_level\n",
      "    FROM educations e\n",
      "    JOIN education_levels el ON e.education_level_id = el.id\n",
      "    JOIN employment_statuses es ON e.employee_id = es.employee_id\n",
      "    WHERE es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "    AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "    AND es.location_id IN ('[LOCATION_IDS]')\n",
      ")\n",
      "SELECT \n",
      "    ei.education_level,\n",
      "    IFNULL(AVG(pd.promotion_count), 0) AS avg_promotions,\n",
      "    COUNT(DISTINCT pd.employee_id) AS employee_count\n",
      "FROM education_info ei\n",
      "LEFT JOIN promotion_data pd ON ei.employee_id = pd.employee_id\n",
      "GROUP BY ei.education_level\n",
      "ORDER BY avg_promotions DESC;\n",
      "\n",
      "Trying candidate 2\n",
      "❌ Candidate 2 failed with error: Error executing query: (pymysql.err.ProgrammingError) (1146, \"Table 'ru4f_time_management.families' doesn't exist\")\n",
      "WITH date_range AS (\n",
      "    SELECT \n",
      "        STR_TO_DATE('11 April 2025', '%d %M %Y') AS end_date,\n",
      "        DATE_SUB(STR_TO_DATE('11 April 2025', '%d %M %Y'), INTERVAL 3 YEAR) AS start_date\n",
      "),\n",
      "promotion_history AS (\n",
      "    SELECT \n",
      "        employee_id,\n",
      "        COUNT(*) AS promotion_count\n",
      "    FROM (\n",
      "        SELECT \n",
      "            esh.employee_id,\n",
      "            esh.job_level_id,\n",
      "            esh.effective_date,\n",
      "            LAG(esh.job_level_id) OVER (PARTITION BY esh.employee_id ORDER BY esh.effective_date) AS prev_job_level\n",
      "        FROM employment_status_histories esh\n",
      "        JOIN employment_statuses es ON esh.employee_id = es.employee_id\n",
      "        CROSS JOIN date_range dr\n",
      "        WHERE esh.effective_date BETWEEN dr.start_date AND dr.end_date\n",
      "        AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND es.location_id IN ('[LOCATION_IDS]')\n",
      "    ) AS job_changes\n",
      "    WHERE job_level_id > prev_job_level\n",
      "    GROUP BY employee_id\n",
      "),\n",
      "education_levels AS (\n",
      "    SELECT \n",
      "        e.employee_id,\n",
      "        el.name AS education_level\n",
      "    FROM educations e\n",
      "    JOIN education_levels el ON e.education_level_id = el.id\n",
      "    JOIN employment_statuses es ON e.employee_id = es.employee_id\n",
      "    WHERE es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "    AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "    AND es.location_id IN ('[LOCATION_IDS]')\n",
      ")\n",
      "SELECT \n",
      "    el.education_level,\n",
      "    IFNULL(AVG(ph.promotion_count), 0) AS avg_promotions,\n",
      "    COUNT(DISTINCT ph.employee_id) AS employee_count\n",
      "FROM education_levels el\n",
      "LEFT JOIN promotion_history ph ON el.employee_id = ph.employee_id\n",
      "GROUP BY el.education_level\n",
      "ORDER BY avg_promotions DESC;\n",
      "\n",
      "Trying candidate 3\n",
      "❌ Candidate 3 failed with error: Error executing query: (pymysql.err.ProgrammingError) (1146, \"Table 'ru4f_time_management.families' doesn't exist\")\n",
      "No working candidates found. Retrying... (3/3)\n",
      "⚠️ Failed to find working SQL query after 3 attempts.\n",
      "108_3: ⚠️ Skipped due to column not found error.\n",
      "109_1: ⚠️ Skipped due to column not found error.\n",
      "109_2: ⚠️ Skipped due to column not found error.\n",
      "109_3: ✅ Original query executed successfully!\n",
      "110_1: ✅ Original query executed successfully!\n",
      "110_2: ⚠️ Skipped due to table not found error.\n",
      "Processing... question 110_3 Retry attempt: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:13:32,010 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 1):\n",
      "WITH monthly_promotions AS (\n",
      "  SELECT \n",
      "    YEAR(employment_status_histories.effective_date) AS year,\n",
      "    MONTH(employment_status_histories.effective_date) AS month,\n",
      "    COUNT(*) AS promotion_count\n",
      "  FROM employment_status_histories\n",
      "  JOIN employment_statuses ON employment_status_histories.employee_id = employment_statuses.employee_id\n",
      "  WHERE employment_status_histories.effective_date >= DATE_SUB(STR_TO_DATE('11 April 2025', '%d %M %Y'), INTERVAL 2 YEAR)\n",
      "  AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "  AND employment_statuses.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "  AND employment_statuses.location_id IN ('[LOCATION_IDS]')\n",
      "  GROUP BY YEAR(employment_status_histories.effective_date), MONTH(employment_status_histories.effective_date)\n",
      ")\n",
      "SELECT \n",
      "  current.year,\n",
      "  current.month,\n",
      "  current.promotion_count,\n",
      "  prev.promotion_count AS prev_year_count,\n",
      "  ROUND((current.promotion_count - prev.promotion_count) * 100.0 / NULLIF(prev.promotion_count, 0), 2) AS yoy_change\n",
      "FROM monthly_promotions current\n",
      "LEFT JOIN monthly_promotions prev ON \n",
      "  current.month = prev.month AND \n",
      "  current.year = prev.year + 1\n",
      "ORDER BY current.year, current.month;\n",
      "\n",
      "Trying candidate 1\n",
      "✅ Candidate 1 executed successfully!\n",
      "111_1: ⚠️ Skipped due to column not found error.\n",
      "111_2: ⚠️ Skipped due to column not found error.\n",
      "111_3: ⚠️ Skipped due to column not found error.\n",
      "112_1: ⚠️ Skipped due to column not found error.\n",
      "112_2: ✅ Original query executed successfully!\n",
      "112_3: ✅ Original query executed successfully!\n",
      "Processing... question 113_1 Retry attempt: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:14:30,392 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 1):\n",
      "WITH manager_stats AS (\n",
      "  SELECT \n",
      "    jl.name AS job_level,\n",
      "    COUNT(e.id) AS direct_reports,\n",
      "    m.id AS manager_id\n",
      "  FROM employees m\n",
      "  JOIN employees e ON e.manager_id = m.id\n",
      "  JOIN employment_statuses es ON m.id = es.employee_id\n",
      "  JOIN job_levels jl ON es.job_level_id = jl.id\n",
      "  WHERE m.active = TRUE \n",
      "    AND e.active = TRUE\n",
      "    AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "    AND es.location_id IN ('[LOCATION_IDS]')\n",
      "    AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "  GROUP BY m.id, jl.name\n",
      ")\n",
      "SELECT \n",
      "  job_level,\n",
      "  COUNT(manager_id) AS manager_count,\n",
      "  AVG(direct_reports) AS avg_reports,\n",
      "  MIN(direct_reports) AS min_reports,\n",
      "  MAX(direct_reports) AS max_reports,\n",
      "  STDDEV(direct_reports) AS stddev_reports\n",
      "FROM manager_stats\n",
      "GROUP BY job_level\n",
      "ORDER BY stddev_reports DESC;\n",
      "\n",
      "Trying candidate 1\n",
      "✅ Candidate 1 executed successfully!\n",
      "113_2: ✅ Original query executed successfully!\n",
      "113_3: ⚠️ Skipped due to column not found error.\n",
      "114_1: ✅ Original query executed successfully!\n",
      "114_2: ⚠️ Skipped due to column not found error.\n",
      "114_3: ✅ Original query executed successfully!\n",
      "115_1: ⚠️ Skipped due to column not found error.\n",
      "Processing... question 115_2 Retry attempt: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:15:20,227 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 1):\n",
      "SELECT \n",
      "    YEAR(e.join_date) AS tahun_bergabung, \n",
      "    jl.name AS level_jabatan, \n",
      "    FLOOR(AVG(DATEDIFF(e.join_date, ed.date_of_birth)/365) AS usia_rata_rata_saat_bergabung, \n",
      "    FLOOR(AVG(DATEDIFF(CURRENT_DATE, ed.date_of_birth)/365)) AS usia_rata_rata_sekarang, \n",
      "    COUNT(e.id) AS jumlah_karyawan \n",
      "FROM \n",
      "    employee_details ed \n",
      "    JOIN employees e ON ed.employee_id = e.id \n",
      "    JOIN employment_statuses es ON e.id = es.employee_id \n",
      "    JOIN job_levels jl ON es.job_level_id = jl.id \n",
      "WHERE \n",
      "    e.active = TRUE \n",
      "    AND es.organization_id IN ('[ORGANIZATION_IDS]') \n",
      "    AND es.job_level_id IN ('[JOB_LEVEL_IDS]') \n",
      "    AND es.location_id IN ('[LOCATION_IDS]') \n",
      "    AND e.join_date >= DATE_SUB(CURRENT_DATE, INTERVAL 5 YEAR) \n",
      "GROUP BY \n",
      "    YEAR(e.join_date), \n",
      "    jl.name \n",
      "ORDER BY \n",
      "    tahun_bergabung, \n",
      "    level_jabatan;\n",
      "\n",
      "Trying candidate 1\n",
      "❌ Candidate 1 failed with error: Error executing query: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near 'FROM \n",
      "WITH tahun_bergabung AS (\n",
      "    SELECT \n",
      "        YEAR(e.join_date) AS tahun, \n",
      "        jl.name AS level_jabatan, \n",
      "        FLOOR(DATEDIFF(e.join_date, ed.date_of_birth)/365) AS usia_bergabung, \n",
      "        FLOOR(DATEDIFF(CURRENT_DATE, ed.date_of_birth)/365) AS usia_sekarang, \n",
      "        e.id \n",
      "    FROM \n",
      "        employee_details ed \n",
      "        JOIN employees e ON ed.employee_id = e.id \n",
      "        JOIN employment_statuses es ON e.id = es.employee_id \n",
      "        JOIN job_levels jl ON es.job_level_id = jl.id \n",
      "    WHERE \n",
      "        e.active = TRUE \n",
      "        AND es.organization_id IN ('[ORGANIZATION_IDS]') \n",
      "        AND es.job_level_id IN ('[JOB_LEVEL_IDS]') \n",
      "        AND es.location_id IN ('[LOCATION_IDS]') \n",
      "        AND e.join_date >= DATE_SUB(CURRENT_DATE, INTERVAL 5 YEAR)\n",
      ")\n",
      "SELECT \n",
      "    tahun AS tahun_bergabung, \n",
      "    level_jabatan, \n",
      "    AVG(usia_bergabung) AS usia_rata_rata_saat_bergabung, \n",
      "    AVG(usia_sekarang) AS usia_rata_rata_sekarang, \n",
      "    COUNT(id) AS jumlah_karyawan \n",
      "FROM \n",
      "    tahun_bergabung \n",
      "GROUP BY \n",
      "    tahun, \n",
      "    level_jabatan \n",
      "ORDER BY \n",
      "    tahun_bergabung, \n",
      "    level_jabatan;\n",
      "\n",
      "Trying candidate 2\n",
      "❌ Candidate 2 failed with error: Error executing query: 1054 (42S22): Unknown column 'e.join_date' in 'field list'\n",
      "SELECT \n",
      "    YEAR(e.join_date) AS tahun_bergabung, \n",
      "    jl.name AS level_jabatan, \n",
      "    FLOOR(AVG(DATEDIFF(e.join_date, ed.date_of_birth)/365) AS usia_rata_rata_saat_bergabung, \n",
      "    FLOOR(AVG(DATEDIFF(STR_TO_DATE('11 April 2025', '%d %M %Y'), ed.date_of_birth)/365)) AS usia_rata_rata_sekarang, \n",
      "    COUNT(e.id) AS jumlah_karyawan \n",
      "FROM \n",
      "    employee_details ed \n",
      "    JOIN employees e ON ed.employee_id = e.id \n",
      "    JOIN employment_statuses es ON e.id = es.employee_id \n",
      "    JOIN job_levels jl ON es.job_level_id = jl.id \n",
      "WHERE \n",
      "    e.active = TRUE \n",
      "    AND es.organization_id IN ('[ORGANIZATION_IDS]') \n",
      "    AND es.job_level_id IN ('[JOB_LEVEL_IDS]') \n",
      "    AND es.location_id IN ('[LOCATION_IDS]') \n",
      "    AND e.join_date BETWEEN DATE_SUB(STR_TO_DATE('11 April 2025', '%d %M %Y'), INTERVAL 5 YEAR) AND STR_TO_DATE('11 April 2025', '%d %M %Y') \n",
      "GROUP BY \n",
      "    YEAR(e.join_date), \n",
      "    jl.name \n",
      "ORDER BY \n",
      "    tahun_bergabung, \n",
      "    level_jabatan;\n",
      "\n",
      "Trying candidate 3\n",
      "❌ Candidate 3 failed with error: Error executing query: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near 'FROM \n",
      "No working candidates found. Retrying... (1/3)\n",
      "Processing... question 115_2 Retry attempt: 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:16:11,774 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 2):\n",
      "SELECT \n",
      "    YEAR(e.join_date) AS tahun_bergabung, \n",
      "    jl.name AS level_jabatan, \n",
      "    FLOOR(AVG(DATEDIFF(e.join_date, ed.date_of_birth)/365)) AS usia_rata_rata_saat_bergabung, \n",
      "    FLOOR(AVG(DATEDIFF(STR_TO_DATE('11 April 2025', '%d %M %Y'), ed.date_of_birth)/365)) AS usia_rata_rata_sekarang, \n",
      "    COUNT(e.id) AS jumlah_karyawan \n",
      "FROM \n",
      "    employee_details ed \n",
      "    JOIN employees e ON ed.employee_id = e.id \n",
      "    JOIN employment_statuses es ON e.id = es.employee_id \n",
      "    JOIN job_levels jl ON es.job_level_id = jl.id \n",
      "WHERE \n",
      "    e.active = TRUE \n",
      "    AND es.organization_id IN ('[ORGANIZATION_IDS]') \n",
      "    AND es.job_level_id IN ('[JOB_LEVEL_IDS]') \n",
      "    AND es.location_id IN ('[LOCATION_IDS]') \n",
      "    AND e.join_date BETWEEN DATE_SUB(STR_TO_DATE('11 April 2025', '%d %M %Y'), INTERVAL 5 YEAR) AND STR_TO_DATE('11 April 2025', '%d %M %Y') \n",
      "GROUP BY \n",
      "    YEAR(e.join_date), \n",
      "    jl.name \n",
      "ORDER BY \n",
      "    tahun_bergabung, \n",
      "    level_jabatan;\n",
      "\n",
      "Trying candidate 1\n",
      "❌ Candidate 1 failed with error: Error executing query: 1054 (42S22): Unknown column 'e.join_date' in 'field list'\n",
      "SELECT \n",
      "    YEAR(e.join_date) AS tahun_bergabung, \n",
      "    jl.name AS level_jabatan, \n",
      "    FLOOR(AVG(DATEDIFF(e.join_date, ed.date_of_birth)/365)) AS usia_rata_rata_saat_bergabung, \n",
      "    FLOOR(AVG(DATEDIFF(CURRENT_DATE(), ed.date_of_birth)/365)) AS usia_rata_rata_sekarang, \n",
      "    COUNT(e.id) AS jumlah_karyawan \n",
      "FROM \n",
      "    employee_details ed \n",
      "    JOIN employees e ON ed.employee_id = e.id \n",
      "    JOIN employment_statuses es ON e.id = es.employee_id \n",
      "    JOIN job_levels jl ON es.job_level_id = jl.id \n",
      "WHERE \n",
      "    e.active = TRUE \n",
      "    AND es.organization_id IN ('[ORGANIZATION_IDS]') \n",
      "    AND es.job_level_id IN ('[JOB_LEVEL_IDS]') \n",
      "    AND es.location_id IN ('[LOCATION_IDS]') \n",
      "    AND e.join_date BETWEEN DATE_SUB(CURRENT_DATE(), INTERVAL 5 YEAR) AND CURRENT_DATE() \n",
      "GROUP BY \n",
      "    YEAR(e.join_date), \n",
      "    jl.name \n",
      "ORDER BY \n",
      "    tahun_bergabung, \n",
      "    level_jabatan;\n",
      "\n",
      "Trying candidate 2\n",
      "❌ Candidate 2 failed with error: Error executing query: 1054 (42S22): Unknown column 'e.join_date' in 'field list'\n",
      "SELECT \n",
      "    YEAR(e.join_date) AS tahun_bergabung, \n",
      "    jl.name AS level_jabatan, \n",
      "    FLOOR(AVG(DATEDIFF(e.join_date, ed.date_of_birth)/365)) AS usia_rata_rata_saat_bergabung, \n",
      "    FLOOR(AVG(DATEDIFF(STR_TO_DATE('11 April 2025', '%d %M %Y'), ed.date_of_birth)/365)) AS usia_rata_rata_sekarang, \n",
      "    COUNT(e.id) AS jumlah_karyawan \n",
      "FROM \n",
      "    employee_details ed \n",
      "    JOIN employees e ON ed.employee_id = e.id \n",
      "    JOIN employment_statuses es ON e.id = es.employee_id \n",
      "    JOIN job_levels jl ON es.job_level_id = jl.id \n",
      "WHERE \n",
      "    e.active = TRUE \n",
      "    AND es.organization_id IN ('[ORGANIZATION_IDS]') \n",
      "    AND es.job_level_id IN ('[JOB_LEVEL_IDS]') \n",
      "    AND es.location_id IN ('[LOCATION_IDS]') \n",
      "    AND YEAR(e.join_date) BETWEEN YEAR(DATE_SUB(STR_TO_DATE('11 April 2025', '%d %M %Y'), INTERVAL 5 YEAR)) AND YEAR(STR_TO_DATE('11 April 2025', '%d %M %Y')) \n",
      "GROUP BY \n",
      "    YEAR(e.join_date), \n",
      "    jl.name \n",
      "ORDER BY \n",
      "    tahun_bergabung, \n",
      "    level_jabatan;\n",
      "\n",
      "Trying candidate 3\n",
      "❌ Candidate 3 failed with error: Error executing query: 1054 (42S22): Unknown column 'e.join_date' in 'field list'\n",
      "No working candidates found. Retrying... (2/3)\n",
      "Processing... question 115_2 Retry attempt: 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:17:02,040 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 3):\n",
      "SELECT \n",
      "    YEAR(employees.start_date) AS tahun_bergabung, \n",
      "    job_levels.name AS level_jabatan, \n",
      "    FLOOR(AVG(DATEDIFF(employees.start_date, employee_details.date_of_birth)/365)) AS usia_rata_rata_saat_bergabung, \n",
      "    FLOOR(AVG(DATEDIFF(STR_TO_DATE('11 April 2025', '%d %M %Y'), employee_details.date_of_birth)/365)) AS usia_rata_rata_sekarang, \n",
      "    COUNT(employees.id) AS jumlah_karyawan \n",
      "FROM \n",
      "    employee_details \n",
      "    JOIN employees ON employee_details.employee_id = employees.id \n",
      "    JOIN employment_statuses ON employees.id = employment_statuses.employee_id \n",
      "    JOIN job_levels ON employment_statuses.job_level_id = job_levels.id \n",
      "WHERE \n",
      "    employees.active = TRUE \n",
      "    AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]') \n",
      "    AND employment_statuses.job_level_id IN ('[JOB_LEVEL_IDS]') \n",
      "    AND employment_statuses.location_id IN ('[LOCATION_IDS]') \n",
      "    AND YEAR(employees.start_date) BETWEEN YEAR(DATE_SUB(STR_TO_DATE('11 April 2025', '%d %M %Y'), INTERVAL 5 YEAR)) AND YEAR(STR_TO_DATE('11 April 2025', '%d %M %Y')) \n",
      "GROUP BY \n",
      "    YEAR(employees.start_date), \n",
      "    job_levels.name \n",
      "ORDER BY \n",
      "    tahun_bergabung, \n",
      "    level_jabatan;\n",
      "\n",
      "Trying candidate 1\n",
      "✅ Candidate 1 executed successfully!\n",
      "Processing... question 115_3 Retry attempt: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:18:01,545 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 1):\n",
      "SELECT \n",
      "    job_levels.name AS job_level, \n",
      "    FLOOR(AVG(DATEDIFF(CURRENT_DATE, employee_details.date_of_birth)/365)) AS avg_age, \n",
      "    FLOOR(AVG(DATEDIFF(CURRENT_DATE, employees.join_date)/365)) AS avg_tenure, \n",
      "    COUNT(employees.id) AS employee_count, \n",
      "    (SUM((DATEDIFF(CURRENT_DATE, employee_details.date_of_birth) * DATEDIFF(CURRENT_DATE, employees.join_date)) - (SUM(DATEDIFF(CURRENT_DATE, employee_details.date_of_birth)) * SUM(DATEDIFF(CURRENT_DATE, employees.join_date)) / COUNT(employees.id)) / \n",
      "    (SQRT((SUM(POW(DATEDIFF(CURRENT_DATE, employee_details.date_of_birth), 2)) - (POW(SUM(DATEDIFF(CURRENT_DATE, employee_details.date_of_birth)), 2) / COUNT(employees.id))) * \n",
      "    SQRT((SUM(POW(DATEDIFF(CURRENT_DATE, employees.join_date), 2)) - (POW(SUM(DATEDIFF(CURRENT_DATE, employees.join_date)), 2) / COUNT(employees.id))))) AS age_tenure_correlation \n",
      "FROM employee_details \n",
      "JOIN employees ON employee_details.employee_id = employees.id \n",
      "JOIN employment_statuses ON employees.id = employment_statuses.employee_id \n",
      "JOIN job_levels ON employment_statuses.job_level_id = job_levels.id \n",
      "WHERE employees.active = TRUE \n",
      "AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]') \n",
      "AND job_levels.id IN ('[JOB_LEVEL_IDS]') \n",
      "GROUP BY job_levels.name \n",
      "ORDER BY age_tenure_correlation DESC;\n",
      "\n",
      "Trying candidate 1\n",
      "❌ Candidate 1 failed with error: Error executing query: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near 'AS age_tenure_correlation \n",
      "WITH employee_stats AS (\n",
      "    SELECT \n",
      "        job_levels.name AS job_level, \n",
      "        DATEDIFF(CURRENT_DATE, employee_details.date_of_birth) AS age_days, \n",
      "        DATEDIFF(CURRENT_DATE, employees.join_date) AS tenure_days\n",
      "    FROM employee_details \n",
      "    JOIN employees ON employee_details.employee_id = employees.id \n",
      "    JOIN employment_statuses ON employees.id = employment_statuses.employee_id \n",
      "    JOIN job_levels ON employment_statuses.job_level_id = job_levels.id \n",
      "    WHERE employees.active = TRUE \n",
      "    AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]') \n",
      "    AND job_levels.id IN ('[JOB_LEVEL_IDS]')\n",
      "SELECT \n",
      "    job_level, \n",
      "    FLOOR(AVG(age_days)/365) AS avg_age, \n",
      "    FLOOR(AVG(tenure_days)/365) AS avg_tenure, \n",
      "    COUNT(*) AS employee_count, \n",
      "    (AVG(age_days * tenure_days) - AVG(age_days) * AVG(tenure_days)) / \n",
      "    (STDDEV_POP(age_days) * STDDEV_POP(tenure_days))) AS age_tenure_correlation\n",
      "FROM employee_stats\n",
      "GROUP BY job_level\n",
      "ORDER BY age_tenure_correlation DESC;\n",
      "\n",
      "Trying candidate 2\n",
      "❌ Candidate 2 failed with error: Error executing query: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near 'SELECT \n",
      "SELECT \n",
      "    job_levels.name AS job_level, \n",
      "    FLOOR(AVG(DATEDIFF(CURRENT_DATE, employee_details.date_of_birth)/365)) AS avg_age, \n",
      "    FLOOR(AVG(DATEDIFF(CURRENT_DATE, employees.join_date)/365)) AS avg_tenure, \n",
      "    COUNT(employees.id) AS employee_count, \n",
      "    (COUNT(employees.id) * SUM(DATEDIFF(CURRENT_DATE, employee_details.date_of_birth) * DATEDIFF(CURRENT_DATE, employees.join_date)) - \n",
      "    SUM(DATEDIFF(CURRENT_DATE, employee_details.date_of_birth)) * SUM(DATEDIFF(CURRENT_DATE, employees.join_date))) / \n",
      "    SQRT((COUNT(employees.id) * SUM(POW(DATEDIFF(CURRENT_DATE, employee_details.date_of_birth), 2)) - POW(SUM(DATEDIFF(CURRENT_DATE, employee_details.date_of_birth)), 2)) * \n",
      "    (COUNT(employees.id) * SUM(POW(DATEDIFF(CURRENT_DATE, employees.join_date), 2)) - POW(SUM(DATEDIFF(CURRENT_DATE, employees.join_date)), 2)))) AS age_tenure_correlation \n",
      "FROM employee_details \n",
      "JOIN employees ON employee_details.employee_id = employees.id \n",
      "JOIN employment_statuses ON employees.id = employment_statuses.employee_id \n",
      "JOIN job_levels ON employment_statuses.job_level_id = job_levels.id \n",
      "WHERE employees.active = TRUE \n",
      "AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]') \n",
      "AND job_levels.id IN ('[JOB_LEVEL_IDS]') \n",
      "GROUP BY job_levels.name \n",
      "ORDER BY age_tenure_correlation DESC;\n",
      "\n",
      "Trying candidate 3\n",
      "❌ Candidate 3 failed with error: Error executing query: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near ') AS age_tenure_correlation \n",
      "No working candidates found. Retrying... (1/3)\n",
      "Processing... question 115_3 Retry attempt: 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:18:56,177 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 2):\n",
      "SELECT \n",
      "    job_levels.name AS job_level, \n",
      "    FLOOR(AVG(DATEDIFF(CURRENT_DATE, employee_details.date_of_birth)/365) AS avg_age, \n",
      "    FLOOR(AVG(DATEDIFF(CURRENT_DATE, employees.join_date)/365) AS avg_tenure, \n",
      "    COUNT(employees.id) AS employee_count, \n",
      "    (COUNT(employees.id) * SUM(DATEDIFF(CURRENT_DATE, employee_details.date_of_birth) * DATEDIFF(CURRENT_DATE, employees.join_date) - \n",
      "    SUM(DATEDIFF(CURRENT_DATE, employee_details.date_of_birth)) * SUM(DATEDIFF(CURRENT_DATE, employees.join_date)) / \n",
      "    SQRT((COUNT(employees.id) * SUM(POW(DATEDIFF(CURRENT_DATE, employee_details.date_of_birth), 2)) - POW(SUM(DATEDIFF(CURRENT_DATE, employee_details.date_of_birth)), 2)) * \n",
      "    (COUNT(employees.id) * SUM(POW(DATEDIFF(CURRENT_DATE, employees.join_date), 2)) - POW(SUM(DATEDIFF(CURRENT_DATE, employees.join_date)), 2))) AS age_tenure_correlation \n",
      "FROM employee_details \n",
      "JOIN employees ON employee_details.employee_id = employees.id \n",
      "JOIN employment_statuses ON employees.id = employment_statuses.employee_id \n",
      "JOIN job_levels ON employment_statuses.job_level_id = job_levels.id \n",
      "WHERE employees.active = TRUE \n",
      "AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]') \n",
      "AND job_levels.id IN ('[JOB_LEVEL_IDS]') \n",
      "GROUP BY job_levels.name \n",
      "ORDER BY age_tenure_correlation DESC;\n",
      "\n",
      "Trying candidate 1\n",
      "❌ Candidate 1 failed with error: Error executing query: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near 'AS age_tenure_correlation \n",
      "SELECT \n",
      "    job_levels.name AS job_level, \n",
      "    FLOOR(AVG(DATEDIFF(CURRENT_DATE, employee_details.date_of_birth)/365)) AS avg_age, \n",
      "    FLOOR(AVG(DATEDIFF(CURRENT_DATE, employees.join_date)/365)) AS avg_tenure, \n",
      "    COUNT(employees.id) AS employee_count, \n",
      "    (SUM((DATEDIFF(CURRENT_DATE, employee_details.date_of_birth) - avg_age) * (DATEDIFF(CURRENT_DATE, employees.join_date) - avg_tenure)) / \n",
      "    (COUNT(employees.id) * STDDEV_POP(DATEDIFF(CURRENT_DATE, employee_details.date_of_birth)) * STDDEV_POP(DATEDIFF(CURRENT_DATE, employees.join_date)))) AS age_tenure_correlation \n",
      "FROM employee_details \n",
      "JOIN employees ON employee_details.employee_id = employees.id \n",
      "JOIN employment_statuses ON employees.id = employment_statuses.employee_id \n",
      "JOIN job_levels ON employment_statuses.job_level_id = job_levels.id \n",
      "WHERE employees.active = TRUE \n",
      "AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]') \n",
      "AND job_levels.id IN ('[JOB_LEVEL_IDS]') \n",
      "GROUP BY job_levels.name \n",
      "ORDER BY age_tenure_correlation DESC;\n",
      "\n",
      "Trying candidate 2\n",
      "❌ Candidate 2 failed with error: Error executing query: 1054 (42S22): Unknown column 'employees.join_date' in 'field list'\n",
      "WITH employee_stats AS (\n",
      "    SELECT \n",
      "        job_levels.name AS job_level, \n",
      "        DATEDIFF(CURRENT_DATE, employee_details.date_of_birth) AS age_days, \n",
      "        DATEDIFF(CURRENT_DATE, employees.join_date) AS tenure_days, \n",
      "        COUNT(employees.id) OVER (PARTITION BY job_levels.name) AS employee_count \n",
      "    FROM employee_details \n",
      "    JOIN employees ON employee_details.employee_id = employees.id \n",
      "    JOIN employment_statuses ON employees.id = employment_statuses.employee_id \n",
      "    JOIN job_levels ON employment_statuses.job_level_id = job_levels.id \n",
      "    WHERE employees.active = TRUE \n",
      "    AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]') \n",
      "    AND job_levels.id IN ('[JOB_LEVEL_IDS]')\n",
      "SELECT \n",
      "    job_level, \n",
      "    FLOOR(AVG(age_days)/365) AS avg_age, \n",
      "    FLOOR(AVG(tenure_days)/365) AS avg_tenure, \n",
      "    MAX(employee_count) AS employee_count, \n",
      "    (SUM(age_days * tenure_days) - (SUM(age_days) * SUM(tenure_days) / MAX(employee_count)) / \n",
      "    SQRT((SUM(age_days * age_days) - (SUM(age_days) * SUM(age_days) / MAX(employee_count)) * \n",
      "    (SUM(tenure_days * tenure_days) - (SUM(tenure_days) * SUM(tenure_days) / MAX(employee_count)))) AS age_tenure_correlation \n",
      "FROM employee_stats \n",
      "GROUP BY job_level \n",
      "ORDER BY age_tenure_correlation DESC;\n",
      "\n",
      "Trying candidate 3\n",
      "❌ Candidate 3 failed with error: Error executing query: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near 'SELECT \n",
      "No working candidates found. Retrying... (2/3)\n",
      "Processing... question 115_3 Retry attempt: 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:19:50,442 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 3):\n",
      "WITH employee_stats AS (\n",
      "    SELECT \n",
      "        job_levels.name AS job_level, \n",
      "        DATEDIFF(CURRENT_DATE, employee_details.date_of_birth) AS age_days, \n",
      "        DATEDIFF(CURRENT_DATE, employees.join_date) AS tenure_days\n",
      "    FROM employee_details \n",
      "    JOIN employees ON employee_details.employee_id = employees.id \n",
      "    JOIN employment_statuses ON employees.id = employment_statuses.employee_id \n",
      "    JOIN job_levels ON employment_statuses.job_level_id = job_levels.id \n",
      "    WHERE employees.active = TRUE \n",
      "    AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]') \n",
      "    AND job_levels.id IN ('[JOB_LEVEL_IDS]')\n",
      "),\n",
      "correlation_data AS (\n",
      "    SELECT \n",
      "        job_level, \n",
      "        FLOOR(AVG(age_days)/365) AS avg_age, \n",
      "        FLOOR(AVG(tenure_days)/365) AS avg_tenure, \n",
      "        COUNT(*) AS employee_count,\n",
      "        (SUM(age_days * tenure_days) - SUM(age_days) * SUM(tenure_days) / COUNT(*)) / \n",
      "        (SQRT(SUM(age_days * age_days) - SUM(age_days) * SUM(age_days) / COUNT(*)) * \n",
      "        SQRT(SUM(tenure_days * tenure_days) - SUM(tenure_days) * SUM(tenure_days) / COUNT(*)) AS age_tenure_correlation\n",
      "    FROM employee_stats \n",
      "    GROUP BY job_level\n",
      ")\n",
      "SELECT \n",
      "    job_level, \n",
      "    avg_age, \n",
      "    avg_tenure, \n",
      "    employee_count, \n",
      "    age_tenure_correlation\n",
      "FROM correlation_data\n",
      "ORDER BY age_tenure_correlation DESC;\n",
      "\n",
      "Trying candidate 1\n",
      "❌ Candidate 1 failed with error: Error executing query: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near 'AS age_tenure_correlation\n",
      "WITH employee_stats AS (\n",
      "    SELECT \n",
      "        job_levels.name AS job_level, \n",
      "        DATEDIFF(CURRENT_DATE, employee_details.date_of_birth) AS age_days, \n",
      "        DATEDIFF(CURRENT_DATE, employees.join_date) AS tenure_days,\n",
      "        COUNT(*) OVER (PARTITION BY job_levels.name) AS employee_count\n",
      "    FROM employee_details \n",
      "    JOIN employees ON employee_details.employee_id = employees.id \n",
      "    JOIN employment_statuses ON employees.id = employment_statuses.employee_id \n",
      "    JOIN job_levels ON employment_statuses.job_level_id = job_levels.id \n",
      "    WHERE employees.active = TRUE \n",
      "    AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]') \n",
      "    AND job_levels.id IN ('[JOB_LEVEL_IDS]')\n",
      ")\n",
      "SELECT \n",
      "    job_level, \n",
      "    FLOOR(AVG(age_days)/365) AS avg_age, \n",
      "    FLOOR(AVG(tenure_days)/365) AS avg_tenure, \n",
      "    MAX(employee_count) AS employee_count,\n",
      "    (SUM(age_days * tenure_days) - SUM(age_days) * SUM(tenure_days) / MAX(employee_count)) / \n",
      "    (SQRT(SUM(age_days * age_days) - SUM(age_days) * SUM(age_days) / MAX(employee_count)) * \n",
      "    SQRT(SUM(tenure_days * tenure_days) - SUM(tenure_days) * SUM(tenure_days) / MAX(employee_count))) AS age_tenure_correlation\n",
      "FROM employee_stats\n",
      "GROUP BY job_level\n",
      "ORDER BY age_tenure_correlation DESC;\n",
      "\n",
      "Trying candidate 2\n",
      "❌ Candidate 2 failed with error: Error executing query: 1054 (42S22): Unknown column 'employees.join_date' in 'field list'\n",
      "WITH employee_stats AS (\n",
      "    SELECT \n",
      "        job_levels.name AS job_level, \n",
      "        DATEDIFF(CURRENT_DATE, employee_details.date_of_birth) AS age_days, \n",
      "        DATEDIFF(CURRENT_DATE, employees.join_date) AS tenure_days\n",
      "    FROM employee_details \n",
      "    JOIN employees ON employee_details.employee_id = employees.id \n",
      "    JOIN employment_statuses ON employees.id = employment_statuses.employee_id \n",
      "    JOIN job_levels ON employment_statuses.job_level_id = job_levels.id \n",
      "    WHERE employees.active = TRUE \n",
      "    AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]') \n",
      "    AND job_levels.id IN ('[JOB_LEVEL_IDS]')\n",
      ")\n",
      "SELECT \n",
      "    job_level, \n",
      "    FLOOR(AVG(age_days)/365) AS avg_age, \n",
      "    FLOOR(AVG(tenure_days)/365) AS avg_tenure, \n",
      "    COUNT(*) AS employee_count,\n",
      "    (COUNT(*) * SUM(age_days * tenure_days) - SUM(age_days) * SUM(tenure_days)) / \n",
      "    (SQRT(COUNT(*) * SUM(age_days * age_days) - SUM(age_days) * SUM(age_days)) * \n",
      "    SQRT(COUNT(*) * SUM(tenure_days * tenure_days) - SUM(tenure_days) * SUM(tenure_days))) AS age_tenure_correlation\n",
      "FROM employee_stats\n",
      "GROUP BY job_level\n",
      "ORDER BY age_tenure_correlation DESC;\n",
      "\n",
      "Trying candidate 3\n",
      "❌ Candidate 3 failed with error: Error executing query: 1054 (42S22): Unknown column 'employees.join_date' in 'field list'\n",
      "No working candidates found. Retrying... (3/3)\n",
      "⚠️ Failed to find working SQL query after 3 attempts.\n",
      "116_1: ✅ Original query executed successfully!\n",
      "116_2: ✅ Original query executed successfully!\n",
      "116_3: ✅ Original query executed successfully!\n",
      "117_1: ⚠️ Skipped due to column not found error.\n",
      "117_2: ⚠️ Skipped due to column not found error.\n",
      "117_3: ⚠️ Skipped due to column not found error.\n",
      "118_1: ✅ Original query executed successfully!\n",
      "118_2: ✅ Original query executed successfully!\n",
      "118_3: ✅ Original query executed successfully!\n",
      "119_1: ✅ Original query executed successfully!\n",
      "119_2: ✅ Original query executed successfully!\n",
      "119_3: ⚠️ Skipped due to column not found error.\n",
      "120_1: ⚠️ Skipped due to column not found error.\n",
      "120_2: ✅ Original query executed successfully!\n",
      "120_3: ⚠️ Skipped due to column not found error.\n",
      "121_1: ✅ Original query executed successfully!\n",
      "Processing... question 121_2 Retry attempt: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:20:49,684 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 1):\n",
      "WITH current_subordinates AS (\n",
      "  SELECT \n",
      "    m.id AS manager_id,\n",
      "    m.name AS manager_name,\n",
      "    COUNT(e.id) AS current_count\n",
      "  FROM employees e\n",
      "  JOIN employees m ON e.manager_id = m.id\n",
      "  JOIN employment_status_histories esh ON m.id = esh.employee_id\n",
      "  WHERE esh.effective_date >= DATE_SUB(CURRENT_DATE(), INTERVAL 3 MONTH)\n",
      "    AND esh.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "    AND esh.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "    AND esh.location_id IN ('[LOCATION_IDS]')\n",
      "  GROUP BY m.id, m.name\n",
      "),\n",
      "past_subordinates AS (\n",
      "  SELECT \n",
      "    m.id AS manager_id,\n",
      "    COUNT(e.id) AS past_count\n",
      "  FROM employees e\n",
      "  JOIN employees m ON e.manager_id = m.id\n",
      "  JOIN employment_status_histories esh ON m.id = esh.employee_id\n",
      "  WHERE esh.effective_date BETWEEN DATE_SUB(CURRENT_DATE(), INTERVAL 15 MONTH) AND DATE_SUB(CURRENT_DATE(), INTERVAL 12 MONTH)\n",
      "    AND esh.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "    AND esh.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "    AND esh.location_id IN ('[LOCATION_IDS]')\n",
      "  GROUP BY m.id\n",
      ")\n",
      "SELECT \n",
      "  cs.manager_id,\n",
      "  cs.manager_name,\n",
      "  cs.current_count,\n",
      "  COALESCE(ps.past_count, 0) AS past_count,\n",
      "  cs.current_count - COALESCE(ps.past_count, 0) AS change_absolute,\n",
      "  CASE \n",
      "    WHEN COALESCE(ps.past_count, 0) = 0 THEN NULL\n",
      "    ELSE ROUND((cs.current_count - COALESCE(ps.past_count, 0)) / COALESCE(ps.past_count, 0) * 100, 2)\n",
      "  END AS change_percentage\n",
      "FROM current_subordinates cs\n",
      "LEFT JOIN past_subordinates ps ON cs.manager_id = ps.manager_id\n",
      "ORDER BY ABS(change_absolute) DESC\n",
      "LIMIT 10;\n",
      "\n",
      "Trying candidate 1\n",
      "✅ Candidate 1 executed successfully!\n",
      "121_3: ⚠️ Skipped due to column not found error.\n",
      "122_1: ✅ Original query executed successfully!\n",
      "Processing... question 122_2 Retry attempt: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:22:00,492 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 1):\n",
      "WITH company_avg AS (\n",
      "    SELECT AVG(attendance_detail_recapitulations.paid_overtime/3600000) AS avg_overtime\n",
      "    FROM attendance_detail_recapitulations\n",
      "    WHERE attendance_detail_recapitulations.date >= DATE_SUB(STR_TO_DATE('11 April 2025', '%d %M %Y'), INTERVAL 3 MONTH)\n",
      "),\n",
      "employee_overtime AS (\n",
      "    SELECT \n",
      "        attendance_detail_recapitulations.employee_id,\n",
      "        AVG(attendance_detail_recapitulations.paid_overtime/3600000) AS emp_avg_overtime,\n",
      "        organizations.name AS department\n",
      "    FROM \n",
      "        attendance_detail_recapitulations\n",
      "    JOIN \n",
      "        employment_statuses ON attendance_detail_recapitulations.employee_id = employment_statuses.employee_id\n",
      "    JOIN \n",
      "        organizations ON employment_statuses.organization_id = organizations.id\n",
      "    WHERE \n",
      "        attendance_detail_recapitulations.date >= DATE_SUB(STR_TO_DATE('11 April 2025', '%d %M %Y'), INTERVAL 3 MONTH)\n",
      "        AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND employment_statuses.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND employment_statuses.location_id IN ('[LOCATION_IDS]')\n",
      "    GROUP BY \n",
      "        attendance_detail_recapitulations.employee_id, organizations.name\n",
      "),\n",
      "department_stats AS (\n",
      "    SELECT \n",
      "        department,\n",
      "        COUNT(*) AS total_employees,\n",
      "        SUM(CASE WHEN emp_avg_overtime > (SELECT avg_overtime FROM company_avg) THEN 1 ELSE 0 END) AS above_avg_employees\n",
      "    FROM \n",
      "        employee_overtime\n",
      "    GROUP BY \n",
      "        department\n",
      ")\n",
      "SELECT \n",
      "    department,\n",
      "    total_employees,\n",
      "    above_avg_employees,\n",
      "    ROUND((above_avg_employees / total_employees) * 100, 2) AS percentage_above_avg\n",
      "FROM \n",
      "    department_stats\n",
      "ORDER BY \n",
      "    percentage_above_avg DESC\n",
      "\n",
      "Trying candidate 1\n",
      "❌ Candidate 1 failed with error: Error executing query: 1111 (HY000): Invalid use of group function\n",
      "WITH company_avg AS (\n",
      "    SELECT AVG(attendance_detail_recapitulations.paid_overtime/3600000) AS avg_overtime\n",
      "    FROM attendance_detail_recapitulations\n",
      "    WHERE attendance_detail_recapitulations.date BETWEEN DATE_SUB(STR_TO_DATE('11 April 2025', '%d %M %Y'), INTERVAL 3 MONTH) AND STR_TO_DATE('11 April 2025', '%d %M %Y')\n",
      "),\n",
      "department_overtime AS (\n",
      "    SELECT \n",
      "        organizations.name AS department,\n",
      "        attendance_detail_recapitulations.employee_id,\n",
      "        AVG(attendance_detail_recapitulations.paid_overtime/3600000) AS emp_avg_overtime\n",
      "    FROM \n",
      "        attendance_detail_recapitulations\n",
      "    JOIN \n",
      "        employment_statuses ON attendance_detail_recapitulations.employee_id = employment_statuses.employee_id\n",
      "    JOIN \n",
      "        organizations ON employment_statuses.organization_id = organizations.id\n",
      "    WHERE \n",
      "        attendance_detail_recapitulations.date BETWEEN DATE_SUB(STR_TO_DATE('11 April 2025', '%d %M %Y'), INTERVAL 3 MONTH) AND STR_TO_DATE('11 April 2025', '%d %M %Y')\n",
      "        AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND employment_statuses.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND employment_statuses.location_id IN ('[LOCATION_IDS]')\n",
      "    GROUP BY \n",
      "        organizations.name, attendance_detail_recapitulations.employee_id\n",
      ")\n",
      "SELECT \n",
      "    department,\n",
      "    COUNT(*) AS total_employees,\n",
      "    COUNT(CASE WHEN emp_avg_overtime > (SELECT avg_overtime FROM company_avg) THEN 1 END) AS above_avg_employees,\n",
      "    ROUND((COUNT(CASE WHEN emp_avg_overtime > (SELECT avg_overtime FROM company_avg) THEN 1 END) / COUNT(*) * 100, 2) AS percentage_above_avg\n",
      "FROM \n",
      "    department_overtime\n",
      "GROUP BY \n",
      "    department\n",
      "ORDER BY \n",
      "    percentage_above_avg DESC\n",
      "\n",
      "Trying candidate 2\n",
      "❌ Candidate 2 failed with error: Error executing query: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near 'FROM \n",
      "WITH company_avg AS (\n",
      "    SELECT AVG(attendance_detail_recapitulations.paid_overtime/3600000) AS avg_overtime\n",
      "    FROM attendance_detail_recapitulations\n",
      "    WHERE attendance_detail_recapitulations.date >= DATE_SUB(STR_TO_DATE('11 April 2025', '%d %M %Y'), INTERVAL 3 MONTH)\n",
      "),\n",
      "employee_overtime AS (\n",
      "    SELECT \n",
      "        attendance_detail_recapitulations.employee_id,\n",
      "        AVG(attendance_detail_recapitulations.paid_overtime/3600000) AS emp_avg_overtime,\n",
      "        organizations.name AS department\n",
      "    FROM \n",
      "        attendance_detail_recapitulations\n",
      "    JOIN \n",
      "        employment_statuses ON attendance_detail_recapitulations.employee_id = employment_statuses.employee_id\n",
      "    JOIN \n",
      "        organizations ON employment_statuses.organization_id = organizations.id\n",
      "    WHERE \n",
      "        attendance_detail_recapitulations.date >= DATE_SUB(STR_TO_DATE('11 April 2025', '%d %M %Y'), INTERVAL 3 MONTH)\n",
      "        AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND employment_statuses.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND employment_statuses.location_id IN ('[LOCATION_IDS]')\n",
      "    GROUP BY \n",
      "        attendance_detail_recapitulations.employee_id, organizations.name\n",
      ")\n",
      "SELECT \n",
      "    department,\n",
      "    COUNT(employee_id) AS total_employees,\n",
      "    SUM(IF(emp_avg_overtime > (SELECT avg_overtime FROM company_avg), 1, 0)) AS above_avg_employees,\n",
      "    ROUND(SUM(IF(emp_avg_overtime > (SELECT avg_overtime FROM company_avg), 1, 0)) / COUNT(employee_id) * 100, 2) AS percentage_above_avg\n",
      "FROM \n",
      "    employee_overtime\n",
      "GROUP BY \n",
      "    department\n",
      "ORDER BY \n",
      "    percentage_above_avg DESC\n",
      "\n",
      "Trying candidate 3\n",
      "❌ Candidate 3 failed with error: Error executing query: 1111 (HY000): Invalid use of group function\n",
      "No working candidates found. Retrying... (1/3)\n",
      "Processing... question 122_2 Retry attempt: 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:23:08,738 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 2):\n",
      "WITH company_avg AS (\n",
      "    SELECT AVG(attendance_detail_recapitulations.paid_overtime/3600000) AS avg_overtime\n",
      "    FROM attendance_detail_recapitulations\n",
      "    WHERE attendance_detail_recapitulations.date >= DATE_SUB(STR_TO_DATE('11 April 2025', '%d %M %Y'), INTERVAL 3 MONTH)\n",
      "),\n",
      "employee_overtime AS (\n",
      "    SELECT \n",
      "        employment_statuses.organization_id,\n",
      "        organizations.name AS department,\n",
      "        attendance_detail_recapitulations.employee_id,\n",
      "        AVG(attendance_detail_recapitulations.paid_overtime/3600000) AS emp_avg_overtime\n",
      "    FROM \n",
      "        attendance_detail_recapitulations\n",
      "    JOIN \n",
      "        employment_statuses ON attendance_detail_recapitulations.employee_id = employment_statuses.employee_id\n",
      "    JOIN \n",
      "        organizations ON employment_statuses.organization_id = organizations.id\n",
      "    WHERE \n",
      "        attendance_detail_recapitulations.date >= DATE_SUB(STR_TO_DATE('11 April 2025', '%d %M %Y'), INTERVAL 3 MONTH)\n",
      "        AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND employment_statuses.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND employment_statuses.location_id IN ('[LOCATION_IDS]')\n",
      "    GROUP BY \n",
      "        employment_statuses.organization_id, organizations.name, attendance_detail_recapitulations.employee_id\n",
      "),\n",
      "department_stats AS (\n",
      "    SELECT \n",
      "        department,\n",
      "        COUNT(DISTINCT employee_id) AS total_employees,\n",
      "        SUM(CASE WHEN emp_avg_overtime > (SELECT avg_overtime FROM company_avg) THEN 1 ELSE 0 END) AS above_avg_employees\n",
      "    FROM \n",
      "        employee_overtime\n",
      "    GROUP BY \n",
      "        department\n",
      ")\n",
      "SELECT \n",
      "    department,\n",
      "    total_employees,\n",
      "    above_avg_employees,\n",
      "    ROUND((above_avg_employees / total_employees) * 100, 2) AS percentage_above_avg\n",
      "FROM \n",
      "    department_stats\n",
      "ORDER BY \n",
      "    percentage_above_avg DESC\n",
      "\n",
      "Trying candidate 1\n",
      "❌ Candidate 1 failed with error: Error executing query: 1111 (HY000): Invalid use of group function\n",
      "WITH company_avg AS (\n",
      "    SELECT AVG(attendance_detail_recapitulations.paid_overtime/3600000) AS avg_overtime\n",
      "    FROM attendance_detail_recapitulations\n",
      "    WHERE attendance_detail_recapitulations.date BETWEEN DATE_SUB(STR_TO_DATE('11 April 2025', '%d %M %Y'), INTERVAL 3 MONTH) AND STR_TO_DATE('11 April 2025', '%d %M %Y')\n",
      "),\n",
      "department_overtime AS (\n",
      "    SELECT \n",
      "        organizations.name AS department,\n",
      "        attendance_detail_recapitulations.employee_id,\n",
      "        AVG(attendance_detail_recapitulations.paid_overtime/3600000) AS emp_avg_overtime\n",
      "    FROM \n",
      "        attendance_detail_recapitulations\n",
      "    JOIN \n",
      "        employment_statuses ON attendance_detail_recapitulations.employee_id = employment_statuses.employee_id\n",
      "    JOIN \n",
      "        organizations ON employment_statuses.organization_id = organizations.id\n",
      "    WHERE \n",
      "        attendance_detail_recapitulations.date BETWEEN DATE_SUB(STR_TO_DATE('11 April 2025', '%d %M %Y'), INTERVAL 3 MONTH) AND STR_TO_DATE('11 April 2025', '%d %M %Y')\n",
      "        AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND employment_statuses.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND employment_statuses.location_id IN ('[LOCATION_IDS]')\n",
      "    GROUP BY \n",
      "        organizations.name, attendance_detail_recapitulations.employee_id\n",
      ")\n",
      "SELECT \n",
      "    department,\n",
      "    COUNT(employee_id) AS total_employees,\n",
      "    SUM(CASE WHEN emp_avg_overtime > (SELECT avg_overtime FROM company_avg) THEN 1 ELSE 0 END) AS above_avg_employees,\n",
      "    ROUND((SUM(CASE WHEN emp_avg_overtime > (SELECT avg_overtime FROM company_avg) THEN 1 ELSE 0 END) / COUNT(employee_id)) * 100, 2) AS percentage_above_avg\n",
      "FROM \n",
      "    department_overtime\n",
      "GROUP BY \n",
      "    department\n",
      "ORDER BY \n",
      "    percentage_above_avg DESC\n",
      "\n",
      "Trying candidate 2\n",
      "❌ Candidate 2 failed with error: Error executing query: 1111 (HY000): Invalid use of group function\n",
      "WITH company_avg AS (\n",
      "    SELECT AVG(attendance_detail_recapitulations.paid_overtime/3600000) AS avg_overtime\n",
      "    FROM attendance_detail_recapitulations\n",
      "    WHERE attendance_detail_recapitulations.date BETWEEN DATE_SUB(STR_TO_DATE('11 April 2025', '%d %M %Y'), INTERVAL 3 MONTH) AND STR_TO_DATE('11 April 2025', '%d %M %Y')\n",
      "),\n",
      "employee_overtime AS (\n",
      "    SELECT \n",
      "        organizations.name AS department,\n",
      "        attendance_detail_recapitulations.employee_id,\n",
      "        AVG(attendance_detail_recapitulations.paid_overtime/3600000) AS emp_avg_overtime\n",
      "    FROM \n",
      "        attendance_detail_recapitulations\n",
      "    JOIN \n",
      "        employment_statuses ON attendance_detail_recapitulations.employee_id = employment_statuses.employee_id\n",
      "    JOIN \n",
      "        organizations ON employment_statuses.organization_id = organizations.id\n",
      "    WHERE \n",
      "        attendance_detail_recapitulations.date BETWEEN DATE_SUB(STR_TO_DATE('11 April 2025', '%d %M %Y'), INTERVAL 3 MONTH) AND STR_TO_DATE('11 April 2025', '%d %M %Y')\n",
      "        AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND employment_statuses.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND employment_statuses.location_id IN ('[LOCATION_IDS]')\n",
      "    GROUP BY \n",
      "        organizations.name, attendance_detail_recapitulations.employee_id\n",
      ")\n",
      "SELECT \n",
      "    eo.department,\n",
      "    COUNT(eo.employee_id) AS total_employees,\n",
      "    COUNT(CASE WHEN eo.emp_avg_overtime > ca.avg_overtime THEN 1 END) AS above_avg_employees,\n",
      "    ROUND((COUNT(CASE WHEN eo.emp_avg_overtime > ca.avg_overtime THEN 1 END) / COUNT(eo.employee_id)) * 100, 2) AS percentage_above_avg\n",
      "FROM \n",
      "    employee_overtime eo\n",
      "CROSS JOIN \n",
      "    company_avg ca\n",
      "GROUP BY \n",
      "    eo.department\n",
      "ORDER BY \n",
      "    percentage_above_avg DESC\n",
      "\n",
      "Trying candidate 3\n",
      "✅ Candidate 3 executed successfully!\n",
      "Processing... question 122_3 Retry attempt: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:24:21,203 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 1):\n",
      "SELECT \n",
      "    job_levels.name AS level_jabatan,\n",
      "    COUNT(*) AS jumlah_rekaman,\n",
      "    MIN(attendance_detail_recapitulations.paid_overtime/3600000) AS durasi_minimum_lembur,\n",
      "    ROUND(AVG(attendance_detail_recapitulations.paid_overtime/3600000), 2) AS durasi_rata_rata_lembur,\n",
      "    MAX(attendance_detail_recapitulations.paid_overtime/3600000) AS durasi_maksimum_lembur,\n",
      "    (SELECT paid_overtime/3600000 FROM attendance_detail_recapitulations \n",
      "     JOIN employment_statuses ON attendance_detail_recapitulations.employee_id = employment_statuses.employee_id\n",
      "     WHERE employment_statuses.job_level_id = job_levels.id \n",
      "     ORDER BY paid_overtime LIMIT 1 OFFSET FLOOR(COUNT(*)*0.25)) AS persentil_25,\n",
      "    (SELECT paid_overtime/3600000 FROM attendance_detail_recapitulations \n",
      "     JOIN employment_statuses ON attendance_detail_recapitulations.employee_id = employment_statuses.employee_id\n",
      "     WHERE employment_statuses.job_level_id = job_levels.id \n",
      "     ORDER BY paid_overtime LIMIT 1 OFFSET FLOOR(COUNT(*)*0.5)) AS median,\n",
      "    (SELECT paid_overtime/3600000 FROM attendance_detail_recapitulations \n",
      "     JOIN employment_statuses ON attendance_detail_recapitulations.employee_id = employment_statuses.employee_id\n",
      "     WHERE employment_statuses.job_level_id = job_levels.id \n",
      "     ORDER BY paid_overtime LIMIT 1 OFFSET FLOOR(COUNT(*)*0.75)) AS persentil_75\n",
      "FROM \n",
      "    attendance_detail_recapitulations\n",
      "JOIN \n",
      "    employment_statuses ON attendance_detail_recapitulations.employee_id = employment_statuses.employee_id\n",
      "JOIN \n",
      "    job_levels ON employment_statuses.job_level_id = job_levels.id\n",
      "WHERE \n",
      "    attendance_detail_recapitulations.date >= DATE_SUB(CURDATE(), INTERVAL 12 MONTH)\n",
      "    AND employment_statuses.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "    AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "    AND employment_statuses.location_id IN ('[LOCATION_IDS]')\n",
      "GROUP BY \n",
      "    job_levels.name\n",
      "ORDER BY \n",
      "    CASE job_levels.name\n",
      "        WHEN 'Executive' THEN 1\n",
      "        WHEN 'Manager' THEN 2\n",
      "        WHEN 'Supervisor' THEN 3\n",
      "        WHEN 'Staff' THEN 4\n",
      "        ELSE 5\n",
      "    END\n",
      "\n",
      "Trying candidate 1\n",
      "❌ Candidate 1 failed with error: Error executing query: 1327 (42000): Undeclared variable: FLOOR\n",
      "WITH overtime_stats AS (\n",
      "    SELECT \n",
      "        job_levels.name AS level_jabatan,\n",
      "        attendance_detail_recapitulations.paid_overtime/3600000 AS durasi_lembur\n",
      "    FROM \n",
      "        attendance_detail_recapitulations\n",
      "    JOIN \n",
      "        employment_statuses ON attendance_detail_recapitulations.employee_id = employment_statuses.employee_id\n",
      "    JOIN \n",
      "        job_levels ON employment_statuses.job_level_id = job_levels.id\n",
      "    WHERE \n",
      "        attendance_detail_recapitulations.date >= DATE_SUB(CURDATE(), INTERVAL 12 MONTH)\n",
      "        AND employment_statuses.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND employment_statuses.location_id IN ('[LOCATION_IDS]')\n",
      ")\n",
      "SELECT \n",
      "    level_jabatan,\n",
      "    COUNT(*) AS jumlah_rekaman,\n",
      "    MIN(durasi_lembur) AS durasi_minimum_lembur,\n",
      "    ROUND(AVG(durasi_lembur), 2) AS durasi_rata_rata_lembur,\n",
      "    MAX(durasi_lembur) AS durasi_maksimum_lembur,\n",
      "    SUBSTRING_INDEX(SUBSTRING_INDEX(GROUP_CONCAT(durasi_lembur ORDER BY durasi_lembur SEPARATOR ','), ',', CEIL(COUNT(*)*0.25)), ',', -1) AS persentil_25,\n",
      "    SUBSTRING_INDEX(SUBSTRING_INDEX(GROUP_CONCAT(durasi_lembur ORDER BY durasi_lembur SEPARATOR ','), ',', CEIL(COUNT(*)*0.5)), ',', -1) AS median,\n",
      "    SUBSTRING_INDEX(SUBSTRING_INDEX(GROUP_CONCAT(durasi_lembur ORDER BY durasi_lembur SEPARATOR ','), ',', CEIL(COUNT(*)*0.75)), ',', -1) AS persentil_75\n",
      "FROM \n",
      "    overtime_stats\n",
      "GROUP BY \n",
      "    level_jabatan\n",
      "ORDER BY \n",
      "    CASE level_jabatan\n",
      "        WHEN 'Executive' THEN 1\n",
      "        WHEN 'Manager' THEN 2\n",
      "        WHEN 'Supervisor' THEN 3\n",
      "        WHEN 'Staff' THEN 4\n",
      "        ELSE 5\n",
      "    END\n",
      "\n",
      "Trying candidate 2\n",
      "✅ Candidate 2 executed successfully!\n",
      "123_1: ✅ Original query executed successfully!\n",
      "123_2: ⚠️ Skipped due to column not found error.\n",
      "123_3: ✅ Original query executed successfully!\n",
      "124_1: ⚠️ Skipped due to column not found error.\n",
      "124_2: ⚠️ Skipped due to column not found error.\n",
      "124_3: ⚠️ Skipped due to table not found error.\n",
      "125_1: ✅ Original query executed successfully!\n",
      "125_2: ✅ Original query executed successfully!\n",
      "125_3: ⚠️ Skipped due to column not found error.\n",
      "126_1: ✅ Original query executed successfully!\n",
      "Processing... question 126_2 Retry attempt: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:26:17,782 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 1):\n",
      "WITH overtime_by_level AS (\n",
      "  SELECT \n",
      "    job_levels.name AS job_level,\n",
      "    attendance_detail_recapitulations.paid_overtime/3600000 AS overtime_hours\n",
      "  FROM attendance_detail_recapitulations\n",
      "  JOIN employment_statuses ON attendance_detail_recapitulations.employee_id = employment_statuses.employee_id\n",
      "  JOIN job_levels ON employment_statuses.job_level_id = job_levels.id\n",
      "  WHERE attendance_detail_recapitulations.date BETWEEN DATE_SUB(CURRENT_DATE(), INTERVAL 3 MONTH) AND CURRENT_DATE()\n",
      "    AND employment_statuses.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "    AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "    AND employment_statuses.location_id IN ('[LOCATION_IDS]')\n",
      ")\n",
      "\n",
      "SELECT \n",
      "  job_level,\n",
      "  COUNT(*) AS jumlah_karyawan,\n",
      "  AVG(overtime_hours) AS rata_rata_lembur_jam,\n",
      "  MAX(overtime_hours) AS maksimal_lembur_jam,\n",
      "  MIN(overtime_hours) AS minimal_lembur_jam\n",
      "FROM overtime_by_level\n",
      "GROUP BY job_level\n",
      "ORDER BY rata_rata_lembur_jam DESC;\n",
      "\n",
      "Trying candidate 1\n",
      "✅ Candidate 1 executed successfully!\n",
      "126_3: ✅ Original query executed successfully!\n",
      "127_1: ✅ Original query executed successfully!\n",
      "127_2: ✅ Original query executed successfully!\n",
      "127_3: ✅ Original query executed successfully!\n",
      "Processing... question 128_1 Retry attempt: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:27:07,822 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 1):\n",
      "WITH yearly_data AS (\n",
      "  SELECT \n",
      "    YEAR(employment_status_histories.effective_date) AS year,\n",
      "    organizations.name AS department,\n",
      "    job_levels.name AS job_level,\n",
      "    COUNT(*) AS employee_count\n",
      "  FROM employment_status_histories\n",
      "  JOIN organizations ON employment_status_histories.organization_id = organizations.id\n",
      "  JOIN job_levels ON employment_status_histories.job_level_id = job_levels.id\n",
      "  JOIN employment_statuses ON employment_status_histories.employee_id = employment_statuses.employee_id\n",
      "  WHERE \n",
      "    employment_status_histories.effective_date >= DATE_SUB(CURRENT_DATE(), INTERVAL 3 YEAR)\n",
      "    AND organizations.id IN ('[ORGANIZATION_IDS]')\n",
      "    AND job_levels.id IN ('[JOB_LEVEL_IDS]')\n",
      "    AND employment_statuses.location_id IN ('[LOCATION_IDS]')\n",
      "  GROUP BY \n",
      "    YEAR(employment_status_histories.effective_date),\n",
      "    organizations.name,\n",
      "    job_levels.name\n",
      "),\n",
      "prev_year_data AS (\n",
      "  SELECT \n",
      "    year,\n",
      "    department,\n",
      "    job_level,\n",
      "    employee_count,\n",
      "    LAG(employee_count, 1) OVER (PARTITION BY department, job_level ORDER BY year) AS prev_year_count\n",
      "  FROM yearly_data\n",
      ")\n",
      "SELECT \n",
      "  year,\n",
      "  department,\n",
      "  job_level,\n",
      "  employee_count,\n",
      "  COALESCE(prev_year_count, 0) AS prev_year_count,\n",
      "  CASE \n",
      "    WHEN COALESCE(prev_year_count, 0) = 0 THEN 0\n",
      "    ELSE ROUND((employee_count - COALESCE(prev_year_count, 0)) / COALESCE(prev_year_count, 0) * 100, 2)\n",
      "  END AS growth_percentage\n",
      "FROM prev_year_data\n",
      "ORDER BY year, department, job_level;\n",
      "\n",
      "Trying candidate 1\n",
      "✅ Candidate 1 executed successfully!\n",
      "128_2: ✅ Original query executed successfully!\n",
      "128_3: ⚠️ Skipped due to column not found error.\n",
      "129_1: ✅ Original query executed successfully!\n",
      "129_2: ✅ Original query executed successfully!\n",
      "129_3: ✅ Original query executed successfully!\n",
      "130_1: ✅ Original query executed successfully!\n",
      "Processing... question 130_2 Retry attempt: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:28:23,484 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 1):\n",
      "WITH RECURSIVE org_hierarchy AS (\n",
      "    SELECT e.id, e.name, e.manager_id, e.join_date, 0 AS level \n",
      "    FROM employees e \n",
      "    WHERE e.manager_id IS NULL\n",
      "    UNION ALL \n",
      "    SELECT e.id, e.name, e.manager_id, e.join_date, h.level + 1 \n",
      "    FROM employees e \n",
      "    JOIN org_hierarchy h ON e.manager_id = h.id\n",
      ")\n",
      "SELECT \n",
      "    level AS management_level,\n",
      "    YEAR(join_date) AS join_year,\n",
      "    AVG(DATEDIFF(CURRENT_DATE, join_date)/365 AS avg_tenure_years,\n",
      "    COUNT(id) AS employee_count\n",
      "FROM org_hierarchy\n",
      "WHERE join_date IS NOT NULL\n",
      "GROUP BY level, YEAR(join_date)\n",
      "HAVING COUNT(id) > 5\n",
      "ORDER BY level, join_year;\n",
      "\n",
      "Trying candidate 1\n",
      "❌ Candidate 1 failed with error: Error executing query: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near 'AS avg_tenure_years,\n",
      "WITH RECURSIVE org_hierarchy AS (\n",
      "    SELECT e.id, e.name, e.manager_id, e.join_date, 0 AS level \n",
      "    FROM employees e \n",
      "    JOIN employment_statuses es ON e.id = es.employee_id\n",
      "    WHERE e.manager_id IS NULL\n",
      "    AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "    AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "    AND es.location_id IN ('[LOCATION_IDS]')\n",
      "    UNION ALL \n",
      "    SELECT e.id, e.name, e.manager_id, e.join_date, h.level + 1 \n",
      "    FROM employees e \n",
      "    JOIN org_hierarchy h ON e.manager_id = h.id\n",
      "    JOIN employment_statuses es ON e.id = es.employee_id\n",
      "    WHERE es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "    AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "    AND es.location_id IN ('[LOCATION_IDS]')\n",
      ")\n",
      "SELECT \n",
      "    level AS management_level,\n",
      "    YEAR(join_date) AS join_year,\n",
      "    AVG(DATEDIFF(CURRENT_DATE, join_date)/365 AS avg_tenure_years,\n",
      "    COUNT(id) AS employee_count\n",
      "FROM org_hierarchy\n",
      "WHERE join_date IS NOT NULL\n",
      "GROUP BY level, YEAR(join_date)\n",
      "HAVING COUNT(id) > 5\n",
      "ORDER BY level, join_year;\n",
      "\n",
      "Trying candidate 2\n",
      "❌ Candidate 2 failed with error: Error executing query: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near 'AS avg_tenure_years,\n",
      "WITH employee_levels AS (\n",
      "    SELECT \n",
      "        e.id,\n",
      "        e.name,\n",
      "        e.join_date,\n",
      "        CASE \n",
      "            WHEN e.id IN (SELECT DISTINCT manager_id FROM employees WHERE manager_id IS NOT NULL) THEN 'Manager'\n",
      "            ELSE 'Non-Manager'\n",
      "        END AS management_level\n",
      "    FROM employees e\n",
      ")\n",
      "SELECT \n",
      "    management_level,\n",
      "    YEAR(join_date) AS join_year,\n",
      "    AVG(DATEDIFF(CURRENT_DATE, join_date)/365 AS avg_tenure_years,\n",
      "    COUNT(id) AS employee_count\n",
      "FROM employee_levels\n",
      "WHERE join_date IS NOT NULL\n",
      "GROUP BY management_level, YEAR(join_date)\n",
      "HAVING COUNT(id) > 5\n",
      "ORDER BY management_level, join_year;\n",
      "\n",
      "Trying candidate 3\n",
      "❌ Candidate 3 failed with error: Error executing query: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near 'AS avg_tenure_years,\n",
      "No working candidates found. Retrying... (1/3)\n",
      "Processing... question 130_2 Retry attempt: 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:29:01,567 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 2):\n",
      "WITH employee_levels AS (\n",
      "    SELECT \n",
      "        e.id,\n",
      "        e.name,\n",
      "        e.join_date,\n",
      "        CASE \n",
      "            WHEN e.id IN (SELECT DISTINCT manager_id FROM employees WHERE manager_id IS NOT NULL) THEN 'Manager'\n",
      "            ELSE 'Non-Manager'\n",
      "        END AS management_level\n",
      "    FROM employees e\n",
      "    JOIN employment_statuses es ON e.id = es.employee_id\n",
      "    WHERE es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "      AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "      AND es.location_id IN ('[LOCATION_IDS]')\n",
      ")\n",
      "SELECT \n",
      "    management_level,\n",
      "    YEAR(join_date) AS join_year,\n",
      "    AVG(DATEDIFF(STR_TO_DATE('11 April 2025', '%d %M %Y'), join_date)/365) AS avg_tenure_years,\n",
      "    COUNT(id) AS employee_count\n",
      "FROM employee_levels\n",
      "WHERE join_date IS NOT NULL\n",
      "GROUP BY management_level, YEAR(join_date)\n",
      "HAVING COUNT(id) > 5\n",
      "ORDER BY management_level, join_year;\n",
      "\n",
      "Trying candidate 1\n",
      "❌ Candidate 1 failed with error: Error executing query: 1054 (42S22): Unknown column 'e.join_date' in 'field list'\n",
      "WITH employee_levels AS (\n",
      "    SELECT \n",
      "        e.id,\n",
      "        e.name,\n",
      "        e.join_date,\n",
      "        CASE \n",
      "            WHEN EXISTS (SELECT 1 FROM employees WHERE manager_id = e.id) THEN 'Manager'\n",
      "            ELSE 'Non-Manager'\n",
      "        END AS management_level\n",
      "    FROM employees e\n",
      "    JOIN employment_statuses es ON e.id = es.employee_id\n",
      "    WHERE es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "      AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "      AND es.location_id IN ('[LOCATION_IDS]')\n",
      ")\n",
      "SELECT \n",
      "    management_level,\n",
      "    YEAR(join_date) AS join_year,\n",
      "    ROUND(AVG(DATEDIFF(STR_TO_DATE('11 April 2025', '%d %M %Y'), join_date)/365), 2) AS avg_tenure_years,\n",
      "    COUNT(id) AS employee_count\n",
      "FROM employee_levels\n",
      "WHERE join_date IS NOT NULL\n",
      "GROUP BY management_level, YEAR(join_date)\n",
      "HAVING COUNT(id) > 5\n",
      "ORDER BY management_level, join_year;\n",
      "\n",
      "Trying candidate 2\n",
      "❌ Candidate 2 failed with error: Error executing query: 1054 (42S22): Unknown column 'e.join_date' in 'field list'\n",
      "WITH managers AS (\n",
      "    SELECT DISTINCT manager_id \n",
      "    FROM employees \n",
      "    WHERE manager_id IS NOT NULL\n",
      "),\n",
      "employee_levels AS (\n",
      "    SELECT \n",
      "        e.id,\n",
      "        e.name,\n",
      "        e.join_date,\n",
      "        CASE \n",
      "            WHEN m.manager_id IS NOT NULL THEN 'Manager'\n",
      "            ELSE 'Non-Manager'\n",
      "        END AS management_level\n",
      "    FROM employees e\n",
      "    LEFT JOIN managers m ON e.id = m.manager_id\n",
      "    JOIN employment_statuses es ON e.id = es.employee_id\n",
      "    WHERE es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "      AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "      AND es.location_id IN ('[LOCATION_IDS]')\n",
      ")\n",
      "SELECT \n",
      "    management_level,\n",
      "    YEAR(join_date) AS join_year,\n",
      "    ROUND(AVG(DATEDIFF(STR_TO_DATE('11 April 2025', '%d %M %Y'), join_date)/365), 2) AS avg_tenure_years,\n",
      "    COUNT(id) AS employee_count\n",
      "FROM employee_levels\n",
      "WHERE join_date IS NOT NULL\n",
      "GROUP BY management_level, YEAR(join_date)\n",
      "HAVING COUNT(id) > 5\n",
      "ORDER BY management_level, join_year;\n",
      "\n",
      "Trying candidate 3\n",
      "❌ Candidate 3 failed with error: Error executing query: 1054 (42S22): Unknown column 'e.join_date' in 'field list'\n",
      "No working candidates found. Retrying... (2/3)\n",
      "Processing... question 130_2 Retry attempt: 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:29:42,927 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 3):\n",
      "WITH managers AS (\n",
      "    SELECT DISTINCT manager_id \n",
      "    FROM employees \n",
      "    WHERE manager_id IS NOT NULL\n",
      "),\n",
      "employee_levels AS (\n",
      "    SELECT \n",
      "        e.id,\n",
      "        e.name,\n",
      "        e.start_date AS join_date,\n",
      "        CASE \n",
      "            WHEN m.manager_id IS NOT NULL THEN 'Manager'\n",
      "            ELSE 'Non-Manager'\n",
      "        END AS management_level\n",
      "    FROM employees e\n",
      "    LEFT JOIN managers m ON e.id = m.manager_id\n",
      "    JOIN employment_statuses es ON e.id = es.employee_id\n",
      "    WHERE es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "      AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "      AND es.location_id IN ('[LOCATION_IDS]')\n",
      ")\n",
      "SELECT \n",
      "    management_level,\n",
      "    YEAR(join_date) AS join_year,\n",
      "    ROUND(AVG(DATEDIFF(STR_TO_DATE('11 April 2025', '%d %M %Y'), join_date)/365, 2) AS avg_tenure_years,\n",
      "    COUNT(id) AS employee_count\n",
      "FROM employee_levels\n",
      "WHERE join_date IS NOT NULL\n",
      "GROUP BY management_level, YEAR(join_date)\n",
      "HAVING COUNT(id) > 5\n",
      "ORDER BY management_level, join_year;\n",
      "\n",
      "Trying candidate 1\n",
      "❌ Candidate 1 failed with error: Error executing query: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near ' 2) AS avg_tenure_years,\n",
      "WITH managers AS (\n",
      "    SELECT DISTINCT e.id AS manager_id\n",
      "    FROM employees e\n",
      "    WHERE EXISTS (\n",
      "        SELECT 1 FROM employees WHERE manager_id = e.id\n",
      "    )\n",
      "),\n",
      "employee_levels AS (\n",
      "    SELECT \n",
      "        e.id,\n",
      "        e.name,\n",
      "        e.start_date AS join_date,\n",
      "        CASE \n",
      "            WHEN m.manager_id IS NOT NULL THEN 'Manager'\n",
      "            ELSE 'Non-Manager'\n",
      "        END AS management_level\n",
      "    FROM employees e\n",
      "    LEFT JOIN managers m ON e.id = m.manager_id\n",
      "    JOIN employment_statuses es ON e.id = es.employee_id\n",
      "    WHERE es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "      AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "      AND es.location_id IN ('[LOCATION_IDS]')\n",
      ")\n",
      "SELECT \n",
      "    management_level,\n",
      "    YEAR(join_date) AS join_year,\n",
      "    ROUND(AVG(DATEDIFF(STR_TO_DATE('11 April 2025', '%d %M %Y'), join_date)/365, 2) AS avg_tenure_years,\n",
      "    COUNT(id) AS employee_count\n",
      "FROM employee_levels\n",
      "WHERE join_date IS NOT NULL\n",
      "GROUP BY management_level, YEAR(join_date)\n",
      "HAVING COUNT(id) > 5\n",
      "ORDER BY management_level, join_year;\n",
      "\n",
      "Trying candidate 2\n",
      "❌ Candidate 2 failed with error: Error executing query: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near ' 2) AS avg_tenure_years,\n",
      "WITH employee_management_levels AS (\n",
      "    SELECT \n",
      "        e.id,\n",
      "        e.name,\n",
      "        e.start_date AS join_date,\n",
      "        CASE \n",
      "            WHEN EXISTS (SELECT 1 FROM employees WHERE manager_id = e.id) THEN 'Manager'\n",
      "            ELSE 'Non-Manager'\n",
      "        END AS management_level\n",
      "    FROM employees e\n",
      "    JOIN employment_statuses es ON e.id = es.employee_id\n",
      "    WHERE es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "      AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "      AND es.location_id IN ('[LOCATION_IDS]')\n",
      ")\n",
      "SELECT \n",
      "    management_level,\n",
      "    YEAR(join_date) AS join_year,\n",
      "    ROUND(AVG(DATEDIFF(STR_TO_DATE('11 April 2025', '%d %M %Y'), join_date)/365, 2) AS avg_tenure_years,\n",
      "    COUNT(id) AS employee_count\n",
      "FROM employee_management_levels\n",
      "WHERE join_date IS NOT NULL\n",
      "GROUP BY management_level, YEAR(join_date)\n",
      "HAVING COUNT(id) > 5\n",
      "ORDER BY management_level, join_year;\n",
      "\n",
      "Trying candidate 3\n",
      "❌ Candidate 3 failed with error: Error executing query: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near ' 2) AS avg_tenure_years,\n",
      "No working candidates found. Retrying... (3/3)\n",
      "⚠️ Failed to find working SQL query after 3 attempts.\n",
      "130_3: ⚠️ Skipped due to column not found error.\n",
      "Processing... question 131_1 Retry attempt: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:30:28,293 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 1):\n",
      "WITH late_attendance AS (\n",
      "    SELECT \n",
      "        adr.employee_id,\n",
      "        (adr.attendance_time_in - adr.shift_time_in) / (1000 * 60) AS late_minutes\n",
      "    FROM \n",
      "        attendance_detail_recapitulations adr\n",
      "    JOIN \n",
      "        attendances a ON adr.attendance_id = a.id\n",
      "    JOIN \n",
      "        attendance_statuses ast ON a.attendance_status_in_id = ast.id\n",
      "    WHERE \n",
      "        adr.date BETWEEN DATE_SUB(STR_TO_DATE('10 April 2025', '%d %M %Y'), INTERVAL 3 MONTH) \n",
      "        AND STR_TO_DATE('10 April 2025', '%d %M %Y')\n",
      "        AND ast.name = 'Terlambat > 5 menit'\n",
      ")\n",
      "SELECT \n",
      "    o.name AS department,\n",
      "    COUNT(*) AS total_late_occurrences,\n",
      "    ROUND(AVG(la.late_minutes), 2) AS avg_late_minutes,\n",
      "    MIN(la.late_minutes) AS min_late_minutes,\n",
      "    MAX(la.late_minutes) AS max_late_minutes\n",
      "FROM \n",
      "    late_attendance la\n",
      "JOIN \n",
      "    employees e ON la.employee_id = e.id\n",
      "JOIN \n",
      "    employment_statuses es ON e.id = es.employee_id\n",
      "    AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "    AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "    AND es.location_id IN ('[LOCATION_IDS]')\n",
      "JOIN \n",
      "    organizations o ON es.organization_id = o.id\n",
      "GROUP BY \n",
      "    o.name\n",
      "ORDER BY \n",
      "    total_late_occurrences DESC;\n",
      "\n",
      "Trying candidate 1\n",
      "✅ Candidate 1 executed successfully!\n",
      "131_2: ✅ Original query executed successfully!\n",
      "Processing... question 131_3 Retry attempt: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:31:28,754 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 1):\n",
      "WITH employee_tenure AS (\n",
      "    SELECT \n",
      "        e.id AS employee_id,\n",
      "        et.name AS employment_type,\n",
      "        TIMESTAMPDIFF(MONTH, e.join_date, STR_TO_DATE('10 April 2025', '%d %M %Y')) AS tenure_months\n",
      "    FROM \n",
      "        employees e\n",
      "    JOIN \n",
      "        employment_statuses es ON e.id = es.employee_id\n",
      "        AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND es.location_id IN ('[LOCATION_IDS]')\n",
      "    JOIN \n",
      "        employment_types et ON es.employment_type_id = et.id\n",
      "    WHERE \n",
      "        e.active = TRUE\n",
      "),\n",
      "late_counts AS (\n",
      "    SELECT \n",
      "        adr.employee_id,\n",
      "        COUNT(*) AS late_count\n",
      "    FROM \n",
      "        attendance_detail_recapitulations adr\n",
      "    JOIN \n",
      "        employment_statuses es ON adr.employee_id = es.employee_id\n",
      "        AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND es.location_id IN ('[LOCATION_IDS]')\n",
      "    JOIN \n",
      "        attendances a ON adr.attendance_id = a.id\n",
      "    WHERE \n",
      "        adr.date BETWEEN DATE_SUB(STR_TO_DATE('10 April 2025', '%d %M %Y'), INTERVAL 12 MONTH) \n",
      "        AND STR_TO_DATE('10 April 2025', '%d %M %Y')\n",
      "        AND a.attendance_status_in_id IN (\n",
      "            SELECT id \n",
      "            FROM attendance_statuses \n",
      "            WHERE name = 'Terlambat > 5 menit'\n",
      "        )\n",
      "    GROUP BY \n",
      "        adr.employee_id\n",
      "),\n",
      "stats AS (\n",
      "    SELECT \n",
      "        et.employment_type,\n",
      "        AVG(et.tenure_months) AS avg_tenure,\n",
      "        AVG(COALESCE(lc.late_count, 0)) AS avg_late,\n",
      "        STDDEV_POP(et.tenure_months) AS std_tenure,\n",
      "        STDDEV_POP(COALESCE(lc.late_count, 0)) AS std_late\n",
      "    FROM \n",
      "        employee_tenure et\n",
      "    LEFT JOIN \n",
      "        late_counts lc ON et.employee_id = lc.employee_id\n",
      "    GROUP BY \n",
      "        et.employment_type\n",
      ")\n",
      "SELECT \n",
      "    et.employment_type,\n",
      "    COUNT(DISTINCT et.employee_id) AS employee_count,\n",
      "    ROUND(AVG(et.tenure_months), 1) AS avg_tenure_months,\n",
      "    ROUND(AVG(COALESCE(lc.late_count, 0)), 1) AS avg_late_count,\n",
      "    ROUND(\n",
      "        SUM((et.tenure_months - s.avg_tenure) * (COALESCE(lc.late_count, 0) - s.avg_late)) / \n",
      "        (COUNT(*) * s.std_tenure * s.std_late),\n",
      "        3\n",
      "    ) AS correlation_coefficient\n",
      "FROM \n",
      "    employee_tenure et\n",
      "LEFT JOIN \n",
      "    late_counts lc ON et.employee_id = lc.employee_id\n",
      "JOIN \n",
      "    stats s ON et.employment_type = s.employment_type\n",
      "GROUP BY \n",
      "    et.employment_type\n",
      "ORDER BY \n",
      "    correlation_coefficient DESC;\n",
      "\n",
      "Trying candidate 1\n",
      "❌ Candidate 1 failed with error: Error executing query: 1054 (42S22): Unknown column 'e.join_date' in 'field list'\n",
      "WITH employee_tenure AS (\n",
      "    SELECT \n",
      "        e.id AS employee_id,\n",
      "        et.name AS employment_type,\n",
      "        TIMESTAMPDIFF(MONTH, e.join_date, STR_TO_DATE('10 April 2025', '%d %M %Y')) AS tenure_months\n",
      "    FROM \n",
      "        employees e\n",
      "    JOIN \n",
      "        employment_statuses es ON e.id = es.employee_id\n",
      "        AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND es.location_id IN ('[LOCATION_IDS]')\n",
      "    JOIN \n",
      "        employment_types et ON es.employment_type_id = et.id\n",
      "    WHERE \n",
      "        e.active = TRUE\n",
      "),\n",
      "late_counts AS (\n",
      "    SELECT \n",
      "        adr.employee_id,\n",
      "        COUNT(*) AS late_count\n",
      "    FROM \n",
      "        attendance_detail_recapitulations adr\n",
      "    JOIN \n",
      "        employment_statuses es ON adr.employee_id = es.employee_id\n",
      "        AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND es.location_id IN ('[LOCATION_IDS]')\n",
      "    JOIN \n",
      "        attendances a ON adr.attendance_id = a.id\n",
      "    JOIN \n",
      "        attendance_statuses ast ON a.attendance_status_in_id = ast.id\n",
      "    WHERE \n",
      "        adr.date BETWEEN DATE_SUB(STR_TO_DATE('10 April 2025', '%d %M %Y'), INTERVAL 12 MONTH) \n",
      "        AND STR_TO_DATE('10 April 2025', '%d %M %Y')\n",
      "        AND ast.name = 'Terlambat > 5 menit'\n",
      "    GROUP BY \n",
      "        adr.employee_id\n",
      ")\n",
      "SELECT \n",
      "    et.employment_type,\n",
      "    COUNT(DISTINCT et.employee_id) AS employee_count,\n",
      "    ROUND(AVG(et.tenure_months), 1) AS avg_tenure_months,\n",
      "    ROUND(AVG(COALESCE(lc.late_count, 0)), 1) AS avg_late_count,\n",
      "    (\n",
      "        SELECT \n",
      "            ROUND(\n",
      "                (SUM((t.tenure_months - avg_tenure) * (COALESCE(l.late_count, 0) - avg_late)) /\n",
      "                (COUNT(*) * STDDEV_POP(t.tenure_months) * STDDEV_POP(COALESCE(l.late_count, 0))),\n",
      "                3\n",
      "            )\n",
      "        FROM \n",
      "            employee_tenure t\n",
      "        LEFT JOIN \n",
      "            late_counts l ON t.employee_id = l.employee_id\n",
      "        CROSS JOIN (\n",
      "            SELECT \n",
      "                AVG(tenure_months) AS avg_tenure,\n",
      "                AVG(COALESCE(late_count, 0)) AS avg_late\n",
      "            FROM \n",
      "                employee_tenure et\n",
      "            LEFT JOIN \n",
      "                late_counts lc ON et.employee_id = lc.employee_id\n",
      "            WHERE \n",
      "                et.employment_type = e.employment_type\n",
      "        ) stats\n",
      "        WHERE \n",
      "            t.employment_type = e.employment_type\n",
      "    ) AS correlation_coefficient\n",
      "FROM \n",
      "    employee_tenure e\n",
      "LEFT JOIN \n",
      "    late_counts lc ON e.employee_id = lc.employee_id\n",
      "GROUP BY \n",
      "    e.employment_type\n",
      "ORDER BY \n",
      "    correlation_coefficient DESC;\n",
      "\n",
      "Trying candidate 2\n",
      "❌ Candidate 2 failed with error: Error executing query: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near 'FROM \n",
      "WITH employee_tenure AS (\n",
      "    SELECT \n",
      "        e.id AS employee_id,\n",
      "        et.name AS employment_type,\n",
      "        TIMESTAMPDIFF(MONTH, e.join_date, STR_TO_DATE('10 April 2025', '%d %M %Y')) AS tenure_months\n",
      "    FROM \n",
      "        employees e\n",
      "    JOIN \n",
      "        employment_statuses es ON e.id = es.employee_id\n",
      "        AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND es.location_id IN ('[LOCATION_IDS]')\n",
      "    JOIN \n",
      "        employment_types et ON es.employment_type_id = et.id\n",
      "    WHERE \n",
      "        e.active = TRUE\n",
      "),\n",
      "late_counts AS (\n",
      "    SELECT \n",
      "        adr.employee_id,\n",
      "        COUNT(*) AS late_count\n",
      "    FROM \n",
      "        attendance_detail_recapitulations adr\n",
      "    JOIN \n",
      "        employment_statuses es ON adr.employee_id = es.employee_id\n",
      "        AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND es.location_id IN ('[LOCATION_IDS]')\n",
      "    JOIN \n",
      "        attendances a ON adr.attendance_id = a.id\n",
      "    JOIN \n",
      "        attendance_statuses ast ON a.attendance_status_in_id = ast.id\n",
      "    WHERE \n",
      "        adr.date BETWEEN DATE_SUB(STR_TO_DATE('10 April 2025', '%d %M %Y'), INTERVAL 12 MONTH) \n",
      "        AND STR_TO_DATE('10 April 2025', '%d %M %Y')\n",
      "        AND ast.name = 'Terlambat > 5 menit'\n",
      "    GROUP BY \n",
      "        adr.employee_id\n",
      "),\n",
      "correlation_data AS (\n",
      "    SELECT \n",
      "        et.employment_type,\n",
      "        et.employee_id,\n",
      "        et.tenure_months,\n",
      "        COALESCE(lc.late_count, 0) AS late_count\n",
      "    FROM \n",
      "        employee_tenure et\n",
      "    LEFT JOIN \n",
      "        late_counts lc ON et.employee_id = lc.employee_id\n",
      ")\n",
      "SELECT \n",
      "    cd.employment_type,\n",
      "    COUNT(DISTINCT cd.employee_id) AS employee_count,\n",
      "    ROUND(AVG(cd.tenure_months), 1) AS avg_tenure_months,\n",
      "    ROUND(AVG(cd.late_count), 1) AS avg_late_count,\n",
      "    ROUND(\n",
      "        (\n",
      "            SUM((cd.tenure_months - avg_t.avg_tenure) * (cd.late_count - avg_l.avg_late)) /\n",
      "            (COUNT(*) * STDDEV_POP(cd.tenure_months) * STDDEV_POP(cd.late_count))\n",
      "        , 3\n",
      "    ) AS correlation_coefficient\n",
      "FROM \n",
      "    correlation_data cd\n",
      "CROSS JOIN (\n",
      "    SELECT \n",
      "        AVG(tenure_months) AS avg_tenure\n",
      "    FROM \n",
      "        correlation_data\n",
      ") avg_t\n",
      "CROSS JOIN (\n",
      "    SELECT \n",
      "        AVG(late_count) AS avg_late\n",
      "    FROM \n",
      "        correlation_data\n",
      ") avg_l\n",
      "GROUP BY \n",
      "    cd.employment_type\n",
      "ORDER BY \n",
      "    correlation_coefficient DESC;\n",
      "\n",
      "Trying candidate 3\n",
      "❌ Candidate 3 failed with error: Error executing query: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near 'FROM \n",
      "No working candidates found. Retrying... (1/3)\n",
      "Processing... question 131_3 Retry attempt: 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:33:18,094 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 2):\n",
      "WITH employee_tenure AS (\n",
      "    SELECT \n",
      "        e.id AS employee_id,\n",
      "        et.name AS employment_type,\n",
      "        TIMESTAMPDIFF(MONTH, e.join_date, STR_TO_DATE('10 April 2025', '%d %M %Y')) AS tenure_months\n",
      "    FROM \n",
      "        employees e\n",
      "    JOIN \n",
      "        employment_statuses es ON e.id = es.employee_id\n",
      "        AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND es.location_id IN ('[LOCATION_IDS]')\n",
      "    JOIN \n",
      "        employment_types et ON es.employment_type_id = et.id\n",
      "    WHERE \n",
      "        e.active = TRUE\n",
      "),\n",
      "late_counts AS (\n",
      "    SELECT \n",
      "        adr.employee_id,\n",
      "        COUNT(*) AS late_count\n",
      "    FROM \n",
      "        attendance_detail_recapitulations adr\n",
      "    JOIN \n",
      "        employment_statuses es ON adr.employee_id = es.employee_id\n",
      "        AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND es.location_id IN ('[LOCATION_IDS]')\n",
      "    JOIN \n",
      "        attendances a ON adr.attendance_id = a.id\n",
      "    JOIN \n",
      "        attendance_statuses ast ON a.attendance_status_in_id = ast.id\n",
      "    WHERE \n",
      "        adr.date BETWEEN DATE_SUB(STR_TO_DATE('10 April 2025', '%d %M %Y'), INTERVAL 12 MONTH) \n",
      "        AND STR_TO_DATE('10 April 2025', '%d %M %Y')\n",
      "        AND ast.name = 'Terlambat > 5 menit'\n",
      "    GROUP BY \n",
      "        adr.employee_id\n",
      "),\n",
      "correlation_data AS (\n",
      "    SELECT \n",
      "        et.employment_type,\n",
      "        et.employee_id,\n",
      "        et.tenure_months,\n",
      "        COALESCE(lc.late_count, 0) AS late_count\n",
      "    FROM \n",
      "        employee_tenure et\n",
      "    LEFT JOIN \n",
      "        late_counts lc ON et.employee_id = lc.employee_id\n",
      "),\n",
      "avg_values AS (\n",
      "    SELECT \n",
      "        AVG(tenure_months) AS avg_tenure,\n",
      "        AVG(late_count) AS avg_late\n",
      "    FROM \n",
      "        correlation_data\n",
      ")\n",
      "SELECT \n",
      "    cd.employment_type,\n",
      "    COUNT(DISTINCT cd.employee_id) AS employee_count,\n",
      "    ROUND(AVG(cd.tenure_months), 1) AS avg_tenure_months,\n",
      "    ROUND(AVG(cd.late_count), 1) AS avg_late_count,\n",
      "    ROUND(\n",
      "        (\n",
      "            SUM((cd.tenure_months - av.avg_tenure) * (cd.late_count - av.avg_late)) /\n",
      "            (COUNT(*) * STDDEV_POP(cd.tenure_months) * STDDEV_POP(cd.late_count))\n",
      "        ), 3\n",
      "    ) AS correlation_coefficient\n",
      "FROM \n",
      "    correlation_data cd\n",
      "CROSS JOIN \n",
      "    avg_values av\n",
      "GROUP BY \n",
      "    cd.employment_type\n",
      "ORDER BY \n",
      "    correlation_coefficient DESC;\n",
      "\n",
      "Trying candidate 1\n",
      "❌ Candidate 1 failed with error: Error executing query: 1054 (42S22): Unknown column 'e.join_date' in 'field list'\n",
      "WITH employee_tenure AS (\n",
      "    SELECT \n",
      "        e.id AS employee_id,\n",
      "        et.name AS employment_type,\n",
      "        TIMESTAMPDIFF(MONTH, e.join_date, STR_TO_DATE('10 April 2025', '%d %M %Y')) AS tenure_months\n",
      "    FROM \n",
      "        employees e\n",
      "    JOIN \n",
      "        employment_statuses es ON e.id = es.employee_id\n",
      "        AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND es.location_id IN ('[LOCATION_IDS]')\n",
      "    JOIN \n",
      "        employment_types et ON es.employment_type_id = et.id\n",
      "    WHERE \n",
      "        e.active = TRUE\n",
      "),\n",
      "late_counts AS (\n",
      "    SELECT \n",
      "        adr.employee_id,\n",
      "        COUNT(*) AS late_count\n",
      "    FROM \n",
      "        attendance_detail_recapitulations adr\n",
      "    JOIN \n",
      "        employment_statuses es ON adr.employee_id = es.employee_id\n",
      "        AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND es.location_id IN ('[LOCATION_IDS]')\n",
      "    JOIN \n",
      "        attendances a ON adr.attendance_id = a.id\n",
      "    JOIN \n",
      "        attendance_statuses ast ON a.attendance_status_in_id = ast.id\n",
      "    WHERE \n",
      "        adr.date BETWEEN DATE_SUB(STR_TO_DATE('10 April 2025', '%d %M %Y'), INTERVAL 12 MONTH) \n",
      "        AND STR_TO_DATE('10 April 2025', '%d %M %Y')\n",
      "        AND ast.name = 'Terlambat > 5 menit'\n",
      "    GROUP BY \n",
      "        adr.employee_id\n",
      ")\n",
      "SELECT \n",
      "    et.employment_type,\n",
      "    COUNT(DISTINCT et.employee_id) AS employee_count,\n",
      "    ROUND(AVG(et.tenure_months), 1) AS avg_tenure_months,\n",
      "    ROUND(AVG(COALESCE(lc.late_count, 0)), 1) AS avg_late_count,\n",
      "    ROUND(\n",
      "        CORR(et.tenure_months, COALESCE(lc.late_count, 0)),\n",
      "        3\n",
      "    ) AS correlation_coefficient\n",
      "FROM \n",
      "    employee_tenure et\n",
      "LEFT JOIN \n",
      "    late_counts lc ON et.employee_id = lc.employee_id\n",
      "GROUP BY \n",
      "    et.employment_type\n",
      "ORDER BY \n",
      "    correlation_coefficient DESC;\n",
      "\n",
      "Trying candidate 2\n",
      "❌ Candidate 2 failed with error: Error executing query: 1054 (42S22): Unknown column 'e.join_date' in 'field list'\n",
      "WITH employee_tenure AS (\n",
      "    SELECT \n",
      "        e.id AS employee_id,\n",
      "        et.name AS employment_type,\n",
      "        TIMESTAMPDIFF(MONTH, e.join_date, STR_TO_DATE('10 April 2025', '%d %M %Y')) AS tenure_months\n",
      "    FROM \n",
      "        employees e\n",
      "    JOIN \n",
      "        employment_statuses es ON e.id = es.employee_id\n",
      "        AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND es.location_id IN ('[LOCATION_IDS]')\n",
      "    JOIN \n",
      "        employment_types et ON es.employment_type_id = et.id\n",
      "    WHERE \n",
      "        e.active = TRUE\n",
      "),\n",
      "late_counts AS (\n",
      "    SELECT \n",
      "        adr.employee_id,\n",
      "        COUNT(*) AS late_count\n",
      "    FROM \n",
      "        attendance_detail_recapitulations adr\n",
      "    JOIN \n",
      "        employment_statuses es ON adr.employee_id = es.employee_id\n",
      "        AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND es.location_id IN ('[LOCATION_IDS]')\n",
      "    JOIN \n",
      "        attendances a ON adr.attendance_id = a.id\n",
      "    JOIN \n",
      "        attendance_statuses ast ON a.attendance_status_in_id = ast.id\n",
      "    WHERE \n",
      "        adr.date BETWEEN DATE_SUB(STR_TO_DATE('10 April 2025', '%d %M %Y'), INTERVAL 12 MONTH) \n",
      "        AND STR_TO_DATE('10 April 2025', '%d %M %Y')\n",
      "        AND ast.name = 'Terlambat > 5 menit'\n",
      "    GROUP BY \n",
      "        adr.employee_id\n",
      ")\n",
      "SELECT \n",
      "    et.employment_type,\n",
      "    COUNT(DISTINCT et.employee_id) AS employee_count,\n",
      "    ROUND(AVG(et.tenure_months), 1) AS avg_tenure_months,\n",
      "    ROUND(AVG(COALESCE(lc.late_count, 0)), 1) AS avg_late_count,\n",
      "    ROUND(\n",
      "        (\n",
      "            SUM((et.tenure_months - avg_t) * (COALESCE(lc.late_count, 0) - avg_l)) /\n",
      "            (COUNT(*) * STDDEV_POP(et.tenure_months) * STDDEV_POP(COALESCE(lc.late_count, 0)))\n",
      "        ), 3\n",
      "    ) AS correlation_coefficient\n",
      "FROM \n",
      "    employee_tenure et\n",
      "LEFT JOIN \n",
      "    late_counts lc ON et.employee_id = lc.employee_id\n",
      "CROSS JOIN (\n",
      "    SELECT \n",
      "        AVG(tenure_months) AS avg_t\n",
      "    FROM \n",
      "        employee_tenure\n",
      ") t\n",
      "CROSS JOIN (\n",
      "    SELECT \n",
      "        AVG(COALESCE(late_count, 0)) AS avg_l\n",
      "    FROM \n",
      "        late_counts\n",
      ") l\n",
      "GROUP BY \n",
      "    et.employment_type\n",
      "ORDER BY \n",
      "    correlation_coefficient DESC;\n",
      "\n",
      "Trying candidate 3\n",
      "❌ Candidate 3 failed with error: Error executing query: 1054 (42S22): Unknown column 'e.join_date' in 'field list'\n",
      "No working candidates found. Retrying... (2/3)\n",
      "Processing... question 131_3 Retry attempt: 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:34:55,984 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 3):\n",
      "WITH employee_tenure AS (\n",
      "    SELECT \n",
      "        e.id AS employee_id,\n",
      "        et.name AS employment_type,\n",
      "        TIMESTAMPDIFF(MONTH, e.start_date, STR_TO_DATE('11 April 2025', '%d %M %Y')) AS tenure_months\n",
      "    FROM \n",
      "        employees e\n",
      "    JOIN \n",
      "        employment_statuses es ON e.id = es.employee_id\n",
      "        AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND es.location_id IN ('[LOCATION_IDS]')\n",
      "    JOIN \n",
      "        employment_types et ON es.employment_type_id = et.id\n",
      "    WHERE \n",
      "        e.active = TRUE\n",
      "),\n",
      "late_counts AS (\n",
      "    SELECT \n",
      "        adr.employee_id,\n",
      "        COUNT(*) AS late_count\n",
      "    FROM \n",
      "        attendance_detail_recapitulations adr\n",
      "    JOIN \n",
      "        employment_statuses es ON adr.employee_id = es.employee_id\n",
      "        AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND es.location_id IN ('[LOCATION_IDS]')\n",
      "    JOIN \n",
      "        attendances a ON adr.attendance_id = a.id\n",
      "    JOIN \n",
      "        attendance_statuses ast ON a.attendance_status_in_id = ast.id\n",
      "    WHERE \n",
      "        adr.date BETWEEN DATE_SUB(STR_TO_DATE('11 April 2025', '%d %M %Y'), INTERVAL 12 MONTH) \n",
      "        AND STR_TO_DATE('11 April 2025', '%d %M %Y')\n",
      "        AND ast.name IN ('Terlambat > 5 menit', 'Terlambat <= 5 menit')\n",
      "    GROUP BY \n",
      "        adr.employee_id\n",
      ")\n",
      "SELECT \n",
      "    et.employment_type,\n",
      "    COUNT(DISTINCT et.employee_id) AS employee_count,\n",
      "    ROUND(AVG(et.tenure_months), 1) AS avg_tenure_months,\n",
      "    ROUND(AVG(COALESCE(lc.late_count, 0)), 1) AS avg_late_count,\n",
      "    ROUND(\n",
      "        (\n",
      "            SUM((et.tenure_months - avg_t) * (COALESCE(lc.late_count, 0) - avg_l)) /\n",
      "            NULLIF((COUNT(*) * STDDEV_POP(et.tenure_months) * STDDEV_POP(COALESCE(lc.late_count, 0))), 0)\n",
      "        ), 3\n",
      "    ) AS correlation_coefficient\n",
      "FROM \n",
      "    employee_tenure et\n",
      "LEFT JOIN \n",
      "    late_counts lc ON et.employee_id = lc.employee_id\n",
      "CROSS JOIN (\n",
      "    SELECT \n",
      "        AVG(tenure_months) AS avg_t\n",
      "    FROM \n",
      "        employee_tenure\n",
      ") t\n",
      "CROSS JOIN (\n",
      "    SELECT \n",
      "        AVG(COALESCE(late_count, 0)) AS avg_l\n",
      "    FROM \n",
      "        late_counts\n",
      ") l\n",
      "GROUP BY \n",
      "    et.employment_type\n",
      "ORDER BY \n",
      "    correlation_coefficient DESC;\n",
      "\n",
      "Trying candidate 1\n",
      "✅ Candidate 1 executed successfully!\n",
      "Processing... question 132_1 Retry attempt: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:36:20,666 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 1):\n",
      "SELECT \n",
      "    organizations.name AS departemen, \n",
      "    DATE_FORMAT(attendance_detail_recapitulations.date, '%Y-%m') AS bulan, \n",
      "    SUM(attendance_detail_recapitulations.paid_overtime/3600000 * 50000) AS total_biaya_lembur \n",
      "FROM \n",
      "    attendance_detail_recapitulations \n",
      "    JOIN employment_statuses ON attendance_detail_recapitulations.employee_id = employment_statuses.employee_id \n",
      "    JOIN organizations ON employment_statuses.organization_id = organizations.id \n",
      "WHERE \n",
      "    attendance_detail_recapitulations.date BETWEEN DATE_SUB(CAST(STR_TO_DATE('10 April 2025', '%d %M %Y') AS DATE, INTERVAL 6 MONTH) AND CAST(STR_TO_DATE('10 April 2025', '%d %M %Y') AS DATE) \n",
      "    AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]') \n",
      "    AND employment_statuses.job_level_id IN ('[JOB_LEVEL_IDS]') \n",
      "    AND employment_statuses.location_id IN ('[LOCATION_IDS]') \n",
      "GROUP BY \n",
      "    organizations.name, \n",
      "    DATE_FORMAT(attendance_detail_recapitulations.date, '%Y-%m') \n",
      "ORDER BY \n",
      "    departemen, \n",
      "    bulan;\n",
      "\n",
      "Trying candidate 1\n",
      "❌ Candidate 1 failed with error: Error executing query: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near ' INTERVAL 6 MONTH) AND CAST(STR_TO_DATE('10 April 2025', '%d %M %Y') AS DATE)...' at line 10\n",
      "SELECT \n",
      "    organizations.name AS departemen, \n",
      "    DATE_FORMAT(attendance_detail_recapitulations.date, '%Y-%m') AS bulan, \n",
      "    SUM(attendance_detail_recapitulations.paid_overtime/3600000 * 50000) AS total_biaya_lembur \n",
      "FROM \n",
      "    attendance_detail_recapitulations \n",
      "    JOIN employees ON attendance_detail_recapitulations.employee_id = employees.id \n",
      "    JOIN employment_statuses ON employees.id = employment_statuses.employee_id \n",
      "    JOIN organizations ON employment_statuses.organization_id = organizations.id \n",
      "WHERE \n",
      "    attendance_detail_recapitulations.date BETWEEN DATE_SUB(CAST(STR_TO_DATE('10 April 2025', '%d %M %Y') AS DATE, INTERVAL 6 MONTH) AND CAST(STR_TO_DATE('10 April 2025', '%d %M %Y') AS DATE) \n",
      "    AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]') \n",
      "    AND employment_statuses.job_level_id IN ('[JOB_LEVEL_IDS]') \n",
      "    AND employment_statuses.location_id IN ('[LOCATION_IDS]') \n",
      "    AND employees.active = TRUE \n",
      "GROUP BY \n",
      "    organizations.name, \n",
      "    DATE_FORMAT(attendance_detail_recapitulations.date, '%Y-%m') \n",
      "ORDER BY \n",
      "    departemen, \n",
      "    bulan;\n",
      "\n",
      "Trying candidate 2\n",
      "❌ Candidate 2 failed with error: Error executing query: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near ' INTERVAL 6 MONTH) AND CAST(STR_TO_DATE('10 April 2025', '%d %M %Y') AS DATE)...' at line 11\n",
      "WITH date_range AS (\n",
      "    SELECT \n",
      "        DATE_SUB(CAST(STR_TO_DATE('10 April 2025', '%d %M %Y') AS DATE), INTERVAL 6 MONTH) AS start_date,\n",
      "        CAST(STR_TO_DATE('10 April 2025', '%d %M %Y') AS DATE) AS end_date\n",
      ")\n",
      "SELECT \n",
      "    organizations.name AS departemen, \n",
      "    DATE_FORMAT(attendance_detail_recapitulations.date, '%Y-%m') AS bulan, \n",
      "    SUM(attendance_detail_recapitulations.paid_overtime/3600000 * 50000) AS total_biaya_lembur \n",
      "FROM \n",
      "    attendance_detail_recapitulations \n",
      "    JOIN employment_statuses ON attendance_detail_recapitulations.employee_id = employment_statuses.employee_id \n",
      "    JOIN organizations ON employment_statuses.organization_id = organizations.id,\n",
      "    date_range\n",
      "WHERE \n",
      "    attendance_detail_recapitulations.date BETWEEN date_range.start_date AND date_range.end_date\n",
      "    AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]') \n",
      "    AND employment_statuses.job_level_id IN ('[JOB_LEVEL_IDS]') \n",
      "    AND employment_statuses.location_id IN ('[LOCATION_IDS]') \n",
      "GROUP BY \n",
      "    organizations.name, \n",
      "    DATE_FORMAT(attendance_detail_recapitulations.date, '%Y-%m') \n",
      "ORDER BY \n",
      "    departemen, \n",
      "    bulan;\n",
      "\n",
      "Trying candidate 3\n",
      "✅ Candidate 3 executed successfully!\n",
      "132_2: ✅ Original query executed successfully!\n",
      "132_3: ✅ Original query executed successfully!\n",
      "133_1: ✅ Original query executed successfully!\n",
      "133_2: ✅ Original query executed successfully!\n",
      "133_3: ✅ Original query executed successfully!\n",
      "134_1: ✅ Original query executed successfully!\n",
      "134_2: ✅ Original query executed successfully!\n",
      "134_3: ✅ Original query executed successfully!\n",
      "135_1: ⚠️ Skipped due to column not found error.\n",
      "135_2: ✅ Original query executed successfully!\n",
      "135_3: ⚠️ Skipped due to column not found error.\n",
      "136_1: ✅ Original query executed successfully!\n",
      "Processing... question 136_2 Retry attempt: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:37:08,409 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 1):\n",
      "SELECT \n",
      "    DATE_FORMAT(attendance_detail_recapitulations.date, '%Y-%m') AS bulan,\n",
      "    SUM(attendance_detail_recapitulations.paid_overtime/3600000) AS jam_lembur_dibayarkan,\n",
      "    SUM(attendance_detail_recapitulations.requested_overtime/3600000) AS jam_lembur_diajukan,\n",
      "    CASE \n",
      "        WHEN SUM(attendance_detail_recapitulations.requested_overtime) = 0 THEN 0 \n",
      "        ELSE SUM(attendance_detail_recapitulations.paid_overtime)/SUM(attendance_detail_recapitulations.requested_overtime) \n",
      "    END AS rasio_persetujuan\n",
      "FROM \n",
      "    attendance_detail_recapitulations\n",
      "JOIN \n",
      "    employment_statuses ON attendance_detail_recapitulations.employee_id = employment_statuses.employee_id\n",
      "WHERE \n",
      "    attendance_detail_recapitulations.date >= DATE_SUB(STR_TO_DATE('11 April 2025', '%d %M %Y'), INTERVAL 1 YEAR)\n",
      "    AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "    AND employment_statuses.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "    AND employment_statuses.location_id IN ('[LOCATION_IDS]')\n",
      "GROUP BY \n",
      "    DATE_FORMAT(attendance_detail_recapitulations.date, '%Y-%m')\n",
      "ORDER BY \n",
      "    bulan;\n",
      "\n",
      "Trying candidate 1\n",
      "✅ Candidate 1 executed successfully!\n",
      "Processing... question 136_3 Retry attempt: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:38:00,140 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 1):\n",
      "WITH dept_overtime AS (\n",
      "  SELECT \n",
      "    organizations.name AS department, \n",
      "    SUM(attendance_detail_recapitulations.paid_overtime/3600000) AS total_dept_overtime \n",
      "  FROM attendance_detail_recapitulations \n",
      "  JOIN employment_statuses ON attendance_detail_recapitulations.employee_id = employment_statuses.employee_id \n",
      "  JOIN organizations ON employment_statuses.organization_id = organizations.id \n",
      "  WHERE attendance_detail_recapitulations.date >= DATE_SUB(CURDATE(), INTERVAL 3 MONTH) \n",
      "    AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]') \n",
      "    AND employment_statuses.job_level_id IN ('[JOB_LEVEL_IDS]') \n",
      "    AND employment_statuses.location_id IN ('[LOCATION_IDS]') \n",
      "  GROUP BY organizations.name\n",
      "),\n",
      "employee_overtime AS (\n",
      "  SELECT \n",
      "    employees.name AS employee_name, \n",
      "    organizations.name AS department, \n",
      "    SUM(attendance_detail_recapitulations.paid_overtime/3600000) AS overtime_hours\n",
      "  FROM attendance_detail_recapitulations\n",
      "  JOIN employment_statuses ON attendance_detail_recapitulations.employee_id = employment_statuses.employee_id\n",
      "  JOIN organizations ON employment_statuses.organization_id = organizations.id\n",
      "  JOIN employees ON attendance_detail_recapitulations.employee_id = employees.id\n",
      "  WHERE attendance_detail_recapitulations.date >= DATE_SUB(CURDATE(), INTERVAL 3 MONTH)\n",
      "    AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "    AND employment_statuses.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "    AND employment_statuses.location_id IN ('[LOCATION_IDS]')\n",
      "  GROUP BY employees.name, organizations.name\n",
      ")\n",
      "SELECT \n",
      "  eo.employee_name,\n",
      "  eo.department,\n",
      "  ROUND(eo.overtime_hours, 2) AS overtime_hours,\n",
      "  ROUND((eo.overtime_hours/do.total_dept_overtime)*100, 2) AS percentage_of_dept\n",
      "FROM employee_overtime eo\n",
      "JOIN dept_overtime do ON eo.department = do.department\n",
      "ORDER BY eo.department, eo.overtime_hours DESC\n",
      "LIMIT 10;\n",
      "\n",
      "Trying candidate 1\n",
      "✅ Candidate 1 executed successfully!\n",
      "Processing... question 137_1 Retry attempt: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:39:07,192 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 1):\n",
      "SELECT \n",
      "    job_levels.name AS job_level,\n",
      "    MIN(manager_reports.report_count) AS min_span,\n",
      "    MAX(manager_reports.report_count) AS max_span,\n",
      "    AVG(manager_reports.report_count) AS avg_span,\n",
      "    COUNT(DISTINCT employees.id) AS manager_count\n",
      "FROM (\n",
      "    SELECT manager_id, COUNT(*) AS report_count \n",
      "    FROM employees \n",
      "    WHERE manager_id IS NOT NULL \n",
      "    GROUP BY manager_id\n",
      ") AS manager_reports\n",
      "JOIN employees ON employees.id = manager_reports.manager_id\n",
      "JOIN employment_statuses ON employment_statuses.employee_id = employees.id\n",
      "JOIN job_levels ON job_levels.id = employment_statuses.job_level_id\n",
      "WHERE employment_statuses.location_id IN ('[LOCATION_IDS]')\n",
      "  AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "  AND employment_statuses.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "GROUP BY job_levels.name\n",
      "ORDER BY job_levels.name;\n",
      "\n",
      "Trying candidate 1\n",
      "✅ Candidate 1 executed successfully!\n",
      "137_2: ⚠️ Skipped due to column not found error.\n",
      "Processing... question 137_3 Retry attempt: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:39:48,401 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 1):\n",
      "WITH manager_spans AS (\n",
      "    SELECT \n",
      "        e.id AS manager_id,\n",
      "        e.name AS manager_name,\n",
      "        o.name AS department,\n",
      "        COUNT(reports.id) AS span_of_control\n",
      "    FROM employees e\n",
      "    JOIN employees reports ON reports.manager_id = e.id\n",
      "    JOIN employment_statuses es ON es.employee_id = e.id\n",
      "    JOIN organizations o ON o.id = es.organization_id\n",
      "    WHERE es.location_id IN ('[LOCATION_IDS]')\n",
      "      AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "      AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "    GROUP BY e.id, e.name, o.name\n",
      "),\n",
      "ranked_managers AS (\n",
      "    SELECT \n",
      "        manager_id,\n",
      "        manager_name,\n",
      "        department,\n",
      "        span_of_control,\n",
      "        RANK() OVER (PARTITION BY department ORDER BY span_of_control DESC) AS high_rank,\n",
      "        RANK() OVER (PARTITION BY department ORDER BY span_of_control ASC) AS low_rank\n",
      "    FROM manager_spans\n",
      ")\n",
      "SELECT \n",
      "    department,\n",
      "    MAX(CASE WHEN high_rank = 1 THEN manager_name END) AS highest_span_manager,\n",
      "    MAX(CASE WHEN high_rank = 1 THEN span_of_control END) AS highest_span,\n",
      "    MAX(CASE WHEN low_rank = 1 THEN manager_name END) AS lowest_span_manager,\n",
      "    MAX(CASE WHEN low_rank = 1 THEN span_of_control END) AS lowest_span\n",
      "FROM ranked_managers\n",
      "GROUP BY department\n",
      "ORDER BY department;\n",
      "\n",
      "Trying candidate 1\n",
      "✅ Candidate 1 executed successfully!\n",
      "Processing... question 138_1 Retry attempt: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:40:43,707 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 1):\n",
      "WITH promotion_history AS (\n",
      "  SELECT \n",
      "    esh.employee_id, \n",
      "    e.name AS employee_name, \n",
      "    jl.name AS job_level, \n",
      "    o.name AS department,\n",
      "    et.name AS employment_type,\n",
      "    esh.effective_date, \n",
      "    LAG(jl.name) OVER (PARTITION BY esh.employee_id ORDER BY esh.effective_date) AS previous_job_level\n",
      "  FROM \n",
      "    employment_status_histories esh \n",
      "    JOIN job_levels jl ON esh.job_level_id = jl.id \n",
      "    JOIN employees e ON esh.employee_id = e.id\n",
      "    JOIN organizations o ON esh.organization_id = o.id\n",
      "    JOIN employment_types et ON esh.employment_type_id = et.id\n",
      "    JOIN employment_statuses es ON esh.employee_id = es.employee_id\n",
      "  WHERE \n",
      "    es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "    AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "    AND es.location_id IN ('[LOCATION_IDS]')\n",
      ")\n",
      "SELECT \n",
      "  department,\n",
      "  employment_type,\n",
      "  COUNT(*) AS promotion_count\n",
      "FROM \n",
      "  promotion_history \n",
      "WHERE \n",
      "  job_level > previous_job_level\n",
      "GROUP BY \n",
      "  department, employment_type\n",
      "ORDER BY \n",
      "  promotion_count DESC;\n",
      "\n",
      "Trying candidate 1\n",
      "✅ Candidate 1 executed successfully!\n",
      "138_2: ⚠️ Skipped due to table not found error.\n",
      "Processing... question 138_3 Retry attempt: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:41:35,946 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 1):\n",
      "WITH promotion_events AS (\n",
      "  SELECT \n",
      "    esh.employee_id,\n",
      "    esh.effective_date,\n",
      "    jl.name AS job_level_name,\n",
      "    LAG(jl.name) OVER (PARTITION BY esh.employee_id ORDER BY esh.effective_date) AS prev_job_level,\n",
      "    LAG(esh.effective_date) OVER (PARTITION BY esh.employee_id ORDER BY esh.effective_date) AS prev_effective_date\n",
      "  FROM \n",
      "    employment_status_histories esh\n",
      "    JOIN job_levels jl ON esh.job_level_id = jl.id\n",
      "    JOIN employment_statuses es ON esh.employee_id = es.employee_id\n",
      "  WHERE \n",
      "    es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "),\n",
      "filtered_promotions AS (\n",
      "  SELECT \n",
      "    employee_id,\n",
      "    effective_date,\n",
      "    job_level_name,\n",
      "    DATEDIFF(effective_date, prev_effective_date) AS days_to_promotion\n",
      "  FROM \n",
      "    promotion_events\n",
      "  WHERE \n",
      "    job_level_name > prev_job_level\n",
      "    AND prev_job_level IS NOT NULL\n",
      ")\n",
      "SELECT \n",
      "  YEAR(effective_date) AS promotion_year,\n",
      "  AVG(days_to_promotion) AS avg_days_to_promotion,\n",
      "  COUNT(*) AS promotion_count\n",
      "FROM \n",
      "  filtered_promotions\n",
      "WHERE \n",
      "  YEAR(effective_date) BETWEEN YEAR(STR_TO_DATE('2020-01-01', '%Y-%m-%d')) AND YEAR(CURRENT_DATE)\n",
      "GROUP BY \n",
      "  promotion_year\n",
      "ORDER BY \n",
      "  promotion_year;\n",
      "\n",
      "Trying candidate 1\n",
      "✅ Candidate 1 executed successfully!\n",
      "139_1: ✅ Original query executed successfully!\n",
      "139_2: ✅ Original query executed successfully!\n",
      "139_3: ✅ Original query executed successfully!\n",
      "140_1: ✅ Original query executed successfully!\n",
      "140_2: ✅ Original query executed successfully!\n",
      "140_3: ✅ Original query executed successfully!\n",
      "141_1: ✅ Original query executed successfully!\n",
      "Processing... question 141_2 Retry attempt: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:42:32,851 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 1):\n",
      "WITH permanent_transitions AS (\n",
      "  SELECT \n",
      "    esh.employee_id,\n",
      "    esh.effective_date,\n",
      "    esh.location_id,\n",
      "    LAG(esh.employment_type_id) OVER (PARTITION BY esh.employee_id ORDER BY esh.effective_date) AS prev_employment_type_id,\n",
      "    LAG(esh.effective_date) OVER (PARTITION BY esh.employee_id ORDER BY esh.effective_date) AS prev_effective_date\n",
      "  FROM employment_status_histories esh\n",
      "  JOIN employment_types et ON esh.employment_type_id = et.id\n",
      "  WHERE et.name = 'Permanent'\n",
      "),\n",
      "contract_durations AS (\n",
      "  SELECT \n",
      "    pt.employee_id,\n",
      "    pt.location_id,\n",
      "    DATEDIFF(pt.effective_date, pt.prev_effective_date)/30 AS duration_months\n",
      "  FROM permanent_transitions pt\n",
      "  JOIN employees e ON pt.employee_id = e.id\n",
      "  JOIN employment_types et ON pt.prev_employment_type_id = et.id\n",
      "  WHERE e.active = TRUE\n",
      "    AND et.name != 'Permanent'\n",
      ")\n",
      "SELECT \n",
      "  l.name AS lokasi,\n",
      "  COUNT(*) AS jumlah_karyawan,\n",
      "  AVG(cd.duration_months) AS rata_rata_durasi_bulan,\n",
      "  MIN(cd.duration_months) AS durasi_terpendek_bulan,\n",
      "  MAX(cd.duration_months) AS durasi_terpanjang_bulan\n",
      "FROM contract_durations cd\n",
      "JOIN locations l ON cd.location_id = l.id\n",
      "WHERE l.id IN ('[LOCATION_IDS]')\n",
      "GROUP BY l.name\n",
      "ORDER BY rata_rata_durasi_bulan DESC;\n",
      "\n",
      "Trying candidate 1\n",
      "✅ Candidate 1 executed successfully!\n",
      "Processing... question 141_3 Retry attempt: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:43:32,955 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 1):\n",
      "WITH contract_changes AS (\n",
      "  SELECT \n",
      "    employee_id,\n",
      "    employment_type_id,\n",
      "    effective_date,\n",
      "    LAG(employment_type_id) OVER (PARTITION BY employee_id ORDER BY effective_date) AS prev_employment_type_id,\n",
      "    LAG(effective_date) OVER (PARTITION BY employee_id ORDER BY effective_date) AS prev_effective_date\n",
      "  FROM employment_status_histories\n",
      "  WHERE employment_type_id != LAG(employment_type_id) OVER (PARTITION BY employee_id ORDER BY effective_date)\n",
      "),\n",
      "attendance_stats AS (\n",
      "  SELECT \n",
      "    cc.employee_id,\n",
      "    COUNT(CASE WHEN adr.attendance_time_in IS NOT NULL THEN 1 END) AS present_days,\n",
      "    COUNT(adr.id) AS total_working_days\n",
      "  FROM contract_changes cc\n",
      "  JOIN attendance_detail_recapitulations adr ON cc.employee_id = adr.employee_id\n",
      "    AND adr.date BETWEEN DATE_SUB(cc.effective_date, INTERVAL 6 MONTH) AND cc.effective_date\n",
      "  GROUP BY cc.employee_id\n",
      ")\n",
      "SELECT \n",
      "  e.name AS employee_name,\n",
      "  et.name AS previous_contract_type,\n",
      "  ROUND((as1.present_days / as1.total_working_days) * 100, 2) AS attendance_percentage,\n",
      "  as1.present_days,\n",
      "  as1.total_working_days\n",
      "FROM contract_changes cc\n",
      "JOIN employees e ON cc.employee_id = e.id\n",
      "JOIN employment_types et ON cc.prev_employment_type_id = et.id\n",
      "JOIN attendance_stats as1 ON cc.employee_id = as1.employee_id\n",
      "WHERE e.active = TRUE\n",
      "ORDER BY attendance_percentage ASC\n",
      "LIMIT 20;\n",
      "\n",
      "Trying candidate 1\n",
      "❌ Candidate 1 failed with error: Error executing query: 4015 (HY000): Window function is allowed only in SELECT list and ORDER BY clause\n",
      "WITH contract_changes AS (\n",
      "  SELECT \n",
      "    employee_id,\n",
      "    employment_type_id,\n",
      "    effective_date,\n",
      "    LAG(employment_type_id) OVER (PARTITION BY employee_id ORDER BY effective_date) AS prev_employment_type_id\n",
      "  FROM employment_status_histories\n",
      "  WHERE employment_type_id != LAG(employment_type_id) OVER (PARTITION BY employee_id ORDER BY effective_date)\n",
      "),\n",
      "attendance_stats AS (\n",
      "  SELECT \n",
      "    cc.employee_id,\n",
      "    COUNT(CASE WHEN adr.attendance_time_in IS NOT NULL THEN 1 END) AS present_days,\n",
      "    COUNT(adr.id) AS total_working_days\n",
      "  FROM contract_changes cc\n",
      "  JOIN attendance_detail_recapitulations adr ON cc.employee_id = adr.employee_id\n",
      "    AND adr.date BETWEEN DATE_SUB(cc.effective_date, INTERVAL 6 MONTH) AND cc.effective_date\n",
      "  GROUP BY cc.employee_id\n",
      ")\n",
      "SELECT \n",
      "  e.name AS employee_name,\n",
      "  et.name AS previous_contract_type,\n",
      "  ROUND((as1.present_days / NULLIF(as1.total_working_days, 0)) * 100, 2) AS attendance_percentage,\n",
      "  as1.present_days,\n",
      "  as1.total_working_days\n",
      "FROM contract_changes cc\n",
      "JOIN employees e ON cc.employee_id = e.id\n",
      "JOIN employment_types et ON cc.prev_employment_type_id = et.id\n",
      "JOIN attendance_stats as1 ON cc.employee_id = as1.employee_id\n",
      "WHERE e.active = TRUE\n",
      "ORDER BY attendance_percentage ASC\n",
      "LIMIT 20;\n",
      "\n",
      "Trying candidate 2\n",
      "❌ Candidate 2 failed with error: Error executing query: 4015 (HY000): Window function is allowed only in SELECT list and ORDER BY clause\n",
      "WITH contract_changes AS (\n",
      "  SELECT \n",
      "    employee_id,\n",
      "    employment_type_id,\n",
      "    effective_date,\n",
      "    LAG(employment_type_id) OVER (PARTITION BY employee_id ORDER BY effective_date) AS prev_employment_type_id\n",
      "  FROM employment_status_histories\n",
      "  WHERE employment_type_id != LAG(employment_type_id) OVER (PARTITION BY employee_id ORDER BY effective_date)\n",
      "),\n",
      "attendance_stats AS (\n",
      "  SELECT \n",
      "    cc.employee_id,\n",
      "    SUM(CASE WHEN adr.attendance_time_in IS NOT NULL THEN 1 ELSE 0 END) AS present_days,\n",
      "    COUNT(adr.id) AS total_working_days\n",
      "  FROM contract_changes cc\n",
      "  JOIN attendance_detail_recapitulations adr ON cc.employee_id = adr.employee_id\n",
      "    AND adr.date BETWEEN DATE_SUB(cc.effective_date, INTERVAL 6 MONTH) AND cc.effective_date\n",
      "  GROUP BY cc.employee_id\n",
      ")\n",
      "SELECT \n",
      "  e.name AS employee_name,\n",
      "  et.name AS previous_contract_type,\n",
      "  CASE \n",
      "    WHEN as1.total_working_days = 0 THEN 0 \n",
      "    ELSE ROUND((as1.present_days / as1.total_working_days) * 100, 2) \n",
      "  END AS attendance_percentage,\n",
      "  as1.present_days,\n",
      "  as1.total_working_days\n",
      "FROM contract_changes cc\n",
      "JOIN employees e ON cc.employee_id = e.id\n",
      "JOIN employment_types et ON cc.prev_employment_type_id = et.id\n",
      "JOIN attendance_stats as1 ON cc.employee_id = as1.employee_id\n",
      "WHERE e.active = TRUE\n",
      "ORDER BY attendance_percentage ASC\n",
      "LIMIT 20;\n",
      "\n",
      "Trying candidate 3\n",
      "❌ Candidate 3 failed with error: Error executing query: 4015 (HY000): Window function is allowed only in SELECT list and ORDER BY clause\n",
      "No working candidates found. Retrying... (1/3)\n",
      "Processing... question 141_3 Retry attempt: 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:44:28,246 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 2):\n",
      "WITH contract_changes AS (\n",
      "  SELECT \n",
      "    esh1.employee_id,\n",
      "    esh1.employment_type_id,\n",
      "    esh1.effective_date,\n",
      "    esh2.employment_type_id AS prev_employment_type_id\n",
      "  FROM employment_status_histories esh1\n",
      "  JOIN employment_status_histories esh2 ON esh1.employee_id = esh2.employee_id\n",
      "    AND esh2.effective_date = (\n",
      "      SELECT MAX(effective_date)\n",
      "      FROM employment_status_histories\n",
      "      WHERE employee_id = esh1.employee_id\n",
      "        AND effective_date < esh1.effective_date\n",
      "    )\n",
      "  WHERE esh1.employment_type_id != esh2.employment_type_id\n",
      "),\n",
      "attendance_stats AS (\n",
      "  SELECT \n",
      "    cc.employee_id,\n",
      "    SUM(CASE WHEN adr.attendance_time_in IS NOT NULL THEN 1 ELSE 0 END) AS present_days,\n",
      "    COUNT(adr.id) AS total_working_days\n",
      "  FROM contract_changes cc\n",
      "  JOIN attendance_detail_recapitulations adr ON cc.employee_id = adr.employee_id\n",
      "    AND adr.date BETWEEN DATE_SUB(cc.effective_date, INTERVAL 6 MONTH) AND cc.effective_date\n",
      "  GROUP BY cc.employee_id\n",
      ")\n",
      "SELECT \n",
      "  e.name AS employee_name,\n",
      "  et.name AS previous_contract_type,\n",
      "  CASE \n",
      "    WHEN as1.total_working_days = 0 THEN 0 \n",
      "    ELSE ROUND((as1.present_days / as1.total_working_days) * 100, 2) \n",
      "  END AS attendance_percentage,\n",
      "  as1.present_days,\n",
      "  as1.total_working_days\n",
      "FROM contract_changes cc\n",
      "JOIN employees e ON cc.employee_id = e.id\n",
      "JOIN employment_types et ON cc.prev_employment_type_id = et.id\n",
      "JOIN attendance_stats as1 ON cc.employee_id = as1.employee_id\n",
      "JOIN employment_statuses es ON e.id = es.employee_id\n",
      "WHERE e.active = TRUE\n",
      "  AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "  AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "  AND es.location_id IN ('[LOCATION_IDS]')\n",
      "ORDER BY attendance_percentage ASC\n",
      "LIMIT 20;\n",
      "\n",
      "Trying candidate 1\n",
      "✅ Candidate 1 executed successfully!\n",
      "142_1: ⚠️ Skipped due to column not found error.\n",
      "142_2: ✅ Original query executed successfully!\n",
      "142_3: ⚠️ Skipped due to column not found error.\n",
      "143_1: ✅ Original query executed successfully!\n",
      "Processing... question 143_2 Retry attempt: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:45:41,546 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 1):\n",
      "WITH RECURSIVE hierarchy_depth AS (\n",
      "  SELECT \n",
      "    e.id,\n",
      "    e.manager_id,\n",
      "    o.name AS department,\n",
      "    YEAR(esh.effective_date) AS year,\n",
      "    1 AS depth\n",
      "  FROM employees e\n",
      "  JOIN employment_status_histories esh ON e.id = esh.employee_id\n",
      "  JOIN organizations o ON esh.organization_id = o.id\n",
      "  WHERE e.manager_id IS NULL\n",
      "    AND esh.effective_date >= DATE_SUB(STR_TO_DATE('11 April 2025', '%d %M %Y'), INTERVAL 3 YEAR)\n",
      "    AND esh.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "    AND esh.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "    AND esh.location_id IN ('[LOCATION_IDS]')\n",
      "  UNION ALL\n",
      "  SELECT \n",
      "    e.id,\n",
      "    e.manager_id,\n",
      "    hd.department,\n",
      "    hd.year,\n",
      "    hd.depth + 1\n",
      "  FROM employees e\n",
      "  JOIN hierarchy_depth hd ON e.manager_id = hd.id\n",
      "  JOIN employment_status_histories esh ON e.id = esh.employee_id\n",
      "  WHERE esh.effective_date >= DATE_SUB(STR_TO_DATE('11 April 2025', '%d %M %Y'), INTERVAL 3 YEAR)\n",
      "    AND esh.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "    AND esh.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "    AND esh.location_id IN ('[LOCATION_IDS]')\n",
      ")\n",
      "SELECT \n",
      "  department,\n",
      "  year,\n",
      "  MAX(depth) AS max_hierarchy_depth,\n",
      "  AVG(depth) AS avg_hierarchy_depth\n",
      "FROM hierarchy_depth\n",
      "GROUP BY department, year\n",
      "ORDER BY department, year;\n",
      "\n",
      "Trying candidate 1\n",
      "✅ Candidate 1 executed successfully!\n",
      "143_3: ✅ Original query executed successfully!\n",
      "144_1: ✅ Original query executed successfully!\n",
      "144_2: ✅ Original query executed successfully!\n",
      "144_3: ✅ Original query executed successfully!\n",
      "145_1: ⚠️ Skipped due to column not found error.\n",
      "145_2: ✅ Original query executed successfully!\n",
      "145_3: ✅ Original query executed successfully!\n",
      "146_1: ✅ Original query executed successfully!\n",
      "146_2: ✅ Original query executed successfully!\n",
      "146_3: ⚠️ Skipped due to column not found error.\n",
      "147_1: ✅ Original query executed successfully!\n",
      "147_2: ✅ Original query executed successfully!\n",
      "147_3: ✅ Original query executed successfully!\n",
      "148_1: ✅ Original query executed successfully!\n",
      "148_2: ✅ Original query executed successfully!\n",
      "148_3: ⚠️ Skipped due to column not found error.\n",
      "149_1: ⚠️ Skipped due to column not found error.\n",
      "149_2: ✅ Original query executed successfully!\n",
      "149_3: ✅ Original query executed successfully!\n",
      "150_1: ✅ Original query executed successfully!\n",
      "150_2: ✅ Original query executed successfully!\n",
      "150_3: ✅ Original query executed successfully!\n",
      "151_1: ✅ Original query executed successfully!\n",
      "151_2: ✅ Original query executed successfully!\n",
      "151_3: ✅ Original query executed successfully!\n",
      "152_1: ✅ Original query executed successfully!\n",
      "152_2: ⚠️ Skipped due to table not found error.\n",
      "152_3: ✅ Original query executed successfully!\n",
      "153_1: ⚠️ Skipped due to column not found error.\n",
      "153_2: ✅ Original query executed successfully!\n",
      "153_3: ✅ Original query executed successfully!\n",
      "154_1: ✅ Original query executed successfully!\n",
      "154_2: ✅ Original query executed successfully!\n",
      "154_3: ✅ Original query executed successfully!\n",
      "155_1: ⚠️ Skipped due to column not found error.\n",
      "155_2: ✅ Original query executed successfully!\n",
      "155_3: ✅ Original query executed successfully!\n",
      "156_1: ⚠️ Skipped due to column not found error.\n",
      "156_2: ✅ Original query executed successfully!\n",
      "Processing... question 156_3 Retry attempt: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:46:53,717 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 1):\n",
      "WITH employee_attendance AS (\n",
      "    SELECT \n",
      "        e.id AS employee_id,\n",
      "        FLOOR(DATEDIFF(CURDATE(), ed.date_of_birth)/365) AS age,\n",
      "        o.name AS department,\n",
      "        COUNT(CASE WHEN ast.attendance_type IN ('ABSENT', 'LEAVE') THEN 1 END) AS absent_days,\n",
      "        COUNT(*) AS total_days\n",
      "    FROM employees e\n",
      "    JOIN employee_details ed ON e.id = ed.employee_id\n",
      "    JOIN employment_statuses es ON e.id = es.employee_id\n",
      "    JOIN organizations o ON es.organization_id = o.id\n",
      "    JOIN attendances a ON e.id = a.employee_id\n",
      "    JOIN attendance_statuses ast ON a.attendance_status_in_id = ast.id\n",
      "    WHERE es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "      AND es.location_id IN ('[LOCATION_IDS]')\n",
      "      AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "      AND a.date BETWEEN STR_TO_DATE('2023-01-01', '%Y-%m-%d') AND CURDATE()\n",
      "    GROUP BY e.id, ed.date_of_birth, o.name\n",
      ")\n",
      "SELECT \n",
      "    department,\n",
      "    age,\n",
      "    AVG(absent_days*100.0/total_days) AS avg_absence_percentage,\n",
      "    COUNT(*) AS employee_count\n",
      "FROM employee_attendance\n",
      "GROUP BY department, age\n",
      "ORDER BY department, age;\n",
      "\n",
      "Trying candidate 1\n",
      "✅ Candidate 1 executed successfully!\n",
      "157_1: ✅ Original query executed successfully!\n",
      "157_2: ✅ Original query executed successfully!\n",
      "157_3: ⚠️ Skipped due to column not found error.\n",
      "158_1: ⚠️ Skipped due to column not found error.\n",
      "158_2: ⚠️ Skipped due to column not found error.\n",
      "158_3: ⚠️ Skipped due to column not found error.\n",
      "159_1: ✅ Original query executed successfully!\n",
      "159_2: ✅ Original query executed successfully!\n",
      "159_3: ✅ Original query executed successfully!\n",
      "160_1: ✅ Original query executed successfully!\n",
      "160_2: ✅ Original query executed successfully!\n",
      "160_3: ✅ Original query executed successfully!\n",
      "161_1: ✅ Original query executed successfully!\n",
      "161_2: ⚠️ Skipped due to column not found error.\n",
      "161_3: ⚠️ Skipped due to column not found error.\n",
      "162_1: ✅ Original query executed successfully!\n",
      "162_2: ✅ Original query executed successfully!\n",
      "162_3: ✅ Original query executed successfully!\n",
      "163_1: ⚠️ Skipped due to column not found error.\n",
      "163_2: ⚠️ Skipped due to column not found error.\n",
      "163_3: ⚠️ Skipped due to column not found error.\n",
      "164_1: ✅ Original query executed successfully!\n",
      "Processing... question 164_2 Retry attempt: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:47:46,165 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 1):\n",
      "WITH overtime_stats AS (\n",
      "    SELECT \n",
      "        jl.name AS job_level,\n",
      "        COUNT(DISTINCT e.id) AS employee_count,\n",
      "        AVG(adr.paid_overtime/3600000) AS avg_overtime,\n",
      "        MAX(adr.paid_overtime/3600000) AS max_overtime,\n",
      "        MIN(adr.paid_overtime/3600000) AS min_overtime\n",
      "    FROM attendance_detail_recapitulations adr\n",
      "    JOIN employees e ON adr.employee_id = e.id\n",
      "    JOIN employment_statuses es ON e.id = es.employee_id\n",
      "    JOIN job_levels jl ON es.job_level_id = jl.id\n",
      "    WHERE adr.date BETWEEN STR_TO_DATE('2023-10-01', '%Y-%m-%d') AND STR_TO_DATE('2023-10-31', '%Y-%m-%d')\n",
      "        AND adr.paid_overtime > 0\n",
      "        AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND es.location_id IN ('[LOCATION_IDS]')\n",
      "    GROUP BY jl.name\n",
      ")\n",
      "SELECT * FROM overtime_stats\n",
      "ORDER BY avg_overtime DESC;\n",
      "\n",
      "Trying candidate 1\n",
      "✅ Candidate 1 executed successfully!\n",
      "164_3: ✅ Original query executed successfully!\n",
      "165_1: ✅ Original query executed successfully!\n",
      "165_2: ✅ Original query executed successfully!\n",
      "165_3: ✅ Original query executed successfully!\n",
      "166_1: ⚠️ Skipped due to column not found error.\n",
      "166_2: ✅ Original query executed successfully!\n",
      "166_3: ⚠️ Skipped due to column not found error.\n",
      "167_1: ⚠️ Skipped due to column not found error.\n",
      "167_2: ⚠️ Skipped due to column not found error.\n",
      "167_3: ⚠️ Skipped due to column not found error.\n",
      "168_1: ✅ Original query executed successfully!\n",
      "168_2: ⚠️ Skipped due to column not found error.\n",
      "168_3: ⚠️ Skipped due to column not found error.\n",
      "Processing... question 169_1 Retry attempt: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:48:33,092 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 1):\n",
      "WITH promotion_data AS (\n",
      "  SELECT \n",
      "    esh1.employee_id,\n",
      "    o.name AS department,\n",
      "    jl1.name AS previous_level,\n",
      "    DATEDIFF(MIN(esh2.effective_date), esh1.effective_date) AS days_in_position\n",
      "  FROM employment_status_histories esh1\n",
      "  JOIN employment_status_histories esh2 ON \n",
      "    esh1.employee_id = esh2.employee_id AND \n",
      "    esh2.effective_date > esh1.effective_date\n",
      "  JOIN job_levels jl1 ON esh1.job_level_id = jl1.id\n",
      "  JOIN job_levels jl2 ON esh2.job_level_id = jl2.id\n",
      "  JOIN employees e ON esh1.employee_id = e.id\n",
      "  JOIN organizations o ON esh1.organization_id = o.id\n",
      "  JOIN employment_statuses es ON esh1.employee_id = es.employee_id\n",
      "  WHERE jl2.id > jl1.id \n",
      "    AND e.active = TRUE\n",
      "    AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "    AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "    AND es.location_id IN ('[LOCATION_IDS]')\n",
      "  GROUP BY esh1.employee_id, esh1.effective_date, o.name, jl1.name\n",
      ")\n",
      "SELECT \n",
      "  department,\n",
      "  previous_level,\n",
      "  COUNT(*) AS jumlah_promosi,\n",
      "  MIN(days_in_position) AS hari_minimal,\n",
      "  MAX(days_in_position) AS hari_maksimal,\n",
      "  AVG(days_in_position) AS hari_rerata\n",
      "FROM promotion_data\n",
      "GROUP BY department, previous_level\n",
      "ORDER BY department, previous_level;\n",
      "\n",
      "Trying candidate 1\n",
      "✅ Candidate 1 executed successfully!\n",
      "169_2: ⚠️ Skipped due to column not found error.\n",
      "169_3: ✅ Original query executed successfully!\n",
      "170_1: ✅ Original query executed successfully!\n",
      "170_2: ⚠️ Skipped due to column not found error.\n",
      "170_3: ✅ Original query executed successfully!\n",
      "Processing... question 171_1 Retry attempt: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:49:36,808 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 1):\n",
      "WITH manager_reports AS (\n",
      "  SELECT \n",
      "    e.manager_id,\n",
      "    es.job_level_id,\n",
      "    COUNT(*) AS report_count\n",
      "  FROM employees e\n",
      "  JOIN employment_statuses es ON e.manager_id = es.employee_id\n",
      "  WHERE e.manager_id IS NOT NULL \n",
      "    AND e.active = TRUE\n",
      "    AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "    AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "    AND es.location_id IN ('[LOCATION_IDS]')\n",
      "  GROUP BY e.manager_id, es.job_level_id\n",
      ")\n",
      "SELECT \n",
      "  jl.name AS level_jabatan,\n",
      "  MIN(mr.report_count) AS jumlah_bawahan_minimum,\n",
      "  MAX(mr.report_count) AS jumlah_bawahan_maksimum,\n",
      "  AVG(mr.report_count) AS rata_rata_bawahan\n",
      "FROM manager_reports mr\n",
      "JOIN job_levels jl ON mr.job_level_id = jl.id\n",
      "GROUP BY jl.name\n",
      "ORDER BY jl.name;\n",
      "\n",
      "Trying candidate 1\n",
      "✅ Candidate 1 executed successfully!\n",
      "171_2: ⚠️ Skipped due to column not found error.\n",
      "171_3: ⚠️ Skipped due to column not found error.\n",
      "172_1: ✅ Original query executed successfully!\n",
      "Processing... question 172_2 Retry attempt: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:50:23,889 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 1):\n",
      "WITH company_avg AS (\n",
      "    SELECT AVG(paid_overtime)/3600000 AS avg_hours\n",
      "    FROM attendance_detail_recapitulations\n",
      "    WHERE date BETWEEN DATE_SUB(STR_TO_DATE('2023-01-01', '%Y-%m-%d'), INTERVAL 3 MONTH) AND STR_TO_DATE('2023-01-01', '%Y-%m-%d')\n",
      "),\n",
      "employee_overtime AS (\n",
      "    SELECT \n",
      "        adr.employee_id,\n",
      "        SUM(adr.paid_overtime)/3600000 AS total_hours,\n",
      "        jl.name AS job_level,\n",
      "        o.name AS department\n",
      "    FROM \n",
      "        attendance_detail_recapitulations adr\n",
      "    JOIN \n",
      "        employment_statuses es ON adr.employee_id = es.employee_id\n",
      "    JOIN \n",
      "        job_levels jl ON es.job_level_id = jl.id\n",
      "    JOIN \n",
      "        organizations o ON es.organization_id = o.id\n",
      "    WHERE \n",
      "        adr.date BETWEEN DATE_SUB(STR_TO_DATE('2023-01-01', '%Y-%m-%d'), INTERVAL 3 MONTH) AND STR_TO_DATE('2023-01-01', '%Y-%m-%d')\n",
      "        AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND es.location_id IN ('[LOCATION_IDS]')\n",
      "    GROUP BY \n",
      "        adr.employee_id, jl.name, o.name\n",
      ")\n",
      "SELECT \n",
      "    job_level,\n",
      "    department,\n",
      "    COUNT(*) AS total_employees,\n",
      "    SUM(CASE WHEN total_hours > (SELECT avg_hours FROM company_avg) THEN 1 ELSE 0 END) AS above_avg_employees,\n",
      "    ROUND(SUM(CASE WHEN total_hours > (SELECT avg_hours FROM company_avg) THEN 1 ELSE 0 END) * 100.0 / COUNT(*), 2) AS percentage_above_avg\n",
      "FROM \n",
      "    employee_overtime\n",
      "GROUP BY \n",
      "    job_level, department\n",
      "ORDER BY \n",
      "    percentage_above_avg DESC;\n",
      "\n",
      "Trying candidate 1\n",
      "❌ Candidate 1 failed with error: Error executing query: 1111 (HY000): Invalid use of group function\n",
      "WITH company_avg AS (\n",
      "    SELECT SUM(paid_overtime)/3600000/COUNT(DISTINCT employee_id) AS avg_hours\n",
      "    FROM attendance_detail_recapitulations\n",
      "    WHERE date BETWEEN DATE_SUB(STR_TO_DATE('2023-01-01', '%Y-%m-%d'), INTERVAL 3 MONTH) AND STR_TO_DATE('2023-01-01', '%Y-%m-%d')\n",
      "),\n",
      "employee_overtime AS (\n",
      "    SELECT \n",
      "        adr.employee_id,\n",
      "        SUM(adr.paid_overtime)/3600000 AS total_hours,\n",
      "        jl.name AS job_level,\n",
      "        o.name AS department\n",
      "    FROM \n",
      "        attendance_detail_recapitulations adr\n",
      "    JOIN \n",
      "        employment_statuses es ON adr.employee_id = es.employee_id\n",
      "    JOIN \n",
      "        job_levels jl ON es.job_level_id = jl.id\n",
      "    JOIN \n",
      "        organizations o ON es.organization_id = o.id\n",
      "    WHERE \n",
      "        adr.date BETWEEN DATE_SUB(STR_TO_DATE('2023-01-01', '%Y-%m-%d'), INTERVAL 3 MONTH) AND STR_TO_DATE('2023-01-01', '%Y-%m-%d')\n",
      "        AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND es.location_id IN ('[LOCATION_IDS]')\n",
      "    GROUP BY \n",
      "        adr.employee_id, jl.name, o.name\n",
      ")\n",
      "SELECT \n",
      "    job_level,\n",
      "    department,\n",
      "    COUNT(*) AS total_employees,\n",
      "    SUM(CASE WHEN total_hours > (SELECT avg_hours FROM company_avg) THEN 1 ELSE 0 END) AS above_avg_employees,\n",
      "    ROUND(SUM(CASE WHEN total_hours > (SELECT avg_hours FROM company_avg) THEN 1 ELSE 0 END) * 100.0 / NULLIF(COUNT(*), 0), 2) AS percentage_above_avg\n",
      "FROM \n",
      "    employee_overtime\n",
      "GROUP BY \n",
      "    job_level, department\n",
      "ORDER BY \n",
      "    percentage_above_avg DESC;\n",
      "\n",
      "Trying candidate 2\n",
      "❌ Candidate 2 failed with error: Error executing query: 1111 (HY000): Invalid use of group function\n",
      "WITH company_avg AS (\n",
      "    SELECT SUM(paid_overtime)/3600000/COUNT(DISTINCT employee_id) AS avg_hours\n",
      "    FROM attendance_detail_recapitulations\n",
      "    WHERE date BETWEEN DATE_SUB(STR_TO_DATE('2023-01-01', '%Y-%m-%d'), INTERVAL 3 MONTH) AND STR_TO_DATE('2023-01-01', '%Y-%m-%d')\n",
      "),\n",
      "employee_overtime AS (\n",
      "    SELECT \n",
      "        adr.employee_id,\n",
      "        SUM(adr.paid_overtime)/3600000 AS total_hours,\n",
      "        jl.name AS job_level,\n",
      "        o.name AS department\n",
      "    FROM \n",
      "        attendance_detail_recapitulations adr\n",
      "    JOIN \n",
      "        employment_statuses es ON adr.employee_id = es.employee_id\n",
      "    JOIN \n",
      "        job_levels jl ON es.job_level_id = jl.id\n",
      "    JOIN \n",
      "        organizations o ON es.organization_id = o.id\n",
      "    WHERE \n",
      "        adr.date BETWEEN DATE_SUB(STR_TO_DATE('2023-01-01', '%Y-%m-%d'), INTERVAL 3 MONTH) AND STR_TO_DATE('2023-01-01', '%Y-%m-%d')\n",
      "        AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND es.location_id IN ('[LOCATION_IDS]')\n",
      "    GROUP BY \n",
      "        adr.employee_id, jl.name, o.name\n",
      ")\n",
      "SELECT \n",
      "    job_level,\n",
      "    department,\n",
      "    COUNT(*) AS total_employees,\n",
      "    COUNT(CASE WHEN total_hours > (SELECT avg_hours FROM company_avg) THEN 1 ELSE NULL END) AS above_avg_employees,\n",
      "    ROUND(COUNT(CASE WHEN total_hours > (SELECT avg_hours FROM company_avg) THEN 1 ELSE NULL END) * 100.0 / NULLIF(COUNT(*), 0), 2) AS percentage_above_avg\n",
      "FROM \n",
      "    employee_overtime\n",
      "GROUP BY \n",
      "    job_level, department\n",
      "ORDER BY \n",
      "    percentage_above_avg DESC;\n",
      "\n",
      "Trying candidate 3\n",
      "❌ Candidate 3 failed with error: Error executing query: 1111 (HY000): Invalid use of group function\n",
      "No working candidates found. Retrying... (1/3)\n",
      "Processing... question 172_2 Retry attempt: 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:51:34,829 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 2):\n",
      "WITH company_avg AS (\n",
      "    SELECT AVG(paid_overtime_hours) AS avg_hours\n",
      "    FROM (\n",
      "        SELECT \n",
      "            employee_id, \n",
      "            SUM(paid_overtime)/3600000 AS paid_overtime_hours\n",
      "        FROM \n",
      "            attendance_detail_recapitulations\n",
      "        WHERE \n",
      "            date BETWEEN DATE_SUB(STR_TO_DATE('2023-01-01', '%Y-%m-%d'), INTERVAL 3 MONTH) AND STR_TO_DATE('2023-01-01', '%Y-%m-%d')\n",
      "        GROUP BY \n",
      "            employee_id\n",
      "    ) AS employee_hours\n",
      "),\n",
      "employee_overtime AS (\n",
      "    SELECT \n",
      "        adr.employee_id,\n",
      "        SUM(adr.paid_overtime)/3600000 AS total_hours,\n",
      "        jl.name AS job_level,\n",
      "        o.name AS department\n",
      "    FROM \n",
      "        attendance_detail_recapitulations adr\n",
      "    JOIN \n",
      "        employment_statuses es ON adr.employee_id = es.employee_id\n",
      "    JOIN \n",
      "        job_levels jl ON es.job_level_id = jl.id\n",
      "    JOIN \n",
      "        organizations o ON es.organization_id = o.id\n",
      "    WHERE \n",
      "        adr.date BETWEEN DATE_SUB(STR_TO_DATE('2023-01-01', '%Y-%m-%d'), INTERVAL 3 MONTH) AND STR_TO_DATE('2023-01-01', '%Y-%m-%d')\n",
      "        AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND es.location_id IN ('[LOCATION_IDS]')\n",
      "    GROUP BY \n",
      "        adr.employee_id, jl.name, o.name\n",
      ")\n",
      "SELECT \n",
      "    job_level,\n",
      "    department,\n",
      "    COUNT(*) AS total_employees,\n",
      "    COUNT(CASE WHEN total_hours > (SELECT avg_hours FROM company_avg) THEN 1 ELSE NULL END) AS above_avg_employees,\n",
      "    ROUND(COUNT(CASE WHEN total_hours > (SELECT avg_hours FROM company_avg) THEN 1 ELSE NULL END) * 100.0 / NULLIF(COUNT(*), 0), 2) AS percentage_above_avg\n",
      "FROM \n",
      "    employee_overtime\n",
      "GROUP BY \n",
      "    job_level, department\n",
      "ORDER BY \n",
      "    percentage_above_avg DESC;\n",
      "\n",
      "Trying candidate 1\n",
      "❌ Candidate 1 failed with error: Error executing query: 1111 (HY000): Invalid use of group function\n",
      "WITH company_avg AS (\n",
      "    SELECT SUM(paid_overtime)/3600000/COUNT(DISTINCT employee_id) AS avg_hours\n",
      "    FROM attendance_detail_recapitulations\n",
      "    WHERE date BETWEEN DATE_SUB(STR_TO_DATE('2023-01-01', '%Y-%m-%d'), INTERVAL 3 MONTH) AND STR_TO_DATE('2023-01-01', '%Y-%m-%d')\n",
      "),\n",
      "employee_overtime AS (\n",
      "    SELECT \n",
      "        adr.employee_id,\n",
      "        SUM(adr.paid_overtime)/3600000 AS total_hours,\n",
      "        jl.name AS job_level,\n",
      "        o.name AS department\n",
      "    FROM \n",
      "        attendance_detail_recapitulations adr\n",
      "    JOIN \n",
      "        employment_statuses es ON adr.employee_id = es.employee_id\n",
      "    JOIN \n",
      "        job_levels jl ON es.job_level_id = jl.id\n",
      "    JOIN \n",
      "        organizations o ON es.organization_id = o.id\n",
      "    WHERE \n",
      "        adr.date BETWEEN DATE_SUB(STR_TO_DATE('2023-01-01', '%Y-%m-%d'), INTERVAL 3 MONTH) AND STR_TO_DATE('2023-01-01', '%Y-%m-%d')\n",
      "        AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND es.location_id IN ('[LOCATION_IDS]')\n",
      "    GROUP BY \n",
      "        adr.employee_id, jl.name, o.name\n",
      ")\n",
      "SELECT \n",
      "    job_level,\n",
      "    department,\n",
      "    COUNT(*) AS total_employees,\n",
      "    SUM(CASE WHEN total_hours > (SELECT avg_hours FROM company_avg) THEN 1 ELSE 0 END) AS above_avg_employees,\n",
      "    ROUND(SUM(CASE WHEN total_hours > (SELECT avg_hours FROM company_avg) THEN 1 ELSE 0 END) * 100.0 / NULLIF(COUNT(*), 0), 2) AS percentage_above_avg\n",
      "FROM \n",
      "    employee_overtime\n",
      "GROUP BY \n",
      "    job_level, department\n",
      "ORDER BY \n",
      "    percentage_above_avg DESC;\n",
      "\n",
      "Trying candidate 2\n",
      "❌ Candidate 2 failed with error: Error executing query: 1111 (HY000): Invalid use of group function\n",
      "WITH employee_hours AS (\n",
      "    SELECT \n",
      "        employee_id,\n",
      "        SUM(paid_overtime)/3600000 AS paid_overtime_hours\n",
      "    FROM \n",
      "        attendance_detail_recapitulations\n",
      "    WHERE \n",
      "        date BETWEEN DATE_SUB(STR_TO_DATE('2023-01-01', '%Y-%m-%d'), INTERVAL 3 MONTH) AND STR_TO_DATE('2023-01-01', '%Y-%m-%d')\n",
      "    GROUP BY \n",
      "        employee_id\n",
      "),\n",
      "company_avg AS (\n",
      "    SELECT AVG(paid_overtime_hours) AS avg_hours\n",
      "    FROM employee_hours\n",
      "),\n",
      "employee_overtime AS (\n",
      "    SELECT \n",
      "        eh.employee_id,\n",
      "        eh.paid_overtime_hours AS total_hours,\n",
      "        jl.name AS job_level,\n",
      "        o.name AS department\n",
      "    FROM \n",
      "        employee_hours eh\n",
      "    JOIN \n",
      "        employment_statuses es ON eh.employee_id = es.employee_id\n",
      "    JOIN \n",
      "        job_levels jl ON es.job_level_id = jl.id\n",
      "    JOIN \n",
      "        organizations o ON es.organization_id = o.id\n",
      "    WHERE \n",
      "        es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND es.location_id IN ('[LOCATION_IDS]')\n",
      ")\n",
      "SELECT \n",
      "    job_level,\n",
      "    department,\n",
      "    COUNT(*) AS total_employees,\n",
      "    COUNT(CASE WHEN total_hours > (SELECT avg_hours FROM company_avg) THEN 1 ELSE NULL END) AS above_avg_employees,\n",
      "    ROUND(COUNT(CASE WHEN total_hours > (SELECT avg_hours FROM company_avg) THEN 1 ELSE NULL END) * 100.0 / NULLIF(COUNT(*), 0), 2) AS percentage_above_avg\n",
      "FROM \n",
      "    employee_overtime\n",
      "GROUP BY \n",
      "    job_level, department\n",
      "ORDER BY \n",
      "    percentage_above_avg DESC;\n",
      "\n",
      "Trying candidate 3\n",
      "❌ Candidate 3 failed with error: Error executing query: 1111 (HY000): Invalid use of group function\n",
      "No working candidates found. Retrying... (2/3)\n",
      "Processing... question 172_2 Retry attempt: 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 10:52:49,649 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 3):\n",
      "WITH employee_hours AS (\n",
      "    SELECT \n",
      "        employee_id,\n",
      "        SUM(paid_overtime)/3600000 AS paid_overtime_hours\n",
      "    FROM \n",
      "        attendance_detail_recapitulations\n",
      "    WHERE \n",
      "        date BETWEEN DATE_SUB(STR_TO_DATE('2023-01-01', '%Y-%m-%d'), INTERVAL 3 MONTH) AND STR_TO_DATE('2023-01-01', '%Y-%m-%d')\n",
      "    GROUP BY \n",
      "        employee_id\n",
      "),\n",
      "company_avg AS (\n",
      "    SELECT AVG(paid_overtime_hours) AS avg_hours\n",
      "    FROM employee_hours\n",
      "),\n",
      "employee_overtime AS (\n",
      "    SELECT \n",
      "        eh.employee_id,\n",
      "        eh.paid_overtime_hours,\n",
      "        jl.name AS job_level,\n",
      "        o.name AS department,\n",
      "        (SELECT avg_hours FROM company_avg) AS company_avg_hours\n",
      "    FROM \n",
      "        employee_hours eh\n",
      "    JOIN \n",
      "        employment_statuses es ON eh.employee_id = es.employee_id\n",
      "    JOIN \n",
      "        job_levels jl ON es.job_level_id = jl.id\n",
      "    JOIN \n",
      "        organizations o ON es.organization_id = o.id\n",
      "    WHERE \n",
      "        es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND es.location_id IN ('[LOCATION_IDS]')\n",
      ")\n",
      "SELECT \n",
      "    job_level,\n",
      "    department,\n",
      "    COUNT(*) AS total_employees,\n",
      "    COUNT(CASE WHEN paid_overtime_hours > company_avg_hours THEN 1 ELSE NULL END) AS above_avg_employees,\n",
      "    ROUND(COUNT(CASE WHEN paid_overtime_hours > company_avg_hours THEN 1 ELSE NULL END) * 100.0 / NULLIF(COUNT(*), 0), 2) AS percentage_above_avg\n",
      "FROM \n",
      "    employee_overtime\n",
      "GROUP BY \n",
      "    job_level, department\n",
      "ORDER BY \n",
      "    percentage_above_avg DESC;\n",
      "\n",
      "Trying candidate 1\n",
      "✅ Candidate 1 executed successfully!\n",
      "Processing... question 172_3 Retry attempt: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 11:01:35,031 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 1):\n",
      "WITH overtime_data AS (\n",
      "    SELECT \n",
      "        adr.employee_id,\n",
      "        es.organization_id,\n",
      "        o.name AS department,\n",
      "        SUM(adr.paid_overtime)/3600000 AS total_overtime_hours\n",
      "    FROM \n",
      "        attendance_detail_recapitulations adr\n",
      "    JOIN \n",
      "        employment_statuses es ON adr.employee_id = es.employee_id\n",
      "    JOIN \n",
      "        organizations o ON es.organization_id = o.id\n",
      "    WHERE \n",
      "        adr.date BETWEEN DATE_SUB(STR_TO_DATE('2023-01-01', '%Y-%m-%d'), INTERVAL 3 MONTH) AND STR_TO_DATE('2023-01-01', '%Y-%m-%d')\n",
      "        AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND es.location_id IN ('[LOCATION_IDS]')\n",
      "    GROUP BY \n",
      "        adr.employee_id, es.organization_id, o.name\n",
      "),\n",
      "lateness_data AS (\n",
      "    SELECT \n",
      "        a.employee_id,\n",
      "        es.organization_id,\n",
      "        SUM(CASE \n",
      "            WHEN ast.name = 'Terlambat <= 5 menit' THEN 5\n",
      "            WHEN ast.name = 'Terlambat > 5 menit' THEN \n",
      "                (a.time_in - adr.shift_time_in)/60000\n",
      "            ELSE 0 \n",
      "        END) AS total_lateness_minutes\n",
      "    FROM \n",
      "        attendances a\n",
      "    JOIN \n",
      "        attendance_detail_recapitulations adr ON a.employee_id = adr.employee_id AND a.date = adr.date\n",
      "    JOIN \n",
      "        attendance_statuses ast ON a.attendance_status_in_id = ast.id\n",
      "    JOIN \n",
      "        employment_statuses es ON a.employee_id = es.employee_id\n",
      "    WHERE \n",
      "        a.date BETWEEN DATE_SUB(STR_TO_DATE('2023-01-01', '%Y-%m-%d'), INTERVAL 3 MONTH) AND STR_TO_DATE('2023-01-01', '%Y-%m-%d')\n",
      "        AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND es.location_id IN ('[LOCATION_IDS]')\n",
      "    GROUP BY \n",
      "        a.employee_id, es.organization_id\n",
      ")\n",
      "SELECT \n",
      "    od.department,\n",
      "    AVG(od.total_overtime_hours) AS avg_overtime_hours,\n",
      "    AVG(ld.total_lateness_minutes) AS avg_lateness_minutes,\n",
      "    COUNT(DISTINCT od.employee_id) AS employee_count\n",
      "FROM \n",
      "    overtime_data od\n",
      "JOIN \n",
      "    lateness_data ld ON od.employee_id = ld.employee_id AND od.organization_id = ld.organization_id\n",
      "GROUP BY \n",
      "    od.department\n",
      "ORDER BY \n",
      "    avg_overtime_hours DESC;\n",
      "\n",
      "Trying candidate 1\n",
      "✅ Candidate 1 executed successfully!\n",
      "173_1: ✅ Original query executed successfully!\n",
      "173_2: ✅ Original query executed successfully!\n",
      "173_3: ⚠️ Skipped due to column not found error.\n",
      "Processing... question 174_1 Retry attempt: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 11:02:55,193 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 1):\n",
      "WITH RECURSIVE org_hierarchy AS (\n",
      "  SELECT id, name, manager_id, 0 AS level \n",
      "  FROM employees \n",
      "  WHERE manager_id IS NULL AND active = TRUE\n",
      "  \n",
      "  UNION ALL \n",
      "  \n",
      "  SELECT e.id, e.name, e.manager_id, oh.level + 1 \n",
      "  FROM employees e \n",
      "  JOIN org_hierarchy oh ON e.manager_id = oh.id \n",
      "  WHERE e.active = TRUE\n",
      "),\n",
      "manager_counts AS (\n",
      "  SELECT \n",
      "    oh.level AS management_level,\n",
      "    o.id AS organization_id,\n",
      "    o.name AS department,\n",
      "    COUNT(DISTINCT oh.id) AS number_of_managers,\n",
      "    COUNT(e.id) AS total_direct_reports\n",
      "  FROM org_hierarchy oh\n",
      "  LEFT JOIN employees e ON oh.id = e.manager_id AND e.active = TRUE\n",
      "  LEFT JOIN employment_statuses es ON oh.id = es.employee_id\n",
      "  LEFT JOIN organizations o ON es.organization_id = o.id\n",
      "  WHERE o.id IN ('[ORGANIZATION_IDS]')\n",
      "  GROUP BY oh.level, o.id, o.name\n",
      "),\n",
      "span_stats AS (\n",
      "  SELECT \n",
      "    management_level,\n",
      "    department,\n",
      "    number_of_managers,\n",
      "    total_direct_reports,\n",
      "    ROUND(total_direct_reports / NULLIF(number_of_managers, 0), 2) AS avg_span_of_control,\n",
      "    MIN(total_direct_reports) OVER (PARTITION BY management_level, organization_id) AS min_span,\n",
      "    MAX(total_direct_reports) OVER (PARTITION BY management_level, organization_id) AS max_span\n",
      "  FROM manager_counts\n",
      ")\n",
      "SELECT * FROM span_stats\n",
      "ORDER BY management_level, avg_span_of_control DESC;\n",
      "\n",
      "Trying candidate 1\n",
      "✅ Candidate 1 executed successfully!\n",
      "174_2: ✅ Original query executed successfully!\n",
      "174_3: ✅ Original query executed successfully!\n",
      "175_1: ✅ Original query executed successfully!\n",
      "Processing... question 175_2 Retry attempt: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 11:03:59,788 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 1):\n",
      "WITH monthly_counts AS (\n",
      "    SELECT \n",
      "        m.name AS manager_name,\n",
      "        DATE_FORMAT(esh.effective_date, '%Y-%m') AS month,\n",
      "        COUNT(e.id) AS direct_reports\n",
      "    FROM \n",
      "        employees e\n",
      "        JOIN employees m ON e.manager_id = m.id\n",
      "        JOIN employment_status_histories esh ON e.id = esh.employee_id\n",
      "        JOIN employment_statuses es ON e.id = es.employee_id\n",
      "    WHERE \n",
      "        e.active = TRUE\n",
      "        AND esh.effective_date >= DATE_SUB(CURRENT_DATE(), INTERVAL 12 MONTH)\n",
      "        AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND es.location_id IN ('[LOCATION_IDS]')\n",
      "    GROUP BY \n",
      "        m.name, DATE_FORMAT(esh.effective_date, '%Y-%m')\n",
      ")\n",
      "SELECT \n",
      "    manager_name, \n",
      "    month, \n",
      "    direct_reports,\n",
      "    LAG(direct_reports, 1) OVER (PARTITION BY manager_name ORDER BY month) AS prev_month_count,\n",
      "    direct_reports - LAG(direct_reports, 1) OVER (PARTITION BY manager_name ORDER BY month) AS change_in_count\n",
      "FROM \n",
      "    monthly_counts\n",
      "ORDER BY \n",
      "    manager_name, month;\n",
      "\n",
      "Trying candidate 1\n",
      "✅ Candidate 1 executed successfully!\n",
      "Processing... question 175_3 Retry attempt: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 11:05:08,959 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 1):\n",
      "WITH dept_stats AS (\n",
      "    SELECT \n",
      "        o.id AS org_id,\n",
      "        o.name AS department,\n",
      "        COUNT(e.id) AS total_employees\n",
      "    FROM \n",
      "        employees e\n",
      "        JOIN employment_statuses es ON e.id = es.employee_id\n",
      "        JOIN organizations o ON es.organization_id = o.id\n",
      "    WHERE \n",
      "        e.active = TRUE\n",
      "        AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND es.location_id IN ('[LOCATION_IDS]')\n",
      "    GROUP BY \n",
      "        o.id, o.name\n",
      "),\n",
      "manager_stats AS (\n",
      "    SELECT \n",
      "        m.id AS manager_id,\n",
      "        m.name AS manager_name,\n",
      "        o.id AS org_id,\n",
      "        o.name AS department,\n",
      "        COUNT(e.id) AS direct_reports\n",
      "    FROM \n",
      "        employees e\n",
      "        JOIN employees m ON e.manager_id = m.id\n",
      "        JOIN employment_statuses es ON e.id = es.employee_id\n",
      "        JOIN organizations o ON es.organization_id = o.id\n",
      "    WHERE \n",
      "        e.active = TRUE\n",
      "        AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND es.location_id IN ('[LOCATION_IDS]')\n",
      "    GROUP BY \n",
      "        m.id, m.name, o.id, o.name\n",
      "),\n",
      "attendance_stats AS (\n",
      "    SELECT \n",
      "        e.manager_id,\n",
      "        AVG(CASE WHEN ast.name IN ('Terlambat <= 5 menit', 'Terlambat > 5 menit') THEN 1 ELSE 0 END) AS late_rate\n",
      "    FROM \n",
      "        attendance_detail_recapitulations adr\n",
      "        JOIN employees e ON adr.employee_id = e.id\n",
      "        JOIN employment_statuses es ON e.id = es.employee_id\n",
      "        JOIN attendances a ON adr.attendance_id = a.id\n",
      "        JOIN attendance_statuses ast ON a.attendance_status_in_id = ast.id\n",
      "    WHERE \n",
      "        adr.date BETWEEN STR_TO_DATE('2023-01-01', '%Y-%m-%d') AND STR_TO_DATE('2023-12-31', '%Y-%m-%d')\n",
      "        AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND es.location_id IN ('[LOCATION_IDS]')\n",
      "    GROUP BY \n",
      "        e.manager_id\n",
      ")\n",
      "SELECT \n",
      "    ms.manager_name,\n",
      "    ms.department,\n",
      "    ms.direct_reports,\n",
      "    ds.total_employees,\n",
      "    ROUND(ms.direct_reports / ds.total_employees * 100, 2) AS span_of_control_percentage,\n",
      "    COALESCE(att.late_rate, 0) AS team_late_rate\n",
      "FROM \n",
      "    manager_stats ms\n",
      "    JOIN dept_stats ds ON ms.org_id = ds.org_id\n",
      "    LEFT JOIN attendance_stats att ON ms.manager_id = att.manager_id\n",
      "ORDER BY \n",
      "    span_of_control_percentage DESC\n",
      "LIMIT 10;\n",
      "\n",
      "Trying candidate 1\n",
      "✅ Candidate 1 executed successfully!\n",
      "176_1: ⚠️ Skipped due to column not found error.\n",
      "Processing... question 176_2 Retry attempt: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 11:06:46,040 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response (Attempt 1):\n",
      "WITH employee_join_age AS (\n",
      "    SELECT \n",
      "        e.id,\n",
      "        o.name AS department,\n",
      "        YEAR(e.join_date) AS join_year,\n",
      "        FLOOR(DATEDIFF(e.join_date, ed.date_of_birth)/365) AS age_at_join\n",
      "    FROM \n",
      "        employees e\n",
      "    JOIN \n",
      "        employee_details ed ON e.id = ed.employee_id\n",
      "    JOIN \n",
      "        employment_statuses es ON e.id = es.employee_id\n",
      "    JOIN \n",
      "        organizations o ON es.organization_id = o.id\n",
      "    WHERE \n",
      "        e.join_date >= DATE_SUB(STR_TO_DATE('11 April 2025', '%d %M %Y'), INTERVAL 5 YEAR)\n",
      "        AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND es.location_id IN ('[LOCATION_IDS]')\n",
      ")\n",
      "SELECT \n",
      "    join_year,\n",
      "    department,\n",
      "    AVG(age_at_join) AS average_join_age,\n",
      "    COUNT(*) AS employee_count\n",
      "FROM \n",
      "    employee_join_age\n",
      "GROUP BY \n",
      "    join_year, department\n",
      "ORDER BY \n",
      "    join_year, department;\n",
      "\n",
      "Trying candidate 1\n",
      "❌ Candidate 1 failed with error: Error executing query: 1054 (42S22): Unknown column 'e.join_date' in 'field list'\n",
      "SELECT \n",
      "    YEAR(e.join_date) AS join_year,\n",
      "    o.name AS department,\n",
      "    AVG(FLOOR(DATEDIFF(e.join_date, ed.date_of_birth)/365)) AS average_join_age,\n",
      "    COUNT(*) AS employee_count\n",
      "FROM \n",
      "    employees e\n",
      "JOIN \n",
      "    employee_details ed ON e.id = ed.employee_id\n",
      "JOIN \n",
      "    employment_statuses es ON e.id = es.employee_id\n",
      "JOIN \n",
      "    organizations o ON es.organization_id = o.id\n",
      "WHERE \n",
      "    e.join_date >= DATE_SUB(STR_TO_DATE('11 April 2025', '%d %M %Y'), INTERVAL 5 YEAR)\n",
      "    AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "    AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "    AND es.location_id IN ('[LOCATION_IDS]')\n",
      "GROUP BY \n",
      "    join_year, department\n",
      "ORDER BY \n",
      "    join_year, department;\n",
      "\n",
      "Trying candidate 2\n",
      "❌ Candidate 2 failed with error: Error executing query: 1054 (42S22): Unknown column 'e.join_date' in 'field list'\n",
      "WITH employee_data AS (\n",
      "    SELECT \n",
      "        e.id,\n",
      "        o.name AS department,\n",
      "        YEAR(e.join_date) AS join_year,\n",
      "        ed.date_of_birth\n",
      "    FROM \n",
      "        employees e\n",
      "    JOIN \n",
      "        employee_details ed ON e.id = ed.employee_id\n",
      "    JOIN \n",
      "        employment_statuses es ON e.id = es.employee_id\n",
      "    JOIN \n",
      "        organizations o ON es.organization_id = o.id\n",
      "    WHERE \n",
      "        e.join_date >= DATE_SUB(STR_TO_DATE('11 April 2025', '%d %M %Y'), INTERVAL 5 YEAR)\n",
      "        AND es.organization_id IN ('[ORGANIZATION_IDS]')\n",
      "        AND es.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
      "        AND es.location_id IN ('[LOCATION_IDS]')\n",
      ")\n",
      "SELECT \n",
      "    join_year,\n",
      "    department,\n",
      "    AVG(FLOOR(DATEDIFF(STR_TO_DATE(CONCAT(join_year, '-01-01'), date_of_birth)/365)) AS average_join_age,\n",
      "    COUNT(*) AS employee_count\n",
      "FROM \n",
      "    employee_data\n",
      "GROUP BY \n",
      "    join_year, department\n",
      "ORDER BY \n",
      "    join_year, department;\n",
      "\n",
      "Trying candidate 3\n",
      "❌ Candidate 3 failed with error: Error executing query: 1582 (42000): Incorrect parameter count in the call to native function 'DATEDIFF'\n",
      "No working candidates found. Retrying... (1/3)\n",
      "Processing... question 176_2 Retry attempt: 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 11:07:40,678 - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 391\u001b[39m\n\u001b[32m    387\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProcessing... question \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mno\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Retry attempt: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mretry_count\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_retries\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    390\u001b[39m     \u001b[38;5;66;03m# Invoke the LLM chain to get SQL query candidates\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m391\u001b[39m     response = \u001b[43mchain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mschema\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrelations\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaster_data\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaster_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata_trustee_tables\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_trustee_tables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43manonymized_entities_description\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43manonymized_entities_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcurrent_date\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_date\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbusiness_question\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcurrent_sql_query\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msql_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43merror_output\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb_error_msg\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Pass the current error message\u001b[39;49;00m\n\u001b[32m    401\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    403\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLLM Response (Attempt \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mretry_count\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m):\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    405\u001b[39m     \u001b[38;5;66;03m# Try each SQL query candidate\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Documents/KULIAH/gdp/text-to-sql-fine-tuned/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:3025\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3023\u001b[39m                 \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m   3024\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3025\u001b[39m                 \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3026\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3027\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Documents/KULIAH/gdp/text-to-sql-fine-tuned/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:307\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    297\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    298\u001b[39m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[32m   (...)\u001b[39m\u001b[32m    302\u001b[39m     **kwargs: Any,\n\u001b[32m    303\u001b[39m ) -> BaseMessage:\n\u001b[32m    304\u001b[39m     config = ensure_config(config)\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    306\u001b[39m         ChatGeneration,\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    317\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Documents/KULIAH/gdp/text-to-sql-fine-tuned/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:843\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    835\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    836\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    837\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[32m   (...)\u001b[39m\u001b[32m    840\u001b[39m     **kwargs: Any,\n\u001b[32m    841\u001b[39m ) -> LLMResult:\n\u001b[32m    842\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m843\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Documents/KULIAH/gdp/text-to-sql-fine-tuned/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:683\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    680\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[32m    681\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    682\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m683\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    689\u001b[39m         )\n\u001b[32m    690\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    691\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Documents/KULIAH/gdp/text-to-sql-fine-tuned/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:908\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    906\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    907\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m908\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    909\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    910\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    911\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    912\u001b[39m         result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Documents/KULIAH/gdp/text-to-sql-fine-tuned/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:717\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    715\u001b[39m     generation_info = {\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response.headers)}\n\u001b[32m    716\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m717\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response, generation_info)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Documents/KULIAH/gdp/text-to-sql-fine-tuned/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py:279\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    277\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Documents/KULIAH/gdp/text-to-sql-fine-tuned/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:914\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    871\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    872\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    873\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    911\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    912\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    913\u001b[39m     validate_response_format(response_format)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Documents/KULIAH/gdp/text-to-sql-fine-tuned/.venv/lib/python3.12/site-packages/openai/_base_client.py:1242\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1228\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1230\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1238\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1239\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1240\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1241\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Documents/KULIAH/gdp/text-to-sql-fine-tuned/.venv/lib/python3.12/site-packages/openai/_base_client.py:919\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[39m\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    917\u001b[39m     retries_taken = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m919\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Documents/KULIAH/gdp/text-to-sql-fine-tuned/.venv/lib/python3.12/site-packages/openai/_base_client.py:955\u001b[39m, in \u001b[36mSyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m    952\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[33mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, request.method, request.url)\n\u001b[32m    954\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m955\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    961\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Documents/KULIAH/gdp/text-to-sql-fine-tuned/.venv/lib/python3.12/site-packages/httpx/_client.py:928\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    927\u001b[39m     response.close()\n\u001b[32m--> \u001b[39m\u001b[32m928\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Documents/KULIAH/gdp/text-to-sql-fine-tuned/.venv/lib/python3.12/site-packages/httpx/_client.py:922\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[32m--> \u001b[39m\u001b[32m922\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    924\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[32m    926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Documents/KULIAH/gdp/text-to-sql-fine-tuned/.venv/lib/python3.12/site-packages/httpx/_models.py:881\u001b[39m, in \u001b[36mResponse.read\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    877\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    878\u001b[39m \u001b[33;03mRead and return the response content.\u001b[39;00m\n\u001b[32m    879\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    880\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_content\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m881\u001b[39m     \u001b[38;5;28mself\u001b[39m._content = \u001b[33;43mb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._content\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Documents/KULIAH/gdp/text-to-sql-fine-tuned/.venv/lib/python3.12/site-packages/httpx/_models.py:897\u001b[39m, in \u001b[36mResponse.iter_bytes\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    895\u001b[39m chunker = ByteChunker(chunk_size=chunk_size)\n\u001b[32m    896\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m897\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Documents/KULIAH/gdp/text-to-sql-fine-tuned/.venv/lib/python3.12/site-packages/httpx/_models.py:951\u001b[39m, in \u001b[36mResponse.iter_raw\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    948\u001b[39m chunker = ByteChunker(chunk_size=chunk_size)\n\u001b[32m    950\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m951\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_num_bytes_downloaded\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Documents/KULIAH/gdp/text-to-sql-fine-tuned/.venv/lib/python3.12/site-packages/httpx/_client.py:153\u001b[39m, in \u001b[36mBoundSyncStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Documents/KULIAH/gdp/text-to-sql-fine-tuned/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:127\u001b[39m, in \u001b[36mResponseStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m    126\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_httpcore_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Documents/KULIAH/gdp/text-to-sql-fine-tuned/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:407\u001b[39m, in \u001b[36mPoolByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    405\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    406\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Documents/KULIAH/gdp/text-to-sql-fine-tuned/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:403\u001b[39m, in \u001b[36mPoolByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Documents/KULIAH/gdp/text-to-sql-fine-tuned/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:342\u001b[39m, in \u001b[36mHTTP11ConnectionByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ShieldCancellation():\n\u001b[32m    341\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Documents/KULIAH/gdp/text-to-sql-fine-tuned/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:334\u001b[39m, in \u001b[36mHTTP11ConnectionByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    333\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mreceive_response_body\u001b[39m\u001b[33m\"\u001b[39m, logger, \u001b[38;5;28mself\u001b[39m._request, kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    337\u001b[39m     \u001b[38;5;66;03m# If we get an exception while streaming the response,\u001b[39;00m\n\u001b[32m    338\u001b[39m     \u001b[38;5;66;03m# we want to close the response (and possibly the connection)\u001b[39;00m\n\u001b[32m    339\u001b[39m     \u001b[38;5;66;03m# before raising that exception.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Documents/KULIAH/gdp/text-to-sql-fine-tuned/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:203\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_body\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    200\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Data):\n\u001b[32m    205\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mbytes\u001b[39m(event.data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Documents/KULIAH/gdp/text-to-sql-fine-tuned/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Documents/KULIAH/gdp/text-to-sql-fine-tuned/.venv/lib/python3.12/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/ssl.py:1233\u001b[39m, in \u001b[36mSSLSocket.recv\u001b[39m\u001b[34m(self, buflen, flags)\u001b[39m\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1230\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1231\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1232\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1233\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1235\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv(buflen, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/ssl.py:1106\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1104\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1105\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1106\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[32m   1108\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.args[\u001b[32m0\u001b[39m] == SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.suppress_ragged_eofs:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import re\n",
    "from typing import Any, Dict, List, Optional\n",
    "import pandas as pd\n",
    "from datetime import datetime, time\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy.orm import Session\n",
    "from decimal import Decimal\n",
    "from modules.constants import ColumnName\n",
    "\n",
    "class SQLQueryTester:\n",
    "    \"\"\"Class to handle SQL query testing across different databases.\"\"\"\n",
    "\n",
    "    def __init__(self, databases: Dict[str, Session], default_db: str = 'core', refresh_interval: Optional[int] = None):\n",
    "        \"\"\"Initialize with database sessions.\n",
    "\n",
    "        Args:\n",
    "            databases (Dict[str, Session]): Dictionary mapping database names to their sessions\n",
    "            default_db (str): Name of the default database to use when not specified\n",
    "            refresh_interval (Optional[int]): Seconds between filter refreshes. None means no auto-refresh.\n",
    "        \"\"\"\n",
    "        self.databases = databases\n",
    "        self.default_db = default_db\n",
    "        self.refresh_interval = refresh_interval\n",
    "        self.last_refresh = datetime.now()\n",
    "\n",
    "        # Setup logging\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "        # Cache for prepared queries and filters\n",
    "        self._query_cache = {}\n",
    "        self.filters = self._get_employment_filters()\n",
    "\n",
    "\n",
    "    def _get_distinct_values(self, db: Session, table: str, column: str) -> List[str]:\n",
    "        \"\"\"Get distinct values from a specified column in a table.\n",
    "\n",
    "        Args:\n",
    "            db (Session): Database session\n",
    "            table (str): Table name\n",
    "            column (str): Column name\n",
    "\n",
    "        Returns:\n",
    "            List[str]: List of distinct non-null values\n",
    "        \"\"\"\n",
    "        query = f\"SELECT DISTINCT {column} FROM {table} WHERE {column} IS NOT NULL\"\n",
    "        cursor = db.cursor(dictionary=True)\n",
    "        cursor.execute(query)\n",
    "        result = cursor.fetchall()\n",
    "        cursor.close()\n",
    "        return [str(row[column]) for row in result]\n",
    "\n",
    "    def _get_filters(self, db_name: str, filters_config: List[Dict[str, str]]) -> Dict[str, List[str]]:\n",
    "        \"\"\"Get filter values based on provided configuration.\n",
    "\n",
    "        Args:\n",
    "            db_name (str): Name of the database to query (e.g., 'core', 'time')\n",
    "            filters_config (List[Dict[str, str]]): List of filter configurations.\n",
    "                Each config should have:\n",
    "                - 'key': Key for the returned dictionary\n",
    "                - 'table': Table name to query\n",
    "                - 'column': Column name to get distinct values from\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, List[str]]: Dictionary containing filter values mapped to their keys\n",
    "        \"\"\"\n",
    "        db = self.databases.get(db_name)\n",
    "        if not db:\n",
    "            raise ValueError(f\"Database '{db_name}' not found\")\n",
    "\n",
    "        result = {}\n",
    "        for config in filters_config:\n",
    "            values = self._get_distinct_values(db, config['table'], config['column'])\n",
    "            if not values:\n",
    "                self.logger.warning(f\"No values found for {config['table']}.{config['column']}\")\n",
    "            result[config['key']] = values\n",
    "\n",
    "        return result\n",
    "\n",
    "    def _get_employment_filters(self) -> Dict[str, List[str]]:\n",
    "        \"\"\"Get all filter values needed for employment status queries.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, List[str]]: Dictionary containing filter values\n",
    "        \"\"\"\n",
    "        # Define the filter configuration\n",
    "        filters_config = [\n",
    "            {'key': 'organization_id', 'table': 'employment_statuses', 'column': 'organization_id'},\n",
    "            {'key': 'job_level_id', 'table': 'employment_statuses', 'column': 'job_level_id'},\n",
    "            {'key': 'location_id', 'table': 'employment_statuses', 'column': 'location_id'}\n",
    "        ]\n",
    "\n",
    "        return self._get_filters(self.default_db, filters_config)\n",
    "\n",
    "    def refresh_filters_if_needed(self) -> None:\n",
    "        \"\"\"Refresh filters if the refresh interval has passed.\"\"\"\n",
    "        if not self.refresh_interval:\n",
    "            return\n",
    "\n",
    "        now = datetime.now()\n",
    "        elapsed = (now - self.last_refresh).total_seconds()\n",
    "\n",
    "        if elapsed >= self.refresh_interval:\n",
    "            self.logger.info(\"Refreshing filters due to interval expiration\")\n",
    "            self.filters = self._get_employment_filters()\n",
    "            self.last_refresh = now\n",
    "            # Clear cache when filters change\n",
    "            self._query_cache.clear()\n",
    "\n",
    "    def prepare_query(self, sql_query: str) -> str:\n",
    "        \"\"\"Replace placeholder values in SQL query with actual filter values.\n",
    "\n",
    "        Args:\n",
    "            sql_query (str): Original SQL query with placeholders like [ORGANIZATION_IDS]\n",
    "                or '[ORGANIZATION_IDS]'\n",
    "\n",
    "        Returns:\n",
    "            str: SQL query with placeholders replaced by actual filter values\n",
    "        \"\"\"\n",
    "        # Input validation\n",
    "        if not sql_query:\n",
    "            raise ValueError(\"SQL query cannot be empty\")\n",
    "\n",
    "        # Check cache first\n",
    "        if sql_query in self._query_cache:\n",
    "            return self._query_cache[sql_query]\n",
    "\n",
    "        # Make sure filters are up-to-date\n",
    "        self.refresh_filters_if_needed()\n",
    "        # Create filter values with proper SQL formatting\n",
    "        filter_values = {\n",
    "            'organization_id': \", \".join(f\"'{id}'\" for id in self.filters['organization_id']),\n",
    "            'job_level_id': \", \".join(f\"'{id}'\" for id in self.filters['job_level_id']),\n",
    "            'location_id': \", \".join(f\"'{id}'\" for id in self.filters['location_id'])\n",
    "        }\n",
    "\n",
    "        # Handle both quoted and unquoted placeholders\n",
    "        replacements = {\n",
    "            # For quoted placeholders: '([ORGANIZATION_IDS])'\n",
    "            \"'[ORGANIZATION_IDS]'\": filter_values['organization_id'],\n",
    "            \"'[JOB_LEVEL_IDS]'\": filter_values['job_level_id'],\n",
    "            \"'[LOCATION_IDS]'\": filter_values['location_id'],\n",
    "\n",
    "            # For unquoted placeholders: ([ORGANIZATION_IDS])\n",
    "            \"[ORGANIZATION_IDS]\": filter_values['organization_id'],\n",
    "            \"[JOB_LEVEL_IDS]\": filter_values['job_level_id'],\n",
    "            \"[LOCATION_IDS]\": filter_values['location_id']\n",
    "        }\n",
    "\n",
    "        # Replace all placeholders\n",
    "        prepared_query = sql_query\n",
    "        for placeholder, value in replacements.items():\n",
    "            prepared_query = prepared_query.replace(placeholder, value)\n",
    "\n",
    "        # Store in cache\n",
    "        self._query_cache[sql_query] = prepared_query\n",
    "\n",
    "        return prepared_query\n",
    "\n",
    "    def format_query_results(self, results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Format query results by converting special data types to standard formats.\n",
    "\n",
    "        Args:\n",
    "            results (List[Dict[str, Any]]): List of dictionaries containing query results\n",
    "\n",
    "        Returns:\n",
    "            List[Dict[str, Any]]: Formatted results with dates as strings and decimals as integers\n",
    "        \"\"\"\n",
    "        formatted_results = []\n",
    "        for row in results:\n",
    "            formatted_row = {}\n",
    "            for key, value in row.items():\n",
    "                # Check if value has a strftime method (date/datetime objects)\n",
    "                if hasattr(value, 'strftime'):\n",
    "                    formatted_row[key] = value.strftime('%Y-%m-%d')\n",
    "                # Check if value is a Decimal\n",
    "                elif str(type(value)).find('Decimal') > -1:\n",
    "                    # Convert to int if it's a whole number, otherwise to float\n",
    "                    try:\n",
    "                        if value % 1 == 0:\n",
    "                            formatted_row[key] = int(value)\n",
    "                        else:\n",
    "                            formatted_row[key] = float(value)\n",
    "                    except:\n",
    "                        formatted_row[key] = float(value)\n",
    "                else:\n",
    "                    formatted_row[key] = value\n",
    "            formatted_results.append(formatted_row)\n",
    "\n",
    "        return formatted_results\n",
    "\n",
    "    def execute_query(self, sql_query: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Execute SQL query on specified database.\n",
    "\n",
    "        Args:\n",
    "            sql_query (str): SQL query to execute\n",
    "            db_name (str, optional): Name of database to use. If None, uses the default database.\n",
    "\n",
    "        Returns:\n",
    "            List[Dict[str, Any]]: Query results as list of dictionaries with formatted values\n",
    "        \"\"\"\n",
    "        db_name = self.default_db\n",
    "\n",
    "        connection = self.databases.get(db_name)\n",
    "        if not connection:\n",
    "            raise ValueError(f\"Database '{db_name}' not found\")\n",
    "        cursor = connection.cursor(dictionary=True)\n",
    "        try:\n",
    "            # Prepare and execute query\n",
    "            final_query = self.prepare_query(sql_query)\n",
    "            cursor.execute(final_query)\n",
    "            results = cursor.fetchall()\n",
    "            # Format results to handle special data types\n",
    "            cursor.close()\n",
    "            return self.format_query_results(results), []\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error executing query: {str(e)}\"\n",
    "            # self.logger.error(error_msg)\n",
    "            # self.logger.error(f\"Query: {sql_query}\")\n",
    "            # print(error_msg)\n",
    "            return [], self.extract_error_message(error_msg)\n",
    "\n",
    "    def extract_error_message(self, error_text: str) -> str:\n",
    "        \"\"\"Extract the error message from SQL error text.\n",
    "\n",
    "        Args:\n",
    "            error_text (str): The full error text containing SQL error information\n",
    "\n",
    "        Returns:\n",
    "            str: The extracted error message sentence\n",
    "        \"\"\"\n",
    "        # Find the first line which contains the error message\n",
    "        lines = error_text.strip().split('\\n')\n",
    "        error_line = lines[0] if lines else \"\"\n",
    "\n",
    "        # If the error is about a table not existing, modify it to match the desired format\n",
    "        if \"Table\" in error_line and \"doesn't exist\" in error_line:\n",
    "            # Extract the table name from the original error\n",
    "            import re\n",
    "            table_match = re.search(r\"Table '([^']+)\\.([^']+)' doesn't exist\", error_line)\n",
    "\n",
    "            if table_match:\n",
    "                database = table_match.group(1)\n",
    "                # Replace with 'families' as requested\n",
    "                return f\"Error executing query: (pymysql.err.ProgrammingError) (1146, \\\"Table '{database}.families' doesn't exist\\\")\"\n",
    "\n",
    "        return error_line\n",
    "\n",
    "\n",
    "# Usage example without a main function\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "databases = {\n",
    "    'core': core_employee_db,\n",
    "    'time': time_management_db\n",
    "}\n",
    "\n",
    "\n",
    "sysntetics_data_dir = \"augmented_sql_data_2\"\n",
    "file_name = \"augmented_data_time_management_196_questions_complete.csv\"\n",
    "# database_type = \"core\"\n",
    "database_type = \"time\"\n",
    "\n",
    "test_data = pd.read_csv(f\"{sysntetics_data_dir}/{file_name}\")\n",
    "query_tester = SQLQueryTester(databases, default_db=database_type)\n",
    "\n",
    "current_date = datetime.now().strftime(\"%d %B %Y\")\n",
    "\n",
    "if database_type == \"core\":\n",
    "    schema = employee_schema\n",
    "    relations = employee_relations\n",
    "    master_data = employee_master_data\n",
    "    data_trustee_tables = data_trustee_employee\n",
    "    master_data = employee_master_data\n",
    "else:\n",
    "    schema = time_management_schema\n",
    "    relations = time_management_relations\n",
    "    master_data = time_management_master_data\n",
    "    data_trustee_tables = data_trustee_time_management\n",
    "    master_data = time_management_master_data\n",
    "\n",
    "\n",
    "# print(qna_pair)\n",
    "save_correct_sql_datasets = os.path.join(sysntetics_data_dir, f\"fix_{file_name}\")\n",
    "save_failed_sql_datasets = os.path.join(sysntetics_data_dir, f\"failed_{file_name}\")\n",
    "final_result = []\n",
    "\n",
    "df_failed_queries = pd.DataFrame(\n",
    "    columns=[\n",
    "        ColumnName.NO,\n",
    "        ColumnName.BASE_PROMPT,\n",
    "        ColumnName.PROMPT,\n",
    "        ColumnName.FAILED_SQL_QUERY, ColumnName.ERROR\n",
    "    ]\n",
    ")\n",
    "df_query_result = pd.DataFrame(\n",
    "    columns=[\n",
    "        ColumnName.NO,\n",
    "        ColumnName.BASE_PROMPT,\n",
    "        ColumnName.PROMPT,\n",
    "        ColumnName.EXPECTED_SQL_QUERY,\n",
    "        ColumnName.EXPECTED_QUERY_RESULT,\n",
    "        ColumnName.TIME_TAKEN\n",
    "    ]\n",
    ")\n",
    "processed_nos = set()\n",
    "failed_nos = set()\n",
    "\n",
    "if os.path.exists(save_correct_sql_datasets):\n",
    "    df_query_result = pd.read_csv(save_correct_sql_datasets)\n",
    "    processed_nos = set(df_query_result['No'].tolist())\n",
    "\n",
    "if os.path.exists(save_failed_sql_datasets):\n",
    "    df_failed_queries = pd.read_csv(save_failed_sql_datasets)\n",
    "    failed_nos = set(df_failed_queries['No'].tolist())\n",
    "\n",
    "# Iterate through test data rows with index\n",
    "for idx, (_, row) in enumerate(test_data.iterrows()):\n",
    "    # Only process first row for testing\n",
    "    # if idx != 0:\n",
    "    #     continue\n",
    "\n",
    "    # Extract SQL query and question from row\n",
    "    if ColumnName.BASE_PROMPT in row:\n",
    "        base_prompt = row[ColumnName.BASE_PROMPT]\n",
    "    else:\n",
    "        base_prompt = row[ColumnName.PROMPT]\n",
    "    no = row[ColumnName.NO]\n",
    "    question = row[ColumnName.PROMPT]\n",
    "    sql_query = row[ColumnName.EXPECTED_SQL_QUERY]\n",
    "\n",
    "    # Skip already processed items\n",
    "    if no in processed_nos or no in failed_nos:\n",
    "        logging.info({\"Status\": f\"Skipped {no}\"})\n",
    "        # print(base_prompt)\n",
    "        continue\n",
    "\n",
    "    # Execute query and get results/error\n",
    "    db_query_result, db_error_msg = query_tester.execute_query(sql_query)\n",
    "\n",
    "    # If error occurs, print debug information\n",
    "    if db_error_msg:\n",
    "        # Skip query if the error is about a table not found\n",
    "        table_not_found_match = re.search(r\"Table '([^']+)\\.([^']+)' doesn't exist\", db_error_msg)\n",
    "        if table_not_found_match:\n",
    "            print(f\"{no}: ⚠️ Skipped due to table not found error.\")\n",
    "            # Log the failure or handle it as needed\n",
    "            failed_query = {\n",
    "                ColumnName.NO: no,\n",
    "                ColumnName.BASE_PROMPT: base_prompt,\n",
    "                ColumnName.PROMPT: question,\n",
    "                ColumnName.FAILED_SQL_QUERY: sql_query,\n",
    "                ColumnName.ERROR: db_error_msg\n",
    "            }\n",
    "            # Optionally save failed queries to a separate file\n",
    "            df_failed_queries = pd.concat([df_failed_queries, pd.DataFrame([failed_query])], ignore_index=True)\n",
    "            df_failed_queries.to_csv(save_failed_sql_datasets, index=False)\n",
    "            continue\n",
    "        \n",
    "        # Skip query if the error is about a column not found\n",
    "        column_not_found_match = re.search(r\"Unknown column '(([^']+)\\.)?([^']+)' in\", db_error_msg)\n",
    "        if column_not_found_match:\n",
    "            print(f\"{no}: ⚠️ Skipped due to column not found error.\")\n",
    "            # Log the failure or handle it as needed\n",
    "            failed_query = {\n",
    "                ColumnName.NO: no,\n",
    "                ColumnName.BASE_PROMPT: base_prompt,\n",
    "                ColumnName.PROMPT: question,\n",
    "                ColumnName.FAILED_SQL_QUERY: sql_query,\n",
    "                ColumnName.ERROR: db_error_msg\n",
    "            }\n",
    "            # Optionally save failed queries to a separate file\n",
    "            df_failed_queries = pd.concat([df_failed_queries, pd.DataFrame([failed_query])], ignore_index=True)\n",
    "            df_failed_queries.to_csv(save_failed_sql_datasets, index=False)\n",
    "            continue\n",
    "\n",
    "        found_best_sql_query = False\n",
    "        max_retries = 3  # Maximum number of LLM retries\n",
    "        retry_count = 0\n",
    "        start_time = datetime.now()\n",
    "        while not found_best_sql_query and retry_count < max_retries:\n",
    "            print(f\"Processing... question {no} Retry attempt: {retry_count + 1}/{max_retries}\")\n",
    "\n",
    "            try:\n",
    "                # Invoke the LLM chain to get SQL query candidates\n",
    "                response = chain.invoke({\n",
    "                    \"schema\": schema,\n",
    "                    \"relations\": relations,\n",
    "                    \"master_data\": master_data,\n",
    "                    \"data_trustee_tables\": data_trustee_tables,\n",
    "                    \"anonymized_entities_description\": anonymized_entities_description,\n",
    "                    \"current_date\": current_date,\n",
    "                    \"business_question\": question,\n",
    "                    \"current_sql_query\": sql_query,\n",
    "                    \"error_output\": db_error_msg  # Pass the current error message\n",
    "                })\n",
    "\n",
    "                print(f\"LLM Response (Attempt {retry_count + 1}):\")\n",
    "\n",
    "                # Try each SQL query candidate\n",
    "                for i in range(3):\n",
    "                    candidate_name = f'sql_query_candidate_{i+1}'\n",
    "                    if candidate_name in response['sql_queries']:\n",
    "                        sql_query = response['sql_queries'][candidate_name]\n",
    "                        print(sql_query)\n",
    "                        print(f\"\\nTrying candidate {i+1}\")\n",
    "\n",
    "                        # Test the candidate query\n",
    "                        db_query_result, db_error_msg = query_tester.execute_query(sql_query)\n",
    "\n",
    "                        if not db_error_msg:\n",
    "                            # We found a working query!\n",
    "                            print(f\"✅ Candidate {i+1} executed successfully!\")\n",
    "                            found_best_sql_query = True\n",
    "                            end_time = datetime.now()\n",
    "                            execution_time = (end_time - start_time).total_seconds()  # Calculate time taken and round to 2 decimal places for seconds\n",
    "                            # Create result row\n",
    "                            update_query = {\n",
    "                                ColumnName.NO: no,\n",
    "                                ColumnName.BASE_PROMPT: base_prompt,\n",
    "                                ColumnName.PROMPT: question,\n",
    "                                ColumnName.EXPECTED_SQL_QUERY: sql_query,\n",
    "                                ColumnName.GENERATED_QUERY_RESULT: db_query_result,\n",
    "                                ColumnName.TIME_TAKEN: execution_time\n",
    "                            }\n",
    "                            # Add to results dataframe\n",
    "                            df_query_result = pd.concat([df_query_result, pd.DataFrame([update_query])], ignore_index=True)\n",
    "                            df_query_result.to_csv(save_correct_sql_datasets, index=False)\n",
    "                            break\n",
    "                        else:\n",
    "                            print(f\"❌ Candidate {i+1} failed with error: {db_error_msg}\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error during LLM chain invocation: {str(e)}\")\n",
    "                db_error_msg = f\"LLM chain invocation failed: {str(e)}\"\n",
    "                retry_count += 1\n",
    "                continue\n",
    "\n",
    "            # If we haven't found a working query, update the error message for the next retry\n",
    "            if not found_best_sql_query:\n",
    "                retry_count += 1\n",
    "                # Update the error message to include information about failed attempts\n",
    "                db_error_msg = f\"Previous attempts failed. Last error: {db_error_msg}\"\n",
    "                print(f\"No working candidates found. Retrying... ({retry_count}/{max_retries})\")\n",
    "\n",
    "        if not found_best_sql_query:\n",
    "            print(f\"⚠️ Failed to find working SQL query after {max_retries} attempts.\")\n",
    "            # Log the failure or handle it as needed\n",
    "            failed_query = {\n",
    "                ColumnName.NO: no,\n",
    "                ColumnName.BASE_PROMPT: base_prompt,\n",
    "                ColumnName.PROMPT: question,\n",
    "                ColumnName.FAILED_SQL_QUERY: sql_query,\n",
    "                ColumnName.ERROR: db_error_msg\n",
    "            }\n",
    "            # Optionally save failed queries to a separate file\n",
    "            df_failed_queries = pd.concat([df_failed_queries, pd.DataFrame([failed_query])], ignore_index=True)\n",
    "            df_failed_queries.to_csv(save_failed_sql_datasets, index=False)\n",
    "    else:\n",
    "        # Query executed successfully, no need for fixes\n",
    "        print(f\"{no}: ✅ Original query executed successfully!\")\n",
    "        success_query = {\n",
    "            ColumnName.NO: no,\n",
    "            ColumnName.BASE_PROMPT: base_prompt,\n",
    "            ColumnName.PROMPT: question,\n",
    "            ColumnName.EXPECTED_SQL_QUERY: sql_query,\n",
    "            ColumnName.EXPECTED_QUERY_RESULT: db_query_result,\n",
    "            ColumnName.TIME_TAKEN: 0\n",
    "        }\n",
    "        # Add to results dataframe\n",
    "        df_query_result = pd.concat([df_query_result, pd.DataFrame([success_query])], ignore_index=True)\n",
    "        df_query_result.to_csv(save_correct_sql_datasets, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "1146 (42S02): Table 'ru4f_time_management.termination_reasons' doesn't exist",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMySQLInterfaceError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Documents/KULIAH/gdp/text-to-sql-fine-tuned/.venv/lib/python3.12/site-packages/mysql/connector/connection_cext.py:755\u001b[39m, in \u001b[36mCMySQLConnection.cmd_query\u001b[39m\u001b[34m(self, query, raw, buffered, raw_as_string, **kwargs)\u001b[39m\n\u001b[32m    754\u001b[39m         query = query.encode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m755\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cmysql\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    756\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    757\u001b[39m \u001b[43m        \u001b[49m\u001b[43mraw\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    758\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbuffered\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbuffered\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    759\u001b[39m \u001b[43m        \u001b[49m\u001b[43mraw_as_string\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraw_as_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    760\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_attrs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mquery_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    761\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m MySQLInterfaceError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[31mMySQLInterfaceError\u001b[39m: Table 'ru4f_time_management.termination_reasons' doesn't exist",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mProgrammingError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m      1\u001b[39m query = \u001b[33m\"\"\"\u001b[39m\u001b[33mWITH termination_counts AS (\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[33m  SELECT \u001b[39m\n\u001b[32m      3\u001b[39m \u001b[33m    organizations.name AS department,\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     28\u001b[39m \u001b[33mORDER BY tc1.count DESC;\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     31\u001b[39m cursor = connection.cursor(dictionary=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[43mcursor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m result = cursor.fetchall()\n\u001b[32m     34\u001b[39m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Documents/KULIAH/gdp/text-to-sql-fine-tuned/.venv/lib/python3.12/site-packages/mysql/connector/cursor_cext.py:351\u001b[39m, in \u001b[36mCMySQLCursor.execute\u001b[39m\u001b[34m(self, operation, params, map_results)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28mself\u001b[39m._executed = (\n\u001b[32m    344\u001b[39m     \u001b[38;5;28mself\u001b[39m._stmt_partition[\u001b[33m\"\u001b[39m\u001b[33msingle_stmts\u001b[39m\u001b[33m\"\u001b[39m].popleft()\n\u001b[32m    345\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m map_results\n\u001b[32m    346\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stmt_partition[\u001b[33m\"\u001b[39m\u001b[33mmappable_stmt\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    347\u001b[39m )\n\u001b[32m    349\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    350\u001b[39m     \u001b[38;5;28mself\u001b[39m._handle_result(\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcmd_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stmt_partition\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmappable_stmt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m            \u001b[49m\u001b[43mraw\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbuffered\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_buffered\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m            \u001b[49m\u001b[43mraw_as_string\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raw_as_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    357\u001b[39m     )\n\u001b[32m    358\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m MySQLInterfaceError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    359\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m get_mysql_exception(\n\u001b[32m    360\u001b[39m         msg=err.msg, errno=err.errno, sqlstate=err.sqlstate\n\u001b[32m    361\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Documents/KULIAH/gdp/text-to-sql-fine-tuned/.venv/lib/python3.12/site-packages/mysql/connector/opentelemetry/context_propagation.py:97\u001b[39m, in \u001b[36mwith_context_propagation.<locals>.wrapper\u001b[39m\u001b[34m(cnx, *args, **kwargs)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;66;03m# pylint: disable=possibly-used-before-assignment\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m OTEL_ENABLED \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cnx.otel_context_propagation:\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcnx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m current_span = trace.get_current_span()\n\u001b[32m    100\u001b[39m tp_header = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/Documents/KULIAH/gdp/text-to-sql-fine-tuned/.venv/lib/python3.12/site-packages/mysql/connector/connection_cext.py:763\u001b[39m, in \u001b[36mCMySQLConnection.cmd_query\u001b[39m\u001b[34m(self, query, raw, buffered, raw_as_string, **kwargs)\u001b[39m\n\u001b[32m    755\u001b[39m     \u001b[38;5;28mself\u001b[39m._cmysql.query(\n\u001b[32m    756\u001b[39m         query,\n\u001b[32m    757\u001b[39m         raw=raw,\n\u001b[32m   (...)\u001b[39m\u001b[32m    760\u001b[39m         query_attrs=\u001b[38;5;28mself\u001b[39m.query_attrs,\n\u001b[32m    761\u001b[39m     )\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m MySQLInterfaceError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m763\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m get_mysql_exception(\n\u001b[32m    764\u001b[39m         err.errno, msg=err.msg, sqlstate=err.sqlstate\n\u001b[32m    765\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    766\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    767\u001b[39m     addr = (\n\u001b[32m    768\u001b[39m         \u001b[38;5;28mself\u001b[39m._unix_socket \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._unix_socket \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._host\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._port\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    769\u001b[39m     )\n",
      "\u001b[31mProgrammingError\u001b[39m: 1146 (42S02): Table 'ru4f_time_management.termination_reasons' doesn't exist"
     ]
    }
   ],
   "source": [
    "query = \"\"\"WITH termination_counts AS (\n",
    "  SELECT \n",
    "    organizations.name AS department,\n",
    "    termination_reasons.name AS reason,\n",
    "    COUNT(*) AS count\n",
    "  FROM termination_entries\n",
    "  JOIN termination_reasons ON termination_entries.termination_reason_id = termination_reasons.id\n",
    "  JOIN employment_statuses ON termination_entries.employee_id = employment_statuses.employee_id\n",
    "  JOIN organizations ON employment_statuses.organization_id = organizations.id\n",
    "  WHERE \n",
    "    termination_entries.effective_date >= DATE_SUB(STR_TO_DATE('01 April 2025', '%d %M %Y'), INTERVAL 1 YEAR)\n",
    "    AND termination_entries.approval_status = 'APPROVED'\n",
    "    AND employment_statuses.organization_id IN ('[ORGANIZATION_IDS]')\n",
    "    AND employment_statuses.job_level_id IN ('[JOB_LEVEL_IDS]')\n",
    "    AND employment_statuses.location_id IN ('[LOCATION_IDS]')\n",
    "  GROUP BY organizations.name, termination_reasons.name\n",
    ")\n",
    "SELECT \n",
    "  tc1.department,\n",
    "  tc1.reason,\n",
    "  tc1.count\n",
    "FROM termination_counts tc1\n",
    "WHERE tc1.count = (\n",
    "  SELECT MAX(tc2.count)\n",
    "  FROM termination_counts tc2\n",
    "  WHERE tc2.department = tc1.department\n",
    ")\n",
    "ORDER BY tc1.count DESC;\n",
    "\"\"\"\n",
    "\n",
    "cursor = connection.cursor(dictionary=True)\n",
    "cursor.execute(query)\n",
    "result = cursor.fetchall()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>Base Prompt</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Expected SQL Query</th>\n",
       "      <th>Expected Query Result</th>\n",
       "      <th>Time Taken</th>\n",
       "      <th>Generated SQL Query</th>\n",
       "      <th>Generated Query Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Bagaimana distribusi pendapatan tambahan karya...</td>\n",
       "      <td>Bagaimana distribusi pendapatan tambahan karya...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.362395</td>\n",
       "      <td>SELECT organizations.name AS departemen, addit...</td>\n",
       "      <td>[{'departemen': 'Board of Directors', 'jenis_p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Berapa rata-rata pengalaman kerja sebelumnya u...</td>\n",
       "      <td>Berapa rata-rata pengalaman kerja sebelumnya u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.858527</td>\n",
       "      <td>SELECT job_levels.name AS level_jabatan, AVG(D...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Berapa lama waktu yang dibutuhkan karyawan unt...</td>\n",
       "      <td>Berapa lama waktu yang dibutuhkan karyawan unt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.066060</td>\n",
       "      <td>WITH first_promotions AS (\\n  SELECT \\n    e.i...</td>\n",
       "      <td>[{'rata_rata_hari_untuk_promosi': None, 'rata_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>Berapa rata-rata lama pengalaman kerja sebelum...</td>\n",
       "      <td>Berapa rata-rata lama pengalaman kerja sebelum...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.453215</td>\n",
       "      <td>WITH employee_experience AS (\\n  SELECT \\n    ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>Bagaimana distribusi pendapatan tambahan karya...</td>\n",
       "      <td>Bagaimana distribusi pendapatan tambahan karya...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.870550</td>\n",
       "      <td>SELECT \\n    job_levels.name AS job_level, \\n ...</td>\n",
       "      <td>[{'job_level': 'Staff', 'income_type': 'THR', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>53</td>\n",
       "      <td>Bagaimana tingkat turnover tahunan per departe...</td>\n",
       "      <td>Bagaimana tingkat turnover tahunan per departe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.119470</td>\n",
       "      <td>WITH year_range AS (\\n  SELECT YEAR(CURRENT_DA...</td>\n",
       "      <td>[{'department': 'Information Technology', 'yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>68</td>\n",
       "      <td>Hitung tingkat turnover tahunan per departemen...</td>\n",
       "      <td>Hitung tingkat turnover tahunan per departemen...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.662263</td>\n",
       "      <td>WITH termination_counts AS (\\n  SELECT \\n    o...</td>\n",
       "      <td>[{'department': 'Board of Directors', 'year': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>91</td>\n",
       "      <td>Bagaimana distribusi usia karyawan saat ini be...</td>\n",
       "      <td>Bagaimana distribusi usia karyawan saat ini be...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.519528</td>\n",
       "      <td>SELECT organizations.name AS department, FLOOR...</td>\n",
       "      <td>[{'department': 'Board of Commissioners', 'ave...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    No                                        Base Prompt  \\\n",
       "14  15  Bagaimana distribusi pendapatan tambahan karya...   \n",
       "17  18  Berapa rata-rata pengalaman kerja sebelumnya u...   \n",
       "19  20  Berapa lama waktu yang dibutuhkan karyawan unt...   \n",
       "34  35  Berapa rata-rata lama pengalaman kerja sebelum...   \n",
       "37  38  Bagaimana distribusi pendapatan tambahan karya...   \n",
       "52  53  Bagaimana tingkat turnover tahunan per departe...   \n",
       "67  68  Hitung tingkat turnover tahunan per departemen...   \n",
       "88  91  Bagaimana distribusi usia karyawan saat ini be...   \n",
       "\n",
       "                                               Prompt Expected SQL Query  \\\n",
       "14  Bagaimana distribusi pendapatan tambahan karya...                NaN   \n",
       "17  Berapa rata-rata pengalaman kerja sebelumnya u...                NaN   \n",
       "19  Berapa lama waktu yang dibutuhkan karyawan unt...                NaN   \n",
       "34  Berapa rata-rata lama pengalaman kerja sebelum...                NaN   \n",
       "37  Bagaimana distribusi pendapatan tambahan karya...                NaN   \n",
       "52  Bagaimana tingkat turnover tahunan per departe...                NaN   \n",
       "67  Hitung tingkat turnover tahunan per departemen...                NaN   \n",
       "88  Bagaimana distribusi usia karyawan saat ini be...                NaN   \n",
       "\n",
       "   Expected Query Result  Time Taken  \\\n",
       "14                   NaN   78.362395   \n",
       "17                   NaN   29.858527   \n",
       "19                   NaN   30.066060   \n",
       "34                   NaN   31.453215   \n",
       "37                   NaN   43.870550   \n",
       "52                   NaN   70.119470   \n",
       "67                   NaN   74.662263   \n",
       "88                   NaN   27.519528   \n",
       "\n",
       "                                  Generated SQL Query  \\\n",
       "14  SELECT organizations.name AS departemen, addit...   \n",
       "17  SELECT job_levels.name AS level_jabatan, AVG(D...   \n",
       "19  WITH first_promotions AS (\\n  SELECT \\n    e.i...   \n",
       "34  WITH employee_experience AS (\\n  SELECT \\n    ...   \n",
       "37  SELECT \\n    job_levels.name AS job_level, \\n ...   \n",
       "52  WITH year_range AS (\\n  SELECT YEAR(CURRENT_DA...   \n",
       "67  WITH termination_counts AS (\\n  SELECT \\n    o...   \n",
       "88  SELECT organizations.name AS department, FLOOR...   \n",
       "\n",
       "                               Generated Query Result  \n",
       "14  [{'departemen': 'Board of Directors', 'jenis_p...  \n",
       "17                                                 []  \n",
       "19  [{'rata_rata_hari_untuk_promosi': None, 'rata_...  \n",
       "34                                                 []  \n",
       "37  [{'job_level': 'Staff', 'income_type': 'THR', ...  \n",
       "52  [{'department': 'Information Technology', 'yea...  \n",
       "67  [{'department': 'Board of Directors', 'year': ...  \n",
       "88  [{'department': 'Board of Commissioners', 'ave...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_query_result[~df_query_result['Generated SQL Query'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to Google Sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]2025-03-27 09:46:13,426 - INFO - Successfully wrote row 1/98\n",
      "2025-03-27 09:46:15,460 - INFO - Successfully wrote row 2/98\n",
      "2025-03-27 09:46:17,318 - INFO - Successfully wrote row 3/98\n",
      "2025-03-27 09:46:19,135 - INFO - Successfully wrote row 4/98\n",
      "2025-03-27 09:46:20,972 - INFO - Successfully wrote row 5/98\n",
      "2025-03-27 09:46:21,905 - INFO - Successfully wrote row 6/98\n",
      "2025-03-27 09:46:23,817 - INFO - Successfully wrote row 7/98\n",
      "2025-03-27 09:46:25,670 - INFO - Successfully wrote row 8/98\n",
      "2025-03-27 09:46:27,516 - INFO - Successfully wrote row 9/98\n",
      "2025-03-27 09:46:29,361 - INFO - Successfully wrote row 10/98\n",
      " 10%|█         | 1/10 [00:20<03:00, 20.10s/it]2025-03-27 09:46:33,197 - INFO - Successfully wrote row 11/98\n",
      "2025-03-27 09:46:35,086 - INFO - Successfully wrote row 12/98\n",
      "2025-03-27 09:46:36,919 - INFO - Successfully wrote row 13/98\n",
      "2025-03-27 09:46:38,783 - INFO - Successfully wrote row 14/98\n",
      "2025-03-27 09:46:40,628 - INFO - Successfully wrote row 15/98\n",
      "2025-03-27 09:46:42,478 - INFO - Successfully wrote row 16/98\n",
      "2025-03-27 09:46:44,436 - INFO - Successfully wrote row 17/98\n",
      "2025-03-27 09:46:46,315 - INFO - Successfully wrote row 18/98\n",
      "2025-03-27 09:46:48,163 - INFO - Successfully wrote row 19/98\n",
      "2025-03-27 09:46:49,989 - INFO - Successfully wrote row 20/98\n",
      " 20%|██        | 2/10 [00:39<02:38, 19.87s/it]2025-03-27 09:46:53,003 - INFO - Successfully wrote row 21/98\n",
      "2025-03-27 09:46:54,828 - INFO - Successfully wrote row 22/98\n",
      "2025-03-27 09:46:56,675 - INFO - Successfully wrote row 23/98\n",
      "2025-03-27 09:46:58,482 - INFO - Successfully wrote row 24/98\n",
      "2025-03-27 09:47:00,322 - INFO - Successfully wrote row 25/98\n",
      "2025-03-27 09:47:02,180 - INFO - Successfully wrote row 26/98\n",
      "2025-03-27 09:47:04,018 - INFO - Successfully wrote row 27/98\n",
      "2025-03-27 09:47:05,796 - INFO - Successfully wrote row 28/98\n",
      "2025-03-27 09:47:07,584 - INFO - Successfully wrote row 29/98\n",
      "2025-03-27 09:47:09,393 - INFO - Successfully wrote row 30/98\n",
      " 30%|███       | 3/10 [01:00<02:20, 20.08s/it]2025-03-27 09:47:13,239 - INFO - Successfully wrote row 31/98\n",
      "2025-03-27 09:47:15,084 - INFO - Successfully wrote row 32/98\n",
      "2025-03-27 09:47:16,363 - WARNING - Rate limit hit. Waiting 2.83 seconds before retry 1\n",
      "2025-03-27 09:47:18,810 - WARNING - Rate limit hit. Waiting 4.52 seconds before retry 2\n",
      "2025-03-27 09:47:23,888 - WARNING - Rate limit hit. Waiting 8.16 seconds before retry 3\n",
      "2025-03-27 09:47:32,590 - WARNING - Rate limit hit. Waiting 16.97 seconds before retry 4\n",
      "2025-03-27 09:47:50,487 - INFO - Successfully wrote row 33/98\n",
      "2025-03-27 09:47:52,302 - INFO - Successfully wrote row 34/98\n",
      "2025-03-27 09:47:54,077 - INFO - Successfully wrote row 35/98\n",
      "2025-03-27 09:47:55,883 - INFO - Successfully wrote row 36/98\n",
      "2025-03-27 09:47:57,731 - INFO - Successfully wrote row 37/98\n",
      "2025-03-27 09:47:59,536 - INFO - Successfully wrote row 38/98\n",
      "2025-03-27 09:48:01,332 - INFO - Successfully wrote row 39/98\n",
      "2025-03-27 09:48:03,139 - INFO - Successfully wrote row 40/98\n",
      " 40%|████      | 4/10 [01:53<03:20, 33.37s/it]2025-03-27 09:48:06,978 - INFO - Successfully wrote row 41/98\n",
      "2025-03-27 09:48:08,795 - INFO - Successfully wrote row 42/98\n",
      "2025-03-27 09:48:10,632 - INFO - Successfully wrote row 43/98\n",
      "2025-03-27 09:48:12,633 - INFO - Successfully wrote row 44/98\n",
      "2025-03-27 09:48:14,480 - INFO - Successfully wrote row 45/98\n",
      "2025-03-27 09:48:16,254 - INFO - Successfully wrote row 46/98\n",
      "2025-03-27 09:48:17,203 - INFO - Successfully wrote row 47/98\n",
      "2025-03-27 09:48:19,020 - INFO - Successfully wrote row 48/98\n",
      "2025-03-27 09:48:20,805 - INFO - Successfully wrote row 49/98\n",
      "2025-03-27 09:48:22,652 - INFO - Successfully wrote row 50/98\n",
      " 50%|█████     | 5/10 [02:13<02:21, 28.37s/it]2025-03-27 09:48:26,429 - INFO - Successfully wrote row 51/98\n",
      "2025-03-27 09:48:28,207 - INFO - Successfully wrote row 52/98\n",
      "2025-03-27 09:48:28,775 - WARNING - Rate limit hit. Waiting 2.85 seconds before retry 1\n",
      "2025-03-27 09:48:32,189 - WARNING - Rate limit hit. Waiting 4.42 seconds before retry 2\n",
      "2025-03-27 09:48:38,423 - INFO - Successfully wrote row 53/98\n",
      "2025-03-27 09:48:40,270 - INFO - Successfully wrote row 54/98\n",
      "2025-03-27 09:48:42,142 - INFO - Successfully wrote row 55/98\n",
      "2025-03-27 09:48:44,904 - INFO - Successfully wrote row 56/98\n",
      "2025-03-27 09:48:45,852 - INFO - Successfully wrote row 57/98\n",
      "2025-03-27 09:48:47,635 - INFO - Successfully wrote row 58/98\n",
      "2025-03-27 09:48:49,441 - INFO - Successfully wrote row 59/98\n",
      "2025-03-27 09:48:51,231 - INFO - Successfully wrote row 60/98\n",
      " 60%|██████    | 6/10 [02:41<01:53, 28.44s/it]2025-03-27 09:48:55,055 - INFO - Successfully wrote row 61/98\n",
      "2025-03-27 09:48:56,835 - INFO - Successfully wrote row 62/98\n",
      "2025-03-27 09:48:58,684 - INFO - Successfully wrote row 63/98\n",
      "2025-03-27 09:49:00,539 - INFO - Successfully wrote row 64/98\n",
      "2025-03-27 09:49:02,377 - INFO - Successfully wrote row 65/98\n",
      "2025-03-27 09:49:04,163 - INFO - Successfully wrote row 66/98\n",
      "2025-03-27 09:49:05,958 - INFO - Successfully wrote row 67/98\n",
      "2025-03-27 09:49:07,744 - INFO - Successfully wrote row 68/98\n",
      "2025-03-27 09:49:09,582 - INFO - Successfully wrote row 69/98\n",
      "2025-03-27 09:49:11,376 - INFO - Successfully wrote row 70/98\n",
      " 70%|███████   | 7/10 [03:02<01:17, 25.73s/it]2025-03-27 09:49:15,195 - INFO - Successfully wrote row 71/98\n",
      "2025-03-27 09:49:16,060 - INFO - Successfully wrote row 72/98\n",
      "2025-03-27 09:49:17,896 - INFO - Successfully wrote row 73/98\n",
      "2025-03-27 09:49:18,434 - WARNING - Rate limit hit. Waiting 2.58 seconds before retry 1\n",
      "2025-03-27 09:49:21,559 - WARNING - Rate limit hit. Waiting 4.43 seconds before retry 2\n",
      "2025-03-27 09:49:26,549 - WARNING - Rate limit hit. Waiting 8.80 seconds before retry 3\n",
      "2025-03-27 09:49:37,173 - INFO - Successfully wrote row 74/98\n",
      "2025-03-27 09:49:39,033 - INFO - Successfully wrote row 75/98\n",
      "2025-03-27 09:49:40,849 - INFO - Successfully wrote row 76/98\n",
      "2025-03-27 09:49:44,037 - INFO - Successfully wrote row 77/98\n",
      "2025-03-27 09:49:44,912 - INFO - Successfully wrote row 78/98\n",
      "2025-03-27 09:49:46,696 - INFO - Successfully wrote row 79/98\n",
      "2025-03-27 09:49:48,545 - INFO - Successfully wrote row 80/98\n",
      " 80%|████████  | 8/10 [03:39<00:58, 29.37s/it]2025-03-27 09:49:52,394 - INFO - Successfully wrote row 81/98\n",
      "2025-03-27 09:49:54,200 - INFO - Successfully wrote row 82/98\n",
      "2025-03-27 09:49:56,070 - INFO - Successfully wrote row 83/98\n",
      "2025-03-27 09:49:57,877 - INFO - Successfully wrote row 84/98\n",
      "2025-03-27 09:49:59,716 - INFO - Successfully wrote row 85/98\n",
      "2025-03-27 09:50:01,564 - INFO - Successfully wrote row 86/98\n",
      "2025-03-27 09:50:03,392 - INFO - Successfully wrote row 87/98\n",
      "2025-03-27 09:50:05,251 - INFO - Successfully wrote row 88/98\n",
      "2025-03-27 09:50:07,181 - INFO - Successfully wrote row 89/98\n",
      "2025-03-27 09:50:09,019 - INFO - Successfully wrote row 90/98\n",
      " 90%|█████████ | 9/10 [03:59<00:26, 26.59s/it]2025-03-27 09:50:12,868 - INFO - Successfully wrote row 91/98\n",
      "2025-03-27 09:50:13,776 - INFO - Successfully wrote row 92/98\n",
      "2025-03-27 09:50:15,643 - INFO - Successfully wrote row 93/98\n",
      "2025-03-27 09:50:16,963 - WARNING - Rate limit hit. Waiting 2.76 seconds before retry 1\n",
      "2025-03-27 09:50:20,274 - WARNING - Rate limit hit. Waiting 4.67 seconds before retry 2\n",
      "2025-03-27 09:50:25,509 - WARNING - Rate limit hit. Waiting 8.11 seconds before retry 3\n",
      "2025-03-27 09:50:34,185 - WARNING - Rate limit hit. Waiting 16.61 seconds before retry 4\n",
      "2025-03-27 09:50:51,706 - INFO - Successfully wrote row 94/98\n",
      "2025-03-27 09:50:53,575 - INFO - Successfully wrote row 95/98\n",
      "2025-03-27 09:50:55,415 - INFO - Successfully wrote row 96/98\n",
      "2025-03-27 09:50:57,224 - INFO - Successfully wrote row 97/98\n",
      "2025-03-27 09:50:59,090 - INFO - Successfully wrote row 98/98\n",
      "100%|██████████| 10/10 [04:47<00:00, 28.78s/it]\n",
      "2025-03-27 09:50:59,098 - INFO - Successfully wrote 98 rows\n"
     ]
    }
   ],
   "source": [
    "from modules.google_sheets_writer import GoogleSheetsWriter\n",
    "import logging\n",
    "\n",
    "SYNTETIC_DATA_SHEET_NAME = \"catapa_syntetics_db_employee_2\"\n",
    "writer = GoogleSheetsWriter(\n",
    "    google_util=google,  # Your GoogleUtil instance\n",
    "    sheet_id=GOOGLE_SPREADSHEET_ID,\n",
    "    worksheet_name=SYNTETIC_DATA_SHEET_NAME,\n",
    "    batch_size=10,  # Customize batch size\n",
    "    max_retries=5,  # Customize retry attempts\n",
    "    batch_delay=2  # Customize delay between batches\n",
    ")\n",
    "# Write the DataFrame\n",
    "result = writer.write_dataframe(df_query_result)\n",
    "\n",
    "# Log results\n",
    "logging.info(f\"Successfully wrote {result.successful_rows} rows\")\n",
    "if result.failed_rows > 0:\n",
    "    logging.error(f\"Failed to write {result.failed_rows} rows\")\n",
    "    for error in result.errors:\n",
    "        logging.error(f\"Row {error['row_number']}: {error['error']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
